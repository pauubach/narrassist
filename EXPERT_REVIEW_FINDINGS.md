# Revisi√≥n Multi-Experto ‚Äî Narrative Assistant Pipeline

**Fecha**: 2026-02-02
**Paneles**: NLP+Ling√ºista+Corrector, AI+Arquitecto+BE, UX+FE+Editor, PO+QA
**Estado**: 4/4 completados

---

## Resumen Ejecutivo

4 paneles de expertos (11 roles) revisaron exhaustivamente el codebase. Hallaron **85+ issues** que convergen en **4 problemas sist√©micos**:

| Problema sist√©mico | Afecta a | Paneles que lo detectaron |
|---|---|---|
| Listas hardcodeadas donde deber√≠a haber an√°lisis morfol√≥gico | NER, atributos, met√°foras, pro-drop, subjuntivo | NLP, Arquitecto, PO |
| Errores silenciosos entre fases | Pipeline completa, datos corruptos sin aviso | Arquitecto, QA, UX |
| No hay feedback loop | No aprende de correcciones ni dismissals | NLP, UX, PO |
| Proximidad textual en vez de scope gramatical | Atributos, correferencias, coherencia emocional | NLP, Arquitecto, Editor |

### M√©tricas clave (PO+QA)

| M√©trica | Valor | Objetivo |
|---|---|---|
| Codebase | 152 m√≥dulos, 106K l√≠neas | ‚Äî |
| Tests | 2.346 tests, 63 archivos | ‚Äî |
| Cobertura por imports | ~45% de m√≥dulos | >90% |
| C√≥digo sin tests | 35-40% (~400 KB) | <10% |
| MVP features funcionando bien | 3-4 de 12 | 12/12 |
| Recall de inconsistencias | 13% | 80% |
| Performance (2-6 KB) | 100-130s | <30s |
| Bugs cr√≠ticos bloqueantes | 5 | 0 |
| Production readiness | 4.1/10 | 8/10 |

---

# Panel 1: NLP + Ling√ºista + Corrector

**27 issues** (3 cr√≠ticos, 9 mayores, 10 moderados, 5 menores)

---

## NLP-C1 [CR√çTICO]: `mention_count` nunca se incrementa

**Ubicaci√≥n**: `src/narrative_assistant/entities/repository.py:249`

**C√≥digo del problema**: El m√©todo existe pero nadie lo llama:

```python
# repository.py:249 ‚Äî m√©todo existente, hu√©rfano
def increment_mention_count(self, entity_id: int, delta: int = 1) -> None:
    """Incrementar el contador de menciones."""
    self.db.execute(
        "UPDATE entities SET mention_count = mention_count + ? WHERE id = ?",
        (delta, entity_id),
    )
```

Grep en todo el codebase: **cero llamadas** en c√≥digo de producci√≥n.

**Impacto**:
- `mention_count` siempre es 0 para todas las entidades
- Imposible distinguir protagonistas de figurantes
- Ranking de entidades por importancia roto
- `ORDER BY mention_count DESC` devuelve orden arbitrario

**Fix gen√©rico**: Cada vez que NER detecta una menci√≥n y se vincula a una entidad almacenada, llamar a `increment_mention_count(entity_id)`. A√±adir tests que verifiquen incremento.

---

## NLP-C2 [CR√çTICO]: Ventana de 400 chars para resolver atributos

**Ubicaci√≥n**: `src/narrative_assistant/nlp/attributes.py:2556-2728`

**C√≥digo del problema**:

```python
# attributes.py:2556 ‚Äî extrae ventana de contexto (400 chars ATR√ÅS)
context_start = max(0, position - 400)
context = text[context_start:position]

# attributes.py:2567 ‚Äî rechaza candidatos fuera de la ventana
if distance < 400:  # Ventana amplia
    candidates.append((name, start, end, distance, entity_type))

# attributes.py:2728 ‚Äî ajuste de g√©nero TAMBI√âN requiere <400
if best_candidate[1] < 400:
    logger.debug(...)
    return best_candidate[0]
```

**Por qu√© 400 chars no es ling√º√≠sticamente correcto**:
- 400 chars ‚âà 50-65 palabras
- Oraci√≥n media en espa√±ol literario: 150-200 palabras
- Prosa profesional/literaria: frecuentemente 250+ palabras
- 400 chars no corresponde a ninguna unidad ling√º√≠stica (ni oraci√≥n, ni cl√°usula, ni p√°rrafo)

**Ejemplo de fallo**:

```
"Juan Garc√≠a era un ejecutivo exitoso de mediana edad. Su pelo,
que anta√±o hab√≠a sido completamente negro, ahora mostraba algunas
canas. La vida en la metr√≥poli lo hab√≠a envejecido, aunque su
car√°cter segu√≠a siendo jovial. Sus compa√±eros de trabajo siempre
lo recordaban por su sentido del humor, que nunca le abandonaba
incluso en los momentos m√°s dif√≠ciles. Mar√≠a, su esposa, sol√≠a
bromear diciendo que era imposible hacerlo enojar. Pero lo que
pocos sab√≠an era que guardaba un dolor muy profundo en su pecho,
una herida que nunca hab√≠a sanado. Y sus ojos verdes, tan
expresivos normalmente, a veces reflejaban una tristeza inexplicable."

Posici√≥n de "sus ojos verdes": ~char 520
Posici√≥n de "Juan Garc√≠a": char 0
Distancia: >400 chars ‚Üí _find_nearest_entity() PODR√çA resolverlo a Mar√≠a (m√°s cercana)
```

**Otros fallos**: No detecta l√≠mites de p√°rrafo (`\n\n`), ignora cl√°usulas subordinadas ("Mar√≠a, quien hab√≠a estado esperando, sus ojos brillaban" ‚Üí "sus ojos" podr√≠a resolverse a Mar√≠a en vez de a Juan del clause principal), no respeta aposiciones ("Juan, mi amigo Carlos, ten√≠a ojos azules" ‚Üí podr√≠a asignar a Carlos en vez de a Juan).

**Fix gen√©rico**: Reemplazar distancia en chars por scope basado en `doc.sents` de spaCy (oraci√≥n actual + 2-3 oraciones previas). Usar `token.dep_` para identificar sujeto gramatical. Respetar l√≠mites de p√°rrafo. M√°ximo 1000-1500 chars como safety limit.

---

## NLP-C3 [CR√çTICO]: Listas de verbos incompletas en NER

**Ubicaci√≥n**: `src/narrative_assistant/nlp/ner.py:1191-1535`

**Escala del problema**:

```python
# ner.py:1191-1230 ‚Äî VERBS_AT_SENTENCE_START
VERBS_AT_SENTENCE_START = {
    "fue", "saludo", "salud√≥", "vio", "ley√≥", "lleg√≥",
    "escucho", "escuch√≥", "dijo", "correo", "corri√≥",
    # ... ~40 formas
}

# ner.py:1407-1420 ‚Äî verb_indicators
verb_indicators = {
    "hace", "hizo", "hacen", "hac√≠an",
    "toma", "tom√≥", "tomaban",
    # ... ~15 formas
}

# ner.py:1466-1535 ‚Äî VERB_ENDINGS (pattern-based)
VERB_ENDINGS = ('aba', 'aban', 'aria', 'arian', 'ar√©', ...)
# ... ~30-40 terminaciones
```

- Total cubierto: **~200 formas**
- Espa√±ol tiene: **20.000+ formas verbales** inflectadas
- Cobertura: **<1%**

**Conjugaciones que faltan completamente**:
- Subjuntivo: "fuera", "fuese", "llegues", "tuviera", "hayas"
- Gerundios: "sabiendo", "haciendo", "siendo", "teniendo"
- Participios como adjetivos: "cansado", "roto", "escrito", "pintado"
- Imperativos: "vuelve", "venid", "esperad", "escuchad"
- Condicional compuesto: "habr√≠a podido", "habr√≠a sido"
- Verbos comunes enteros: "decir", "ir", "estar", "ser", "mirar", "pensar", "sentir"

**Ejemplo de falso positivo**:

```
Texto: "Mar√≠a corri√≥ r√°pidamente. Sabiendo que la persegu√≠an,
no se atrev√≠a a mirar atr√°s. Roto de cansancio, cada paso le
costaba m√°s. Llegaba a la puerta cuando oy√≥ gritos."

Verbos que DEBER√çAN filtrarse pero NO est√°n en las listas:
- "Sabiendo" (gerundio) ‚Üí extra√≠do como entidad
- "Roto" (participio) ‚Üí extra√≠do como entidad
- "Llegaba" (imperfecto) ‚Üí extra√≠do como entidad
- "oy√≥" (pret√©rito) ‚Üí extra√≠do como entidad
```

**Fix gen√©rico**: Reemplazar listas hardcodeadas con POS tagging de spaCy:

```python
for token in doc:
    if token.pos_ in ("VERB", "AUX") or token.tag_.startswith("V"):
        continue  # Es verbo, no es entidad
```

Esto resuelve de golpe el 100% de formas verbales reconocidas por spaCy, en vez del <1% actual.

---

## NLP-M1 [MAYOR]: MISC‚ÜíPER demasiado agresivo

**Ubicaci√≥n**: `src/narrative_assistant/nlp/ner.py:985-1076`

```python
# ner.py:1038-1067 ‚Äî CUALQUIER MISC que coincida con apellido ‚Üí PER
COMMON_SURNAMES_AS_PER = {
    "ozores", "garc√≠a", "mart√≠nez", "l√≥pez", "fern√°ndez", ...
}

if text_lower in COMMON_SURNAMES_AS_PER:
    entity.label = EntityLabel.PER  # RECLASIFICAR
```

**Falsos positivos**:
- "la Garc√≠a" (taberna/bar) ‚Üí CHARACTER
- "los Mart√≠nez" (barrio) ‚Üí CHARACTER
- "calle Fern√°ndez" ‚Üí CHARACTER
- "El L√≥pez" (tienda) ‚Üí CHARACTER

**Fix gen√©rico**: Verificar contexto antes de reclasificar ‚Äî tokens precedentes (art√≠culo + sustantivo locativo como "calle", "barrio", "zona"), preposici√≥n "en" (ubicaci√≥n), funci√≥n sem√°ntica del sintagma.

---

## NLP-M2 [MAYOR]: Detecci√≥n de met√°foras simplista

**Ubicaci√≥n**: `src/narrative_assistant/nlp/attributes.py:953-962`

```python
METAPHOR_INDICATORS = [
    r"\bcomo\b",           # "como" = like
    r"\bparec[√≠i]a\b",     # "parec√≠a" = seemed
    r"\bcual\b",           # "cual" = such/which
    r"\bsemejante\s+a\b",  # "semejante a" = similar to
]
```

**Problema**: `como` tiene 6+ usos en espa√±ol:
1. **Comparaci√≥n** (met√°fora): "Sus ojos eran como diamantes" ‚úì
2. **Manera**: "Como lo hizo" ‚Äî NO es met√°fora
3. **Temporal**: "Como lleg√≥, vimos la verdad" ‚Äî NO es met√°fora
4. **Condicional**: "Como no vuelvas, te castigo" ‚Äî NO es met√°fora
5. **Aproximaci√≥n**: "Ten√≠a como veinte a√±os" ‚Äî NO es met√°fora
6. **Causal**: "Como estaba cansado, se sent√≥" ‚Äî NO es met√°fora

**El sistema trata los 6 como met√°fora** ‚Üí sobrefiltra atributos v√°lidos (20-30% false negatives).

**Adem√°s NO detecta met√°foras sin marcador**:
- "Era un muro de hielo" (frialdad emocional)
- "Ten√≠a fuego en los ojos" (intensidad)
- "Su coraz√≥n era de piedra"

**Comportamiento actual**: Si detecta met√°fora ‚Üí **filtra completamente** el atributo:

```python
if is_metaphor and self.filter_metaphors:
    continue  # SKIP THE ATTRIBUTE ENTIRELY
```

**Fix gen√©rico**: Desambiguar `como` con POS tags (`token.dep_` == `mark` + `head.pos_` == `VERB` ‚Üí temporal/condicional, no met√°fora). Reducir confianza en vez de filtrar (`confidence *= 0.6`). Usar distancia sem√°ntica para detectar met√°foras impl√≠citas.

---

## NLP-M3 [MAYOR]: Pro-drop incompleto

**Ubicaci√≥n**: `src/narrative_assistant/nlp/coreference_resolver.py:57`

```python
ZERO = "zero"  # Sujeto omitido (pro-drop)
```

`MentionType.ZERO` est√° definido pero la resoluci√≥n real es m√≠nima. En espa√±ol el sujeto se omite constantemente:

```
"Entr√© en la habitaci√≥n. Vi una carta. Le√≠ r√°pidamente.
Guard√© en el bolsillo. Sal√≠ corriendo."

‚Üí Todos los predicados: [Yo] Entr√©, [Yo] Vi, [Yo] Le√≠, [Yo] Guard√©, [Yo] Sal√≠
‚Üí 5 menciones pro-drop del narrador en primera persona
‚Üí Sistema actual: probablemente trata cada verbo como desconectado
```

**Fix gen√©rico**: Implementar resoluci√≥n desde morfolog√≠a verbal:

```python
def detect_pro_drop_subject(token):
    person = token.morph.get("Person")  # [1, 2, 3]
    number = token.morph.get("Number")  # [Sing, Plur]
    if person and number:
        return create_zero_pronoun(person, number, token)
```

---

## NLP-M4 [MAYOR]: No distingue discurso directo/indirecto/libre

**Ubicaci√≥n**: `src/narrative_assistant/nlp/dialogue.py`

El sistema detecta formato de di√°logo (rayas, comillas) pero no clasifica tipo de speech:

| Tipo | Ejemplo | Confianza emocional |
|---|---|---|
| Directo | Mar√≠a dijo: "Ir√© ma√±ana." | Alta ‚Äî voz real del personaje |
| Indirecto | Mar√≠a dijo que ir√≠a ma√±ana. | Baja ‚Äî filtrado por narrador |
| Libre indirecto | ¬øIr√≠a ma√±ana? | Media ‚Äî voz ambigua |
| Narrativizado | Mar√≠a prometi√≥ volver. | Muy baja ‚Äî acci√≥n, no habla |

**Impacto**: Coherencia emocional analiza speech reportado como si fuera di√°logo directo ‚Üí falsos positivos con narrador neutral.

**Fix gen√©rico**: Clasificar tipo de speech (marcas de cita ‚Üí directo, verbo + "que" ‚Üí indirecto, pregunta sin atribuci√≥n ‚Üí libre, verbo de comunicaci√≥n sin cita ‚Üí narrativizado). Ajustar peso de an√°lisis emocional por tipo.

---

## NLP-M5 [MAYOR]: No detecta narrador no fiable

**Ubicaci√≥n**: Sistema completo (no hay m√≥dulo)

```
Narrador: "No estaba nervioso."
Descripci√≥n: Sudaba, tartamudeaba, temblaba.
‚Üí Pipeline marca: INCONSISTENCIA ‚úó
‚Üí Realidad: T√©cnica narrativa deliberada ‚úì
```

Inconsistencias intencionales (narrador poco fiable, iron√≠a dram√°tica, autoenga√±o del personaje) se marcan como errores del manuscrito.

**Manuscritos afectados**: Lolita, Fight Club, cualquier primera persona con autoenga√±o.

**Fix gen√©rico**: Detectar marcadores de incertidumbre ("creo que", "quiz√°", "no recuerdo exactamente"), distancia temporal, limitaciones cognitivas. Flag como "posible t√©cnica narrativa" en vez de error.

---

## NLP-M6 [MAYOR]: Coherencia emocional r√≠gida

**Ubicaci√≥n**: `src/narrative_assistant/analysis/emotional_coherence.py:75-250`

```python
# Mapeo hardcodeado ‚Äî emoci√≥n ‚Üí sentimiento esperado
EMOTION_SENTIMENT_MAP = {
    "furioso": {"negative"},     # SOLO negativo
    "feliz": {"positive"},       # SOLO positivo
    "triste": {"negative", "neutral"},
}
```

**Problemas**:
1. No detecta rabia fr√≠a: "Esc√∫chame bien. No te vuelvo a hablar de esto." ‚Üí tono controlado pero personaje furioso = coherente en literatura
2. No detecta enmascaramiento: personaje finge felicidad frente al jefe
3. Solo marcadores expl√≠citos de iron√≠a ("dijo con iron√≠a"), no impl√≠citos
4. Ventana de proximidad 500 chars demasiado peque√±a
5. Speaker matching exacto (case-sensitive)
6. No considera distancia temporal (furioso ‚Üí calmado 2 horas despu√©s = natural)

**Fix gen√©rico**: Expandir patrones (usar LLM para an√°lisis contextual), ampliar ventana a 1500 chars, matching fuzzy de speakers, considerar distancia temporal entre declaraci√≥n y di√°logo.

---

## NLP-M7 [MAYOR]: Fusi√≥n de acentos incompleta

**Ubicaci√≥n**: `src/narrative_assistant/entities/fusion.py:552-588`

`_name_similarity()` normaliza acentos, pero el path principal de `canonical_name` no:

```python
# Entity creation ‚Äî NO normaliza acentos
canonical_name = name.lower()  # "mar√≠a" ‚â† "maria"
```

Resultado: "Mar√≠a" y "Maria" (error OCR com√∫n) ‚Üí dos entidades separadas. Afecta ~30% de nombres espa√±oles.

**Fix gen√©rico**: Normalizar acentos al crear canonical_name con `unicodedata.normalize('NFKD')` + strip combining chars. A√±adir variante sin acento como alias autom√°ticamente.

---

## NLP Moderados (resumen detallado)

### NLP-m1: Voseo no soportado
- `voice/profiles.py:34` reconoce "vos" como informal pero no valida conjugaciones voseo
- "vos habl√°s" podr√≠a flaggearse como error gramatical (deber√≠a ser v√°lido en espa√±ol rioplatense)
- Fix: Implementar paradigma de conjugaci√≥n voseo; a√±adir modo regional a grammar checker

### NLP-m2: Le√≠smo/la√≠smo muy b√°sico
- `spanish_rules.py:443-609` trata todo como error sin distinguir variantes regionales
- "Le vi a Juan" es le√≠smo aceptado en Espa√±a
- Fix: Base de datos socioling√º√≠stica con gradaci√≥n (est√°ndar/regional/dialectal/error)

### NLP-m3: Atribuci√≥n de di√°logo ambigua en multi-speaker
- `dialogue.py:59-62` extrae speaker_hint pero no maneja m√∫ltiples turnos en un p√°rrafo
- "‚Äî¬øC√≥mo est√°s? ‚ÄîBien, ¬øy t√∫? ‚ÄîTambi√©n bien," dijo Mar√≠a. ‚Üí ¬øqui√©n dice qu√©?
- Fix: Tracking de turnos de di√°logo; action beats como indicadores de cambio de speaker

### NLP-m4: Filtro condicional incompleto
- `attributes.py:1076` ‚Äî CONDITIONAL_INDICATORS no incluye: "si fuese" (arcaico), "aunque fuere" (futuro subj.), "supongamos que", "a menos que"
- Fix: Expandir lista; usar detecci√≥n de modo subjuntivo de spaCy

### NLP-m5: Indicadores temporales pasados limitados
- `attributes.py:991-1002` ‚Äî faltan: "antes era", "otrora", "sol√≠a", "en aquel entonces", "tiempo atr√°s", "anta√±o", "acostumbraba a"
- "Antes era un excelente violinista" ‚Üí "violinista" extra√≠do como atributo PRESENTE
- Fix: Expandir TEMPORAL_PAST_INDICATORS; detectar imperfecto como indicador de estado pasado

### NLP-m6: No valida concordancia morfol√≥gica en atributos
- "El personaje era altas y rubios" ‚Üí no se detecta mismatch g√©nero/n√∫mero
- Fix: Verificar concordancia adjetivo-sustantivo en extracci√≥n de atributos

### NLP-m7: Elipsis y fragmentos no detectados
- "‚Äî¬øOjos azules? ‚ÄîS√≠. Ojos verdes." ‚Üí fragmentos sin sujeto
- Fix: Detectar fragmentos (<3 palabras, sin verbo principal); marcar atributos con confianza reducida

### NLP-m8: "se" impersonal no manejado
- "Se encontr√≥ el cad√°ver. Sus heridas..." ‚Üí "sus" se refiere a qui√©n?
- Fix: Detectar construcci√≥n impersonal con "se"; manejar resoluci√≥n pronominal diferente

### NLP-m9: Detecci√≥n de modo subjuntivo ausente
- "No creo que sea alto" ‚Üí "alto" extra√≠do como atributo real (deber√≠a ser hipot√©tico)
- "Si fuera rico..." ‚Üí "rico" extra√≠do como real
- Fix: Detectar modo subjuntivo desde `token.morph`; marcar atributos en subjuntivo como hipot√©ticos

### NLP-m10: Cl√≠ticos encl√≠ticos incompletos
- `ner.py:1503-1514` ‚Äî ENCLITIC_SUFFIXES tiene "me", "te", "le", etc. pero falta "sela", "selo", combinaciones con gerundio ("d√°ndosela")
- Fix: Expandir combinaciones; detectar accent shifts en gerundio+cl√≠tico

---

# Panel 2: AI + Arquitecto + BE

**17 issues** (4 cr√≠ticos, 4 altos, 5 medios, 4 bajos)

---

## ARCH-C1 [CR√çTICO]: Fases fallan silenciosamente

**Ubicaci√≥n**: `src/narrative_assistant/pipelines/unified_analysis.py` ‚Äî flujo completo de fases

**Flujo actual**:
```python
def analyze(...) -> Result[UnifiedReport]:
    context = AnalysisContext()  # Todo en memoria

    # Phase 1: Parse ‚Üí resultados solo en memoria
    # Phase 2: NER ‚Üí resultados solo en memoria
    # Phase 3: Coreference ‚Üí FALLA ‚Üí context.entities = []
    # Phase 4: Attributes ‚Üí recibe entities vac√≠o ‚Üí 0 atributos
    # Phase 5: Quality ‚Üí recibe atributos vac√≠os ‚Üí 0 issues
    # Phase 6: Consistency ‚Üí recibe vac√≠o ‚Üí "No inconsistencies found"

    return Result.success(report)  # ‚Üê "√âxito" con datos corruptos
```

**Impacto**: El usuario recibe "An√°lisis completo: 0 problemas encontrados" cuando en realidad la pipeline crashe√≥ internamente. Datos corruptos propagados como verdad.

**Fix gen√©rico**: Precondiciones verificables por fase:

```python
class Phase(ABC):
    @abstractmethod
    def validate_preconditions(self, context: AnalysisContext) -> Result[None]:
        """Verificar que los datos necesarios existen."""
        pass

class NERPhase(Phase):
    def validate_preconditions(self, context):
        if not context.full_text:
            return Result.failure(NarrativeError("Texto del documento vac√≠o"))
        return Result.success(None)

class AttributePhase(Phase):
    def validate_preconditions(self, context):
        if not context.entities:
            return Result.failure(NarrativeError("No hay entidades ‚Äî NER fall√≥"))
        return Result.success(None)
```

Checkpointing a DB tras cada fase. Error handling granular. Informe parcial si una fase falla.

---

## ARCH-C2 [CR√çTICO]: Acumulaci√≥n de memoria sin l√≠mite

**Ubicaci√≥n**: Pipeline completa

4 extractores √ó N cap√≠tulos generan listas en memoria sin l√≠mite. Para novela larga:

```
4 extractores √ó 500 cap√≠tulos ‚Üí potencial 180K atributos en memoria
Coherencia emocional: O(n¬≤) comparando p√°rrafos
Consistency check: all-pairs comparison
```

**Extrapolaci√≥n**:
| Documento | Tama√±o | Tiempo estimado | Memoria |
|---|---|---|---|
| 2-6 KB | Evaluaci√≥n | 100-130s | Aceptable |
| 50 KB | Cuento | ~33 min | Alta |
| 100 KB | Novela corta | ~67 min | Muy alta |
| 500 KB | Novela | ~5.5 horas | OOM probable |

**Fix gen√©rico**: Streaming/chunked processing; flush a DB tras cada cap√≠tulo; lazy loading; `BoundedList` con max_size:

```python
class BoundedList(list):
    def __init__(self, max_size=10000):
        self.max_size = max_size
    def append(self, item):
        if len(self) >= self.max_size:
            logger.warning(f"List full (max {self.max_size})")
            return
        super().append(item)
```

---

## ARCH-C3 [CR√çTICO]: Exception handler gen√©rico

**Ubicaci√≥n**: `unified_analysis.py` ‚Äî wrapper principal

Un solo `except Exception` envuelve las 6 fases. Si Phase 3 falla:

```
"Unexpected error"
‚Üí Sin indicar QU√â fase fall√≥
‚Üí Sin indicar QU√â datos se perdieron
‚Üí Sin indicar QU√â acci√≥n tomar
```

**Fix gen√©rico**: Try/except por fase con errores tipados; log de fase+contexto+stack trace; recovery parcial que devuelve lo que s√≠ funcion√≥.

---

## ARCH-C4 [CR√çTICO]: Race condition en entity_map

**Ubicaci√≥n**: `unified_analysis.py` ‚Äî Phase 3-4 con ThreadPoolExecutor

```python
# Phase 4: 4 extractores en paralelo
with ThreadPoolExecutor(max_workers=4) as executor:
    futures = {
        executor.submit(RegexExtractor(...).extract, context): "regex",
        executor.submit(DependencyExtractor(...).extract, context): "dependency",
        executor.submit(EmbeddingsExtractor(...).extract, context): "embeddings",
        executor.submit(LLMExtractor(...).extract, context): "llm",
    }
```

Todos acceden a `context.entity_map` sin locks. Comportamiento no determinista ‚Üí atributos asignados a entidad equivocada a veces s√≠, a veces no.

**Fix gen√©rico**: Inmutabilizar output de cada fase antes de pasar a la siguiente (`frozenset`, `MappingProxyType`). O usar locks en shared state.

---

## ARCH-H1 [ALTO]: `_extract_attributes()` retorna `None`

No propaga errores; caller asume √©xito. Fases posteriores trabajan con datos vac√≠os sin saberlo.

**Fix gen√©rico**: Usar Result pattern consistentemente:
```python
def _extract_attributes(self, context) -> Result[list[ExtractedAttribute]]:
    # ... en vez de retornar None
```

---

## ARCH-H2 [ALTO]: Dos sistemas de tipos de atributos

`AttributeCategory` (viejo) y `AttributeType` (nuevo) coexisten. Queries a DB no encuentran atributos si usan el enum equivocado.

**Fix gen√©rico**: Unificar a un solo sistema; migraci√≥n de datos existentes.

---

## ARCH-H3 [ALTO]: Coherencia emocional nunca se ejecuta

`run_emotional=True` en config pero `_extract_emotional()` no se invoca en ninguna fase. Feature completa ‚Üí dead code.

**Fix gen√©rico**: Wiring correcto en pipeline; test de integraci√≥n que verifique que config flags activan fases.

---

## ARCH-H4 [ALTO]: Campos de cap√≠tulo inconsistentes

```python
ch["number"]                    # A veces
ch.get("number", 1)            # Otras veces
ch.get("end_char", float("inf"))  # Otras veces
```

No hay modelo de datos de cap√≠tulo. Menciones asignadas a cap√≠tulo incorrecto.

**Fix gen√©rico**: Crear dataclass `Chapter` con campos tipados:
```python
@dataclass
class Chapter:
    number: int
    title: str
    start_char: int
    end_char: int
```

---

## ARCH-m1 [MEDIO]: Carga de modelo spaCy repetida en extractores paralelos

**Ubicaci√≥n**: `src/narrative_assistant/nlp/extraction/pipeline.py:109-114`

```python
class BaseExtractor:
    @property
    def nlp(self):
        if self._nlp is None:
            self._nlp = load_spacy_model()  # ‚Üê Cada extractor carga el suyo
        return self._nlp
```

4 extractores en paralelo ‚Üí 4 copias del modelo (4 √ó 500 MB = 2 GB).

**Fix**: Singleton compartido con double-checked locking.

---

## ARCH-m2: No hay checkpointing entre fases

Si Phase 5 falla tras 30 minutos de an√°lisis, se pierde todo el trabajo de Phase 1-4.

**Fix**: Guardar checkpoint a DB tras cada fase completada; implementar resume-on-crash.

---

## ARCH-m3: Magic numbers sin documentar

400 chars (ventana atributos), 0.4 (threshold validaci√≥n NER), 500 chars (ventana emocional) ‚Äî todos hardcodeados sin nombre ni config.

**Fix**: Extraer a constantes nombradas en config.

---

## ARCH-m4: API server sin rate limiting

Sin l√≠mites de tama√±o de request ni rate limiting. Upload de archivo de 10 GB ‚Üí servidor se congela.

---

## ARCH-m5: SQLite WAL sin vacuum autom√°tico

DB crece indefinidamente sin cleanup.

---

## ARCH-b1 [BAJO]: No hay validaci√≥n de nombres de entidad

Entidades se crean sin validar que `canonical_name` no sea vac√≠o, None, o demasiado largo.

---

## ARCH-b2 [BAJO]: FK constraints inconsistentes en SQLite

`PRAGMA foreign_keys = ON` solo en algunos code paths.

---

## ARCH-b3 [BAJO]: Tabla `attribute_evidences` nunca se llena

Schema existe pero nada la popula. Evidencias textuales de atributos no se guardan.

---

## ARCH-b4 [BAJO]: Config no se auto-valida

`run_attributes=True` + `run_ner=False` = atributos sin entidades. No hay validaci√≥n de coherencia de config.

---

# Panel 3: UX + FE + Editor

**20 issues**, organizados por impacto editorial

---

## UX-C1 [CR√çTICO]: No hay edici√≥n inline desde alertas

Editor debe context-switch constantemente entre lista de alertas y texto del manuscrito. En herramientas est√°ndar (Word, Scrivener), el corrector trabaja directamente sobre el texto.

**Impacto**: ~25 minutos extra por manuscrito.

**Fix gen√©rico**: Click en alerta ‚Üí scroll al texto con highlight. Bot√≥n "Ver en contexto":

```typescript
function navigateToLocation() {
  emit('navigate-to-location', {
    chapter: alert.chapter,
    startChar: alert.spanStart,
    endChar: alert.spanEnd,
    excerpt: alert.excerpt
  })
}
```

---

## UX-C2 [CR√çTICO]: No hay comparaci√≥n lado a lado

Inconsistencia "ojos verdes cap 2 vs azules cap 5" ‚Üí editor debe navegar manualmente entre ambos cap√≠tulos para verificar.

**Impacto**: 30-60 segundos por cada inconsistencia para verificar.

**Fix gen√©rico**: Vista split con ambas referencias side by side. Componente `AttributeComparisonTable`:

```typescript
// Agrupar por valor ‚Äî mostrar cada variante con sus menciones
const groupedByValue = computed(() => {
  const groups = new Map<string, AlertSource[]>()
  sources.value.forEach(source => {
    const key = source.value
    if (!groups.has(key)) groups.set(key, [])
    groups.get(key)!.push(source)
  })
  return groups
})
```

Tabla con: Valor | Menciones | Cap√≠tulos | Confianza | Contexto (con bot√≥n "Ver").

---

## UX-C3 [CR√çTICO]: Confidence threshold no configurable en UI

No hay slider ni filtro para nivel de confianza. Imposible reducir ruido de falsos positivos.

**Fix gen√©rico**: A√±adir a workspace store:

```typescript
const alertConfidenceThreshold = ref(0.3)
function setAlertConfidenceThreshold(value: number) {
  alertConfidenceThreshold.value = value
  localStorage.setItem('alertConfidenceThreshold', String(value))
}
```

Slider en panel de alertas.

---

## UX-C4 [CR√çTICO]: No hay "scroll to text" desde alertas

Alerta muestra posici√≥n pero no navega. 30-60s por alerta buscando manualmente.

**Fix gen√©rico**: Bot√≥n "Ver en contexto" que navega y resalta.

---

## UX-FP1 [ALTO]: No aprende de dismissals

Descartar alerta ‚Üí re-an√°lisis ‚Üí misma alerta generada otra vez ‚Üí loop infinito.

**Fix gen√©rico**: Persistir dismissals en DB; excluir de futuros an√°lisis; opci√≥n de "suprimir regla":

```python
class FeedbackTracker:
    def record_dismissal(self, alert_type: str, confidence: float):
        metrics = self.metrics[alert_type]
        metrics.dismissed += 1
        metrics.total_generated += 1
        fp_rate = metrics.false_positive_rate
        if fp_rate > 0.5:
            logger.warning(f"'{alert_type}' tiene {fp_rate:.0%} false positives")
```

---

## UX-FP2 [ALTO]: No hay whitelisting/suppression rules

No puedes decir "ignora variantes Mar√≠a/Maria para entidad #3".

**Fix gen√©rico**: Reglas de supresi√≥n por entidad, por tipo de alerta, por cap√≠tulo.

---

## UX-FP3 [ALTO]: No hay m√©tricas de precisi√≥n

No se trackean aceptaciones vs dismissals. No sabes qu√© detectores tienen 90% accuracy vs 20%.

**Fix gen√©rico**: Dashboard con acceptance rate por tipo de detector.

---

## UX Estado y Responsividad

### UX-m1: Filtros de alertas se resetean al navegar
State no persiste al cambiar de tab/vista.

### UX-m2: Di√°logos con `width: '450px'` hardcodeado
Overflow en pantallas peque√±as/m√≥vil.

### UX-m3: No hay breakpoints responsive
Componentes de alertas no se adaptan.

---

## UX Features Ausentes para Editor Profesional

| ID | Feature | Descripci√≥n |
|---|---|---|
| UX-f1 | Heatmap por cap√≠tulo | Estad√≠sticas de alertas por cap√≠tulo ‚Äî visualizar d√≥nde se concentran los problemas |
| UX-f2 | Operaciones batch | Resolver/descartar m√∫ltiples alertas de una vez |
| UX-f3 | Modo review secuencial | Navegar alertas con keyboard shortcuts (‚Üê‚Üí anterior/siguiente, Enter resolver, Esc descartar) |
| UX-f4 | Vista timeline | Timeline integrado con alertas temporales |
| UX-f5 | Presets por g√©nero | Ficci√≥n/no-ficci√≥n/t√©cnico ‚Üí umbrales y detectores diferentes |
| UX-f6 | Export a Word | Alertas como comentarios de Word para compartir con autores |

---

## Evaluaci√≥n general del panel UX+FE+Editor

| Aspecto | Score |
|---|---|
| Arquitectura frontend | ‚≠ê‚≠ê‚≠ê‚≠ê (Vue 3 + Pinia + TypeScript + PrimeVue) |
| Tipo safety | ‚≠ê‚≠ê‚≠ê‚≠ê (API types separados de domain types con transformers) |
| Experiencia de usuario | ‚≠ê‚≠ê (funcional pero no profesional) |
| Preparaci√≥n para editor profesional | ‚≠ê‚≠ê (falta feedback loop, navegaci√≥n, batch) |
| Responsividad | ‚≠ê (roto en m√≥vil) |
| Testing frontend | ‚≠ê‚≠ê (stores testeados, componentes no) |
| Accesibilidad | ‚≠ê‚≠ê‚≠ê‚≠ê (ARIA labels, sem√°ntico ‚Äî buena base) |

---

# Panel 4: PO + QA

**Hallazgos detallados del Product Owner y QA Lead**

---

## QA: Cobertura de tests

### Infraestructura de tests

```
tests/
‚îú‚îÄ‚îÄ unit/          (35 archivos, ~12K l√≠neas, ~600 tests)
‚îú‚îÄ‚îÄ adversarial/   (22 archivos, ~18K l√≠neas, ~1.200 tests)
‚îú‚îÄ‚îÄ integration/   (5 archivos, ~3K l√≠neas, ~200 tests)
‚îú‚îÄ‚îÄ evaluation/    (2 archivos)
‚îî‚îÄ‚îÄ regression/    (1 archivo)
Total: 2.346 tests en 63 archivos
```

### Tests con buena cobertura

| Archivo | Tests | Calidad |
|---|---|---|
| `test_chapter_summary.py` (26 KB) | 80+ | Exhaustivo |
| `test_character_location.py` (29 KB) | 100+ | Exhaustivo |
| `test_attributes.py` (19 KB) | 65+ | Shallow |
| `test_relationships.py` (24 KB) | 85+ | Bueno |
| `test_consistency.py` (19 KB) | 70+ | Bueno |
| `test_readability.py` (22 KB) | 80+ | Bueno |
| `test_pacing.py` (23 KB) | 90+ | Bueno |
| `test_vital_status.py` (28 KB) | 60+ | Bueno |

### Tests con cobertura d√©bil (smoke tests)

| Archivo | Tests | Problema |
|---|---|---|
| `test_ner.py` (5.3 KB) | **13** | NER apenas testeado ‚Äî m√≥dulo cr√≠tico |
| `test_coreference.py` (7.3 KB) | **7** | Correferencia voting system apenas testeado |
| `test_parsers.py` (5.6 KB) | **8** | Solo TXT/DOCX, no EPUB/PDF |
| `test_orthography.py` (8.9 KB) | ~25 | M√≠nimo para spelling/grammar |

### M√≥dulos sin tests (0 cobertura)

| M√≥dulo | Tama√±o | Riesgo |
|---|---|---|
| `character_knowledge.py` | 55 KB | üî¥ MUY ALTO ‚Äî l√≥gica compleja, no probada |
| `semantic_fusion.py` | ‚Äî | üî¥ Fusi√≥n sem√°ntica de entidades |
| `character_sheets.py` | 60 KB | üî¥ Exportador no validado |
| `scrivener_exporter.py` | 33 KB | üî¥ Probablemente genera XML inv√°lido |
| `pdf_parser.py` | 25 KB | üî¥ Declarado soportado pero sin test |
| `epub_parser.py` | 20 KB | üî¥ Declarado soportado pero sin test |
| `register.py` | ~400 l√≠neas | üî¥ An√°lisis de registro |
| `story_bible.py` | 13 KB | üü† |

### Edge cases no cubiertos

**Documentos extremos**:
- ‚ùå Archivo vac√≠o (0 bytes)
- ‚ùå Solo whitespace
- ‚ùå Una sola palabra/oraci√≥n
- ‚ùå Solo di√°logo (sin narraci√≥n)
- ‚ùå Solo narraci√≥n (sin di√°logo)
- ‚ùå Novela 500+ p√°ginas (500 KB+)
- ‚ùå Documento con miles de personajes
- ‚ùå Cap√≠tulo √∫nico >100 KB

**Idioma**:
- ‚ùå Espa√±ol + ingl√©s mezclado (muy com√∫n en LatAm)
- ‚ùå Espa√±ol medieval/arcaico
- ‚ùå Dialectos m√∫ltiples mezclados
- ‚ùå Poes√≠a (saltos de l√≠nea no est√°ndar)
- ‚ùå Narrativa experimental (fragmentada, no lineal)
- ‚ùå Documentos con HTML/XML embebido

**Personajes**:
- ‚ùå Mismo nombre para distintos personajes (homonimia)
- ‚ùå Nombres de una letra (X, Z, A)
- ‚ùå Nombres fant√°sticos nunca en datos de entrenamiento
- ‚ùå Nombres con part√≠culas ("Mar√≠a de los √Ångeles")

**Di√°logo**:
- ‚ùå Di√°logo anidado (di√°logo dentro de di√°logo)
- ‚ùå Estilos de cita mezclados (‚Äî con ¬´¬ª)
- ‚ùå M√∫ltiples hablantes en un p√°rrafo
- ‚ùå Di√°logo que cruza p√°rrafos
- ‚ùå Mon√≥logo interior vs di√°logo hablado

**Temporal**:
- ‚ùå Narrativa no lineal (flashbacks intercalados)
- ‚ùå Marcadores temporales vagos ("pronto", "tiempo despu√©s")
- ‚ùå Formatos de fecha conflictivos
- ‚ùå Tiempo circular (final = inicio)

**Formatos**:
- ‚ùå DOCX con tablas embebidas
- ‚ùå DOCX con headers/footers
- ‚ùå DOCX con notas al pie
- ‚ùå DOCX con tracked changes
- ‚ùå PDF con texto en imagen (OCR)
- ‚ùå PDF con columnas m√∫ltiples
- ‚ùå EPUB2 vs EPUB3

### Tests de integraci√≥n ‚Äî lo que falta

```
‚ùå Documento grande (100+ KB) end-to-end
‚ùå Validaci√≥n de consistencia multi-cap√≠tulo
‚ùå Exportaci√≥n que preserve estructura de input
‚ùå Recovery de errores (NER falla a mitad)
‚ùå An√°lisis concurrente (thread-safe state)
‚ùå An√°lisis incremental (documento actualizado)
‚ùå Cache invalidation (documento cambiado)
‚ùå Pipeline con todas las features on vs off
```

### Riesgo de regresi√≥n por m√≥dulo

| M√≥dulo | Riesgo | Tests | Raz√≥n |
|---|---|---|---|
| Coreference resolver (2000+ l√≠neas) | üî¥ MUY ALTO | 7 tests | Voting system complejo, sin tests sistem√°ticos |
| NER (500+ l√≠neas) | üî¥ MUY ALTO | 13 tests | Crea entidades basura, sin validaci√≥n post-NER |
| Attributes (800+ l√≠neas) | üü† ALTO | 65 tests (shallow) | 47% recall, misatribuci√≥n conocida |
| Spelling checker (300+ l√≠neas) | üü† ALTO | ~25 tests | Falsos positivos de regex |
| Temporal (400+ l√≠neas) | üü† ALTO | ~30 tests | Deshabilitado por defecto, 0% accuracy |

---

## PO: Feature Completeness ‚Äî MVP vs Realidad

### Definici√≥n de MVP (12 capabilities) vs Estado Actual

| # | Capability | Implementado | Calidad | ¬øFunciona? |
|---|---|---|---|---|
| 1 | Parser DOCX | ‚úÖ | Buena | ‚úÖ S√ç |
| 2 | Detecci√≥n de estructura | ‚úÖ | Regular | ‚ö†Ô∏è PARCIAL (83% precision) |
| 3 | Pipeline NER | ‚úÖ | Pobre | ‚ùå NO (entidades falsas) |
| 4 | Detecci√≥n de di√°logo | ‚úÖ | Buena | ‚úÖ S√ç |
| 5 | Correferencia b√°sica | ‚úÖ | Rota | ‚ùå NO (bug de par√°metros) |
| 6 | Fusi√≥n manual de entidades | ‚úÖ | Buena | ‚úÖ S√ç |
| 7 | Extracci√≥n de atributos | ‚úÖ | Pobre | ‚ùå NO (47% recall) |
| 8 | Inconsistencias de atributos | ‚úÖ | Pobre | ‚ùå NO (13% recall) |
| 9 | Motor de alertas | ‚úÖ | Regular | ‚ö†Ô∏è PARCIAL |
| 10 | Variantes graf√≠a | ‚ö†Ô∏è Parcial | Pobre | ‚ùå NO (sin merge acentos) |
| 11 | Export gu√≠a de estilo | ‚úÖ | Desconocida | ‚ùå SIN TESTAR |
| 12 | CLI | ‚úÖ | Buena | ‚úÖ S√ç |

**Resultado: 9/12 implementadas, 3-4/12 funcionando bien = 25% del MVP funcional**

### Soporte de formatos de documento

| Formato | README dice | Testeado | Estado real |
|---|---|---|---|
| DOCX | Prioritario | ‚úÖ S√≠ | ‚úÖ Producci√≥n |
| TXT | Soportado | ‚úÖ S√≠ | ‚úÖ Producci√≥n |
| MD | Soportado | ‚ö†Ô∏è M√≠nimo | ‚ö†Ô∏è Funciona como TXT |
| PDF | Soportado | ‚ùå No | ‚ùå Probablemente roto |
| EPUB | Soportado | ‚ùå No | ‚ùå Probablemente roto |

**README anuncia 5 formatos, solo 2-3 realmente testeados.**

### Cobertura de g√©neros

**Testeados** (archivos `unseen_test_*.txt`):
‚úÖ Ciencia ficci√≥n, novela hist√≥rica, thriller, romance, fantas√≠a, terror, aventuras, drama familiar

**No testeados**:
‚ùå Poes√≠a, escritura t√©cnica, memorias/autobiograf√≠a, guiones, literatura infantil, narrativa experimental, novela epistolar, m√∫ltiples POV, narrador no fiable

### Performance

| Documento | Tama√±o | Tiempo actual | Aceptable |
|---|---|---|---|
| 2-6 KB | Evaluaci√≥n | 100-130s | ‚ùå Lento |
| 50 KB | Cuento | ~33 min | ‚ùå Inaceptable |
| 100 KB | Novela corta | ~67 min | ‚ùå Inaceptable |
| 500 KB | Novela | ~5.5 horas | ‚ùå Imposible |

**Objetivo**: <30 segundos para 50 KB.

### Offline-first ‚Äî Verificaci√≥n

| Componente | Offline | Nota |
|---|---|---|
| Modelos NLP | ‚úÖ tras descarga | Primera vez requiere internet |
| Ollama/LLM | ‚úÖ localhost | Primera vez requiere download |
| Pipeline de an√°lisis | ‚úÖ 100% | Sin conexiones externas |
| Verificaci√≥n licencias | ‚ùå | Requiere online |
| Telemetr√≠a | ‚úÖ No hay | Ninguna |

**Promesa mayormente mantenida** salvo verificaci√≥n de licencias.

### An√°lisis competitivo

| Feature | ProWritingAid | Grammarly | Scrivener | **Este sistema** |
|---|---|---|---|---|
| Grammar/style | Excelente | Avanzado | ‚Äî | Regular |
| Consistencia personajes | No | No | Manual | **Autom√°tico (roto)** |
| Privacidad | Cloud | Cloud | Offline | **Offline** |
| Espa√±ol nativo | Limitado | B√°sico | S√≠ | **Nativo** |
| Precio | $99-199/a√±o | $12-30/mes | $99 √∫nico | Desconocido |

**USP**: Detecci√≥n autom√°tica de inconsistencias + offline + espa√±ol nativo. Pero USP principal no funciona (13% recall).

---

## PO: Criterios de aceptaci√≥n ‚Äî Evaluaci√≥n

| Criterio | Objetivo | Actual | ¬øCumple? |
|---|---|---|---|
| Parser sin perder texto | 100% p√°rrafos | 100% | ‚úÖ |
| Detecci√≥n cap√≠tulos >95% | 95% | 83% | ‚ùå |
| NER F1 ~60-70% ficci√≥n | 60-70% | Desconocido (sospecha <50%) | ‚ùå |
| Inconsistencias atributos >80% recall | 80% | 13% | ‚ùå (-67pp) |
| Inconsistencias temporales funcional | Funcional | 0% (deshabilitado) | ‚ùå |
| 100% offline post-setup | Offline | Mayormente | ‚ö†Ô∏è |
| Correcci√≥n manual NER/coref | Funcional | Funcional | ‚úÖ |
| Export informe DOCX/PDF | Funcional | Sin testar | ‚ùå |

**Solo 2 de 8 criterios cumplidos.**

---

## QA/PO: Estado de producci√≥n

### Madurez del producto

| Dimensi√≥n | Score | Estado |
|---|---|---|
| Calidad de c√≥digo | 6/10 | ‚ö†Ô∏è M√≥dulos grandes sin tests |
| Cobertura de tests | 5/10 | ‚ö†Ô∏è 2.346 tests pero muchos son smoke |
| Documentaci√≥n | 7/10 | ‚úÖ CLAUDE.md excelente, docs usuario faltan |
| Performance | 2/10 | üî¥ 100+ seg para 2-6 KB |
| Accuracy | 3/10 | üî¥ 13% recall en feature core |
| Feature completeness | 6/10 | ‚ö†Ô∏è 9/12 MVP, solo 3-4 funcionando |
| Error handling | 5/10 | ‚ö†Ô∏è Fallos silenciosos, cascada |
| Offline guarantee | 7/10 | ‚úÖ Funciona offline post-setup |
| Escalabilidad | 2/10 | üî¥ No escala m√°s all√° de docs peque√±os |
| Seguridad/Privacidad | 7/10 | ‚úÖ Sin telemetr√≠a, local |
| **TOTAL** | **5.0/10** | **‚ùå NO PRODUCTION READY** |

### Escenarios de release

| Escenario | Timeline | Riesgo | Resultado |
|---|---|---|---|
| Release as-is | Ahora | MUY ALTO | Usuarios frustrados, da√±o reputacional |
| Fix bugs cr√≠ticos ‚Üí Beta | 2-4 semanas | ALTO | Funciona para docs peque√±os, lento pero usable |
| Fix + Test + Optimize ‚Üí 1.0 | 6-12 meses | MEDIO | Production-ready, cumple MVP |

---

# Convergencia Cross-Panel (4 de 4)

Los 4 paneles convergen en los mismos problemas sist√©micos:

## 1. Listas hardcodeadas vs an√°lisis morfol√≥gico

| Panel | Manifestaci√≥n |
|---|---|
| **NLP** | Verbos, met√°foras, pro-drop, subjuntivo ‚Äî todo usa listas est√°ticas de <1% cobertura |
| **Arquitecto** | Magic numbers (400 chars, 0.4 threshold, 500 char window) sin parametrizar |
| **UX** | Confidence no configurable; presets de g√©nero no existen |
| **QA** | Listas incompletas causan falsos positivos que no se capturan en tests |
| **Soluci√≥n gen√©rica** | Migrar a features de spaCy (`pos_`, `morph`, `dep_`); externalizar umbrales a config editable |

## 2. Errores silenciosos entre fases

| Panel | Manifestaci√≥n |
|---|---|
| **NLP** | NER produce entidades basura ‚Üí pipeline las propaga como verdad |
| **Arquitecto** | Fases fallan ‚Üí datos corruptos, `except Exception` global ‚Üí "Unexpected error" |
| **UX** | Usuario no sabe qu√© fall√≥ ni por qu√©; ve "0 problemas" cuando la pipeline crashe√≥ |
| **QA** | 5 bugs cr√≠ticos bloqueantes; tests no validan precondiciones entre fases |
| **Soluci√≥n gen√©rica** | Precondiciones verificables por fase; Result pattern en todo; feedback visual; checkpoints |

## 3. No hay feedback loop

| Panel | Manifestaci√≥n |
|---|---|
| **NLP** | No aprende de correcciones del usuario; no mejora con uso |
| **Arquitecto** | No guarda checkpoints; no hay m√©tricas de rendimiento por fase |
| **UX** | Dismissals no persisten; mismos falsos positivos en cada re-an√°lisis |
| **PO** | No hay m√©tricas de precisi√≥n por detector; no se sabe qu√© funciona bien |
| **Soluci√≥n gen√©rica** | Persistir decisiones; excluir supresiones; m√©tricas por detector; dashboard de accuracy |

## 4. Proximidad textual en vez de scope gramatical

| Panel | Manifestaci√≥n |
|---|---|
| **NLP** | Atributos por chars (400), no por oraci√≥n; no respeta cl√°usulas subordinadas ni aposiciones |
| **Arquitecto** | entity_map race condition por compartir estado mutable entre threads |
| **UX** | No hay "go to text" para que el editor verifique el contexto real |
| **Editor** | Misatribuciones frustran al editor profesional ‚Äî pierde confianza en la herramienta |
| **Soluci√≥n gen√©rica** | Scope basado en `doc.sents` + dep parsing; inmutabilizar outputs; navegaci√≥n a texto |

---

# Debate Inter-Expertos y Lista Final de Soluciones

## Desacuerdos clave del debate

### ¬øPrimero corregir o primero infraestructura?

**Arquitecto**: "Hay que arreglar la propagaci√≥n de errores silenciosos primero. Cada otro fix se invalida si Phase N+1 consume datos vac√≠os silenciosamente."

**Product Owner**: "La accuracy est√° al 13% vs objetivo 80%. Los usuarios no les importa el error handling si la herramienta no encuentra nada."

**QA Lead**: "Sin validaci√≥n de fases, no podemos ni medir si los fixes de NER funcionan. Arreglaremos NER, veremos '0 issues' en tests de integraci√≥n, y perderemos d√≠as descubriendo que la pipeline se trag√≥ los resultados."

**Consenso**: Validaci√≥n de fases primero (r√°pido, desbloquea medici√≥n), luego NER/atributos.

### ¬øExpandir listas o cambiar mecanismo?

**NLP Engineer**: "Las listas de verbos cubren ~200 formas de 20.000+. Hay que usar `token.pos_ == 'VERB'` de spaCy."

**Ling√ºista**: "De acuerdo, pero spaCy tiene debilidades con voseo y subjuntivo. POS como mecanismo principal, pero un peque√±o override set para errores conocidos de spaCy."

**AI/ML Engineer**: "Esto es un patr√≥n que se repite: MISC‚ÜíPER, met√°foras, pro-drop ‚Äî todos sufren lo mismo. Crear una capa centralizada de an√°lisis morfol√≥gico."

**Arquitecto**: "Elegante pero arriesgado. Fix NER primero, probar el patr√≥n, luego propagar."

**Consenso**: Reemplazar listas con spaCy en NER primero, crear m√≥dulo `morpho_utils.py`, propagar despu√©s.

### ¬øQu√© tan lejos ir con scope gramatical?

**Ling√ºista**: "La ventana de 400 chars es fundamentalmente incorrecta. Necesitamos detecci√≥n de l√≠mites de oraci√≥n como m√≠nimo, idealmente parsing de cl√°usulas."

**NLP Engineer**: "L√≠mites de oraci√≥n f√°cil ‚Äî spaCy nos da `doc.sents`. Cl√°usulas mucho m√°s dif√≠cil ‚Äî el dependency parser de spaCy para espa√±ol no es fiable para segmentaci√≥n de cl√°usulas."

**BE**: "Me preocupa performance. Ya tardamos 100-130s."

**AI/ML**: "Sentence-scoped limita el espacio de b√∫squeda. Podr√≠a ser m√°s r√°pido."

**Consenso**: Reemplazar char-window con sentence/paragraph scope. NO intentar clause-level parsing.

### ¬øEl feedback loop ahora o despu√©s?

**PO**: "Persistencia de dismissals es importante para retenci√≥n, pero no arregla accuracy. P2."

**Editor**: "Mis correctores pierden 30% de su tiempo re-descartando alertas ya revisadas. Es un blocker de workflow, no un nice-to-have."

**QA**: "El feedback loop nos da datos. Si los usuarios descartan 80% de alertas de met√°foras, sabemos que ese detector necesita trabajo."

**Consenso**: Persistencia de dismissals a P1. Tuning de thresholds basado en feedback a P2.

---

## Lista Final de Soluciones (Priorizada)

### S-1 [P0]: Validaci√≥n de Fases y Propagaci√≥n de Errores

**Issues que resuelve**: Fases fallan silenciosamente (ARCH-C1), exception handler gen√©rico (ARCH-C3), race condition entity_map (ARCH-C4), mention_count nunca incrementado (NLP-C1), coherencia emocional nunca ejecutada (ARCH-H3)

**Consenso**: 11/11 expertos de acuerdo. Es la base para todo lo dem√°s.

**Qu√© cambia**:
- `unified_analysis.py`: Reemplazar el `try/except Exception` global con validaci√≥n por fase. Cada fase retorna `Result[T]` y valida que su output no est√© vac√≠o antes de pasar a la siguiente
- `core/errors.py`: A√±adir `PhaseError` con `phase_name`, `input_summary`, `output_summary`
- Assertions entre fases: si NER retorna 0 entidades para documento con >100 palabras ‚Üí WARNING
- Fix `mention_count`: trazar por qu√© nunca se incrementa (probablemente fallo silencioso)
- Fix coherencia emocional: config la activa pero pipeline no la llama ‚Üí a√±adir invocaci√≥n
- `threading.Lock` en entity_map para ThreadPoolExecutor (5 l√≠neas)

**Por qu√© gen√©rico**: No arregla ninguna detecci√≥n espec√≠fica. Arregla la infraestructura que permite observar, medir y validar todos los dem√°s fixes.

**Dependencias**: Ninguna. Es la fundaci√≥n.

**Riesgo si se omite**: Cada fix posterior es inverificable. Mejoras en NER podr√≠an funcionar pero producir "0 issues" porque una fase posterior fall√≥ silenciosamente.

---

### S-2 [P0]: Reemplazar Listas Hardcodeadas con An√°lisis Morfol√≥gico de spaCy

**Issues que resuelve**: NER listas de verbos (NLP-C3), MISC‚ÜíPER agresivo (NLP-M1), met√°foras "como" (NLP-M2), pro-drop (NLP-M3), subjuntivo no detectado (NLP-m9), acentos no normalizados (NLP-M7), ~60-70% de falsos negativos de NER

**Consenso**: 10/11. Arquitecto prefiere NER primero y luego propagar (vs todo de golpe).

**Qu√© cambia**:
- **Crear `nlp/morpho_utils.py`**: M√≥dulo centralizado con `is_verb(token)`, `is_proper_noun(token)`, `get_gender(token)`, `get_number(token)`, `get_verb_mood(token)`, `normalize_name(text)`. Fuente √∫nica de verdad para queries morfol√≥gicas.
- **`nlp/ner.py`**: Reemplazar `_is_verb_form()` + listas con `morpho_utils.is_verb()`. Reemplazar MISC‚ÜíPER con check de contexto: solo reclasificar si tiene capitalizaci√≥n de nombre propio Y aparece como sujeto/objeto de verbo "de persona" (hablar, caminar, sentir) determinado por dep parsing.
- **`nlp/ner.py`**: Normalizaci√≥n de acentos en `canonical_name` v√≠a `morpho_utils.normalize_name()`.
- **`nlp/attributes.py`**: Reemplazar l√≥gica de "como = met√°fora" con dep parsing: `como` como `mark` (conjunci√≥n subordinante) o `advmod` (manera) NO es comparaci√≥n. Reducir de flag binario a score de confianza (0.0-1.0).
- **Pro-drop**: Detectar verbos conjugados sin `nsubj` expl√≠cito en el parse ‚Üí flag como pronombre cero ‚Üí resolver usando persona/n√∫mero contra contexto de entidades.

**Por qu√© gen√©rico**: Reemplaza una categor√≠a entera de conocimiento ling√º√≠stico hardcodeado con modelos entrenados de spaCy. Cualquier verbo en cualquier conjugaci√≥n se maneja. Cualquier nuevo patr√≥n de met√°fora se maneja por dep parsing. Escala a todos los m√≥dulos actuales y futuros.

**Dependencias**: S-1 (necesita validaci√≥n de fases para verificar mejoras).

**Riesgo si se omite**: NER sigue al ~13% recall. La herramienta no detecta nombres de personajes que siguen verbos no incluidos en las 200 formas. Met√°foras falso-positivas contin√∫an. Pro-drop (extremadamente com√∫n en espa√±ol) sigue sin resolver.

---

### S-3 [P0]: Resoluci√≥n de Scope Gramatical (Reemplazar Ventanas de Chars)

**Issues que resuelve**: Ventana 400 chars atributos (NLP-C2), ventana 500 chars emocional (NLP-M6), speaker matching exacto, cross-attribution entre entidades, dos enums de atributos (ARCH-H2)

**Consenso**: 11/11. Puede hacerse en paralelo con S-2.

**Qu√© cambia**:
- **Crear `nlp/scope_resolver.py`**: Utilidad con:
  - `sentence_scope(doc, token) -> Span`: oraci√≥n que contiene el token
  - `paragraph_scope(doc, token) -> Span`: tokens entre `\n\n` m√°s cercanos
  - `chapter_scope(chapters, token_idx) -> Chapter`
  - `find_subject_in_scope(doc, token) -> Optional[Span]`: dado un predicado, busca sujeto gramatical por dep tree
- **`nlp/attributes.py`**: Reemplazar TODA vinculaci√≥n entity-atributo basada en proximidad con `scope_resolver.find_subject_in_scope()`. Consolidar los dos enums de atributos en uno solo.
- **Coherencia emocional**: Reemplazar ventana 500 chars con paragraph scope. Speaker matching con `morpho_utils.normalize_name()` (de S-2).

**Por qu√© gen√©rico**: `ScopeResolver` es un componente reutilizable. Cualquier m√≥dulo que necesite "encontrar la entidad relevante para este elemento ling√º√≠stico" lo usa en vez de inventar su propia ventana de chars.

**Dependencias**: S-1. Se beneficia de S-2 pero puede desarrollarse en paralelo.

**Riesgo si se omite**: Cross-contaminaci√≥n de atributos contin√∫a. "Juan era alto. Pedro era bajo." dentro de 400 chars ‚Üí ambas alturas asignadas a ambos. Usuarios pierden confianza.

---

### S-4 [P1]: Persistencia de Dismissals y Framework de Supresi√≥n

**Issues que resuelve**: Dismissals no persisten (UX-FP1), no hay whitelisting (UX-FP2), no hay batch (UX-f2), no hay m√©tricas de precisi√≥n (UX-FP3)

**Consenso**: 10/11. PO inicialmente P2, cambi√≥ a P1 tras argumento del Editor.

**Qu√© cambia**:
- **`persistence/database.py`**: Tabla `dismissals` con `alert_hash`, `scope` (instancia/documento/proyecto/global), `reason`
- **`persistence/dismissal_repository.py`**: CRUD + `is_dismissed()`, `dismiss_batch()`, `get_dismissal_stats()`
- **`unified_analysis.py`**: Post-procesamiento que filtra alertas contra tabla de dismissals
- **API server**: Endpoints REST para dismiss, undismiss, batch dismiss, stats
- **Frontend**: Bot√≥n dismiss por alerta, checkbox batch, toggle "mostrar descartadas"
- **Tabla `suppression_rules`**: Patrones definidos por usuario (ej: "nunca flaggear 'como' en t√≠tulos de cap√≠tulo")

**Por qu√© gen√©rico**: Framework funciona para TODOS los tipos de alerta. No arregla ning√∫n detector ‚Äî hace todos usables. Stats de dismissal informan qu√© detectores mejorar.

**Dependencias**: S-1.

**Riesgo si se omite**: Correctores pierden 30%+ del tiempo re-descartando. Sin datos de qu√© detectores generan m√°s falsos positivos.

---

### S-5 [P1]: Memory Bounds y Procesamiento por Cap√≠tulos

**Issues que resuelve**: Memoria sin l√≠mite (ARCH-C2), performance (parcialmente), OOM en manuscritos largos

**Consenso**: 11/11.

**Qu√© cambia**:
- **`unified_analysis.py`**: Procesamiento cap√≠tulo por cap√≠tulo con paso de merge, en vez de documento completo en memoria
- **`nlp/chunking.py`**: Auditar y asegurar que se usa realmente
- **Monitorizaci√≥n de memoria**: Log de peak memory por fase
- **spaCy batching**: Usar `nlp.pipe()` con `batch_size` de config
- **`entities/fusion.py`**: Asegurar que fusi√≥n cross-chapter funciona

**Dependencias**: S-1, parcialmente S-3.

**Riesgo si se omite**: Herramienta no puede procesar manuscritos reales (novela 300 pags ‚Üí OOM o 30+ min).

---

### S-6 [P1]: Formalizaci√≥n del Modelo de Datos de Cap√≠tulo

**Issues que resuelve**: Chapter es dict sin tipo (ARCH-H4), no hay campo para tipo de speech (NLP-M4), campos inconsistentes

**Qu√© cambia**:
- Crear dataclasses `Chapter`, `Segment`, `SpeechInstance` con campos tipados
- Migrar de `dict` a dataclass en todos los m√≥dulos
- A√±adir `speech_type: Optional[SpeechType]` (DIRECT, INDIRECT, FREE_INDIRECT, NARRATION)

**Dependencias**: Coordinar con S-5.

---

### S-7 [P1]: Infraestructura de Tests para Medir Accuracy NLP

**Issues que resuelve**: 35-40% c√≥digo sin tests, NER 13 tests, correferencia 7 tests, 13% recall sin forma de medir

**Qu√© cambia**:
- Tests unitarios para `morpho_utils.py` (S-2) y `scope_resolver.py` (S-3)
- **Harness de accuracy**: 5-10 pasajes anotados en espa√±ol (500-1000 palabras cada uno) con gold standard para entidades, atributos, met√°foras, speech, inconsistencias
- Harness reporta precision/recall/F1 por detector
- CI falla si recall baja de threshold (inicialmente 30%, subiendo)
- Tests para parsers PDF/EPUB ‚Äî si no funcionan, marcar como no soportados

**Dependencias**: S-1. Se beneficia de S-2/S-3.

---

### S-8 [P2]: Navegaci√≥n y Comparaci√≥n en UI

**Issues que resuelve**: No hay scroll-to-text (UX-C4), no hay side-by-side (UX-C2), confidence no configurable (UX-C3)

**Qu√© cambia**:
- Backend: asegurar que todas las alertas incluyen `start_offset`, `end_offset`
- Frontend: click en alerta ‚Üí scroll + highlight en document viewer
- Vista side-by-side para inconsistencias ("ojos verdes cap 2" vs "ojos azules cap 5")
- Slider de confidence threshold en settings

**Dependencias**: S-1, S-4, S-2.

---

### S-9 [P3]: Detecci√≥n de Narrador No Fiable y Narrativa Avanzada

**Issues que resuelve**: No detecta narrador no fiable (NLP-M5), no distingue discurso libre indirecto (NLP-M4 parcial)

**Qu√© cambia**:
- Detecci√≥n de tipo de speech con dep parsing + marcadores de cita
- Narrador no fiable v√≠a LLM (Ollama) ‚Äî tarea fundamentalmente sem√°ntica
- Marcadores de incertidumbre, distancia temporal, limitaciones cognitivas

**Dependencias**: S-2, S-3, S-5, S-6.

---

## Enfoques RECHAZADOS

| Enfoque | Por qu√© rechazado |
|---|---|
| **Expandir listas de verbos** | Overfit por definici√≥n. 20.000+ formas, cualquier verbo nuevo requiere cambio de c√≥digo. spaCy los maneja todos con 0 mantenimiento. |
| **Regex para desambiguar "como"** | Overfit cl√°sico. Necesitar√≠as 20+ patrones. Un check de dependencia (`token.dep_`) maneja todos los casos. |
| **Aumentar ventana de chars (400‚Üí800)** | Empeora el problema. Mayor ventana = M√ÅS cross-attribution. La proximidad en chars no es proxy de relaci√≥n gramatical. |
| **Analyzer morfol√≥gico custom (sin spaCy)** | Esfuerzo masivo, beneficio marginal. spaCy tiene 97% accuracy POS para espa√±ol. |
| **Usar LLM para todo** | Performance 100-1000x m√°s lento que spaCy. Output no determinista. LLM reservado para tareas sem√°nticas (P3). |
| **Plugin architecture antes de arreglar detectores** | Abstracci√≥n prematura. Primero hacer que funcionen, luego abstraer. |
| **PostgreSQL en vez de SQLite** | Totalmente innecesario. La herramienta corre local. SQLite con WAL es perfecto. |
| **Clause-level parsing** | Dep parser de spaCy para espa√±ol no es fiable para cl√°usulas. Sentence scope es suficiente y confiable para 90%+ de los casos. |

---

## Roadmap de Implementaci√≥n

| Fase | Soluciones | Gate de calidad |
|---|---|---|
| **P0** | S-1 (Validaci√≥n Pipeline), S-2 (An√°lisis Morfol√≥gico), S-3 (Scope Gramatical) | Recall > 40%, sin fallos silenciosos |
| **P1** | S-4 (Dismissals), S-5 (Memory), S-6 (Chapter Model), S-7 (Test Harness) | Manuscrito completo procesable, dismissals funcionando, recall medible |
| **P2** | S-8 (UX Navegaci√≥n) | Workflow de usuario completo |
| **P3** | S-9 (Narrativa Avanzada) | Tipos de speech detectados, integraci√≥n LLM |

**M√©trica clave**: Recall deber√≠a pasar de 13% a >50% tras P0, y >70% tras P1 con el test harness proporcionando medici√≥n continua. El objetivo de 80% es alcanzable en P2 con tuning informado por datos de dismissals de S-4.

---

# Pr√≥ximos Pasos

1. ‚úÖ Revisi√≥n multi-experto completada (4/4 paneles)
2. ‚úÖ Debate inter-expertos completado
3. ‚úÖ Lista final de 9 soluciones gen√©ricas priorizadas
4. ‚è≥ Implementaci√≥n por prioridad (P0 ‚Üí P1 ‚Üí P2 ‚Üí P3)
