# ADR-004: Arquitectura Offline-First

## Estado

**Aceptada** â€” 2025-12-20 (v0.1.0)

## Contexto

**Requisito fundamental**: Privacidad absoluta de los manuscritos.

Los correctores profesionales trabajan con:
- Manuscritos no publicados de autores
- Contenido confidencial (memorias, ensayos sensibles)
- Material sujeto a NDAs (Non-Disclosure Agreements)

**Riesgo inaceptable**: Enviar texto del manuscrito a internet.

AnÃ¡lisis de arquitecturas alternativas:

| Arquitectura | Privacidad | Latencia | Costo | Disponibilidad | Performance |
|--------------|------------|----------|-------|----------------|-------------|
| **Cloud-first** | âŒ Datos en servidor | âš¡ RÃ¡pido | ğŸ’°ğŸ’° Alto | â˜ï¸ Requiere internet | ğŸš€ Escalable |
| **Hybrid** | âš ï¸ Parcial | âš¡ Media | ğŸ’° Medio | â˜ï¸ Requiere internet | ğŸš€ Escalable |
| **Offline-first** | âœ… Total | âš¡âš¡ Muy rÃ¡pido | âœ… Gratis | ğŸ“´ Siempre disponible | ğŸ’» Local |

**Ejemplos de violaciÃ³n de privacidad**:
- **Grammarly**: EnvÃ­a texto completo a servidores en EE.UU. (leak de OpenAI, 2023)
- **Google Docs**: Texto indexado para publicidad (ToS)
- **ChatGPT API**: OpenAI retiene datos 30 dÃ­as (puede entrenar modelos)

**Principio de diseÃ±o**: *"El manuscrito nunca debe salir del ordenador del usuario, bajo ninguna circunstancia."*

## DecisiÃ³n

Implementar arquitectura **offline-first** con los siguientes principios:

### 1. Procesamiento 100% Local

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Tauri App (Escritorio)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frontend Vue 3                â”‚  â”‚
â”‚  â”‚  (localhost:5173 en dev)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚ HTTP (IPC en prod)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI Backend               â”‚  â”‚
â”‚  â”‚  (localhost:8000)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  spaCy + NLP local             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚               â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Ollama (localhost:11434)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  Todo corre en 127.0.0.1             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   ~/.narrative_assistant/
   â”œâ”€â”€ data/projects.db (SQLite local)
   â”œâ”€â”€ models/ (spaCy, embeddings)
   â””â”€â”€ backups/
```

**Todas las conexiones son localhost** â€” nunca se hace request a internet durante el anÃ¡lisis.

### 2. Modelo de Datos Local

- **Base de datos**: SQLite (~/.narrative_assistant/data/projects.db)
- **Modelos NLP**: Cache local (~/.narrative_assistant/models/)
- **Ollama models**: Cache local (~/.ollama/models/)
- **Backups**: Local (~/.narrative_assistant/backups/)

**No hay sincronizaciÃ³n cloud** â€” ni siquiera como opciÃ³n.

### 3. ConexiÃ³n a Internet: Solo Descarga Inicial

Internet se usa ÃšNICAMENTE para:

| Recurso | CuÃ¡ndo | Destino | QuÃ© se envÃ­a |
|---------|--------|---------|--------------|
| **Modelos NLP** | Primera ejecuciÃ³n | HuggingFace Hub | âŒ Nada (solo GET) |
| **Ollama models** | Setup inicial | ollama.com | âŒ Nada (solo GET) |
| **Licencias** | ValidaciÃ³n | *(futuro)* | âŒ Solo hash de activaciÃ³n |

**Nunca se envÃ­a**:
- âŒ Texto del manuscrito
- âŒ Entidades detectadas
- âŒ Alertas o correcciones
- âŒ Metadata del proyecto
- âŒ TelemetrÃ­a o analytics

### 4. ValidaciÃ³n de Seguridad

**AuditorÃ­as obligatorias**:
- âœ… No hay llamadas a `fetch()`, `axios.post()`, `requests.post()` con datos de usuario
- âœ… No hay SDKs de analytics (Google Analytics, Mixpanel, Sentry)
- âœ… No hay auto-updates (actualizaciÃ³n manual controlada por el usuario)
- âœ… Logs solo en disco local, nunca remote logging

**CÃ³digo prohibido**:
```python
# âŒ PROHIBIDO - enviar datos a internet
import requests
requests.post("https://api.example.com", json={"text": manuscript_text})

# âŒ PROHIBIDO - analytics
import analytics
analytics.track("document_analyzed", {"word_count": 50000})

# âŒ PROHIBIDO - remote logging
import sentry_sdk
sentry_sdk.capture_message("Analysis started")
```

**CÃ³digo permitido**:
```python
# âœ… PERMITIDO - descarga de modelos
from huggingface_hub import snapshot_download
snapshot_download("spacy/es_core_news_lg")

# âœ… PERMITIDO - localhost
import requests
requests.get("http://localhost:11434/api/tags")  # Ollama local
```

### 5. Transparencia con el Usuario

- **PRIVACY.md**: Documento claro sobre privacidad
- **UI prominente**: Badge "ğŸ”’ Offline" en interfaz
- **Logs auditables**: Usuario puede revisar logs para verificar que no hay network calls

## Consecuencias

### Positivas âœ…

1. **Privacidad absoluta**: Manuscritos nunca salen del PC, cumple NDAs
2. **Confianza del usuario**: Correctores profesionales pueden usar la herramienta sin riesgo legal
3. **Costo cero**: No hay costos de servidor, base de datos cloud, ni APIs
4. **Latencia mÃ­nima**: Todo corre en localhost (sub-100ms)
5. **Sin vendor lock-in**: Usuario controla sus datos 100%
6. **Funciona sin internet**: Ideal para escribir en lugares sin WiFi (aviones, cafÃ©s)
7. **No hay downtime**: No depende de servidores externos

### Negativas âš ï¸

1. **Requisitos de hardware**:
   - MÃ­nimo 8 GB RAM para modelos NLP
   - 3-6 GB de espacio en disco
   - CPU/GPU suficiente para procesamiento
2. **Setup inicial**:
   - Requiere internet para descargar modelos (~1 GB)
   - Usuario debe instalar Ollama si quiere anÃ¡lisis LLM
3. **Sin colaboraciÃ³n cloud**:
   - No hay "compartir proyecto" entre correctores
   - Backups son responsabilidad del usuario
4. **Performance variable**:
   - Depende del hardware del usuario
   - No hay escalado elÃ¡stico en la nube
5. **Actualizaciones manuales**:
   - Usuario debe descargar e instalar nuevas versiones

### Mitigaciones

- **Instalador self-contained**: Tauri bundle incluye Python embebido + dependencias
- **Auto-descarga de modelos**: `download_models.py` automatiza el setup inicial
- **Fallbacks**: Si LLM no disponible, sistema funciona con heurÃ­sticas
- **Backups automÃ¡ticos**: Sistema crea backups antes de cada anÃ¡lisis
- **DocumentaciÃ³n clara**: Manual de usuario explica requisitos de hardware

## Notas de ImplementaciÃ³n

Ver:
- `PRIVACY.md` â€” polÃ­tica de privacidad (a crear)
- `src/narrative_assistant/core/model_manager.py` â€” descarga de modelos con validaciÃ³n
- `scripts/download_models.py` â€” setup inicial de modelos
- `api-server/main.py` â€” FastAPI corre solo en localhost
- `frontend/src/composables/useApi.ts` â€” todas las llamadas a localhost

**AuditorÃ­a de red**:
```bash
# Verificar que no hay llamadas externas durante anÃ¡lisis
grep -r "https://" src/ frontend/src/ | grep -v "localhost" | grep -v "127.0.0.1"

# Revisar imports de librerÃ­as de analytics
grep -r "sentry\|mixpanel\|analytics\|google-analytics" src/ frontend/

# Verificar que FastAPI solo escucha localhost
grep "uvicorn.run" api-server/main.py
# â†’ host="127.0.0.1" SIEMPRE, nunca 0.0.0.0
```

## Referencias

- [Tauri Security](https://tauri.app/v1/guides/building/security/) â€” Arquitectura offline-first
- [GDPR Compliance](https://gdpr.eu/) â€” Privacidad de datos europeos
- [Grammarly Data Leak (2023)](https://thehackernews.com/2023/02/grammarly-patches-bug-that-exposed.html)
- Implementado desde v0.1.0, auditado en v0.10.9
