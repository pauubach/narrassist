# EvaluaciÃ³n de MÃ©todos NLP - DiscusiÃ³n TÃ©cnica

> **Fecha**: 2026-01-18
> **Participantes**: LingÃ¼ista Computacional, Especialista en IA/NLP
> **Objetivo**: Evaluar precisiÃ³n de cada mÃ©todo y definir configurabilidad

---

## 1. Inventario de MÃ©todos por MÃ³dulo

### 1.1 Correferencias (4 mÃ©todos con votaciÃ³n ponderada)

| MÃ©todo | Peso Actual | Dependencias | Coste Computacional |
|--------|-------------|--------------|---------------------|
| **Embeddings** | 30% | sentence-transformers | Medio (GPU recomendado) |
| **LLM** | 35% | Ollama (llama3.2/mistral/qwen2.5) | Alto (10min en CPU) |
| **MorfosintÃ¡ctico** | 20% | spaCy es_core_news_lg | Bajo |
| **HeurÃ­sticas** | 15% | Ninguna | Muy bajo |

### 1.2 ExtracciÃ³n de Atributos (4 extractores)

| Extractor | PrecisiÃ³n Declarada | Dependencias | Coste |
|-----------|---------------------|--------------|-------|
| **Regex** | 90% | Ninguna | Muy bajo |
| **Dependencias** | 80% | spaCy | Bajo |
| **Embeddings** | 65% | sentence-transformers | Medio |
| **LLM** | 85% | Ollama | Alto |

### 1.3 FusiÃ³n SemÃ¡ntica de Entidades

| MÃ©todo | Umbral Actual | Problema Reportado |
|--------|---------------|-------------------|
| **Embeddings** | 0.82 | Falsos positivos con umbral bajo (0.65-0.75) |

### 1.4 GramÃ¡tica y OrtografÃ­a

| MÃ©todo | Dependencias | Estado |
|--------|--------------|--------|
| **Reglas Python** | spaCy | Habilitado |
| **LanguageTool** | Java (localhost:8081) | Opcional |
| **LLM** | Ollama | Deshabilitado por defecto |

### 1.5 AnÃ¡lisis de Relaciones (4 tÃ©cnicas)

| TÃ©cnica | Peso | Problema |
|---------|------|----------|
| **Co-ocurrencia** | 30% | Superficial (no distingue tipo) |
| **Clustering jerÃ¡rquico** | 25% | Sensible a outliers |
| **Community detection** | 25% | No determinista |
| **Embeddings** | 20% | Contexto limitado |

### 1.6 Coherencia Emocional

| MÃ©todo | Modelo | LimitaciÃ³n |
|--------|--------|------------|
| **Sentimiento** | pysentimiento (BERT) | Sentimiento â‰  EmociÃ³n especÃ­fica |
| **Mapeo manual** | ~100 emociones | Cobertura limitada |

---

## 2. DiscusiÃ³n: LingÃ¼ista vs. Especialista IA

### LINGÃœISTA:

> El problema principal que veo es la **confusiÃ³n entre precisiÃ³n teÃ³rica y precisiÃ³n prÃ¡ctica**.
>
> Por ejemplo, el extractor Regex declara 90% de precisiÃ³n, pero esto asume que los patrones cubren todas las variantes. En espaÃ±ol literario, "ojos de un azul profundo" no matchea con el patrÃ³n `ojos (azules|verdes|marrones)`.
>
> **Propuesta**: Necesitamos medir precisiÃ³n REAL sobre textos literarios espaÃ±oles, no solo sobre casos de prueba sintÃ©ticos.

### ESPECIALISTA IA:

> Correcto. AdemÃ¡s, los **pesos de votaciÃ³n son arbitrarios**. El LLM tiene peso 35% en correferencias, pero:
> 1. EstÃ¡ deshabilitado por defecto (requiere Ollama)
> 2. En CPU tarda 10+ minutos
> 3. Sin Ã©l, los otros 3 mÃ©todos suman solo 65% del peso original
>
> **Problema**: Si el usuario no tiene Ollama, el sistema corre con solo 65% de capacidad efectiva, pero los pesos no se rebalancean.

### LINGÃœISTA:

> Otro problema crÃ­tico: la **normalizaciÃ³n de entidades es incompleta**.
>
> El cÃ³digo actual quita artÃ­culos (`el`, `la`), pero:
> - No maneja posesivos (`mi MarÃ­a` vs `MarÃ­a`)
> - No maneja diminutivos (`Paquito` vs `Paco` vs `Francisco`)
> - No maneja tÃ­tulos profesionales completos (`Dra. GarcÃ­a` vs `la doctora GarcÃ­a`)
>
> Esto explica los falsos positivos de fusiÃ³n reportados.

### ESPECIALISTA IA:

> Y el umbral de fusiÃ³n (0.82) es **demasiado permisivo para embeddings multilingual**.
>
> Los embeddings `paraphrase-multilingual-MiniLM-L12-v2` no estÃ¡n entrenados para nombres propios espaÃ±oles. Pueden dar alta similitud entre:
> - "La alta sensibilidad" (concepto) y "Entender" (verbo)
> - "El problema" y "McGyver" (nombre)
>
> Esto es exactamente lo que reportÃ³ el usuario en `Errores encontrados.md`.

### LINGÃœISTA:

> Para la regla de **dequeÃ­smo**, el problema es claro: el cÃ³digo busca el verbo DESPUÃ‰S del "de que" cuando deberÃ­a buscar ANTES.
>
> "Me di cuenta de que creÃ­a en mÃ­" â†’ El "de que" depende de "darse cuenta", no de "creÃ­a".
>
> La soluciÃ³n es buscar hacia atrÃ¡s en la cadena de dependencias hasta encontrar el verbo regente.

### ESPECIALISTA IA:

> Y para la **detecciÃ³n de entidades**, el problema es que spaCy etiqueta incorrectamente verbos capitalizados como entidades.
>
> "EngullÃ­a el desayuno" â†’ spaCy puede marcar "EngullÃ­a" como MISC porque estÃ¡ al inicio de oraciÃ³n.
>
> **SoluciÃ³n**: Post-filtrar con anÃ¡lisis de POS-tag sobre la oraciÃ³n completa, no solo el token.

---

## 3. Propuesta de EvaluaciÃ³n

### 3.1 Corpus de EvaluaciÃ³n

Para medir precisiÃ³n real, necesitamos un corpus anotado con:

1. **Entidades correctas** (gold standard)
2. **Correferencias correctas**
3. **Atributos correctos con fuentes**
4. **Errores gramaticales conocidos**

**Propuesta**: Usar los archivos de prueba existentes:
- `test_books/prueba_inconsistencias_personajes.txt`
- `test_books/prueba_relaciones_personajes.txt`
- `test_books/manuscrito_prueba_errores.txt`

### 3.2 MÃ©tricas a Medir

| MÃ³dulo | MÃ©trica | FÃ³rmula |
|--------|---------|---------|
| NER | Precision | TP / (TP + FP) |
| NER | Recall | TP / (TP + FN) |
| NER | F1 | 2 * (P * R) / (P + R) |
| Correferencias | MUC/BÂ³/CEAF | EstÃ¡ndar CoNLL |
| Atributos | Precision por tipo | TP_tipo / Total_tipo |
| GramÃ¡tica | Precision | Alertas correctas / Total alertas |
| GramÃ¡tica | Recall | Errores detectados / Errores reales |
| FusiÃ³n | Precision | Fusiones correctas / Fusiones sugeridas |

### 3.3 Plan de Pruebas

#### Fase 1: Crear Gold Standard
1. Tomar 3-5 textos de prueba existentes
2. Anotar manualmente:
   - Entidades (nombre, tipo, posiciÃ³n)
   - Correferencias (cadenas de menciones)
   - Atributos (entidad, clave, valor, posiciÃ³n)
   - Errores gramaticales (tipo, posiciÃ³n, correcciÃ³n)

#### Fase 2: Ejecutar AnÃ¡lisis
1. Correr pipeline completo sobre cada texto
2. Extraer resultados de BD
3. Comparar con gold standard

#### Fase 3: Calcular MÃ©tricas
1. Por mÃ©todo individual
2. Por combinaciÃ³n de mÃ©todos
3. Con/sin LLM
4. Con diferentes umbrales

---

## 4. Configurabilidad Propuesta

### 4.1 DecisiÃ³n: Â¿QuÃ© DEBE ser configurable?

| Componente | Configurable | JustificaciÃ³n |
|------------|--------------|---------------|
| **LLM (Ollama)** | âœ… SÃ­ | Alto coste, requiere instalaciÃ³n |
| **LanguageTool** | âœ… SÃ­ | Requiere Java |
| **Embeddings GPU** | âœ… SÃ­ | No todos tienen GPU |
| **Umbral de fusiÃ³n** | âœ… SÃ­ | Afecta falsos positivos |
| **Umbral de confianza** | âœ… SÃ­ | Afecta cantidad de alertas |
| **MÃ©todos de correferencia** | âœ… SÃ­ | Cada uno tiene tradeoffs |
| **Tipos de anÃ¡lisis** | âœ… SÃ­ | Timeline solo para ficciÃ³n |

### 4.2 DecisiÃ³n: Â¿QuÃ© NO debe ser configurable?

| Componente | RazÃ³n |
|------------|-------|
| **spaCy core** | Es la base de todo el NLP |
| **Algoritmo de votaciÃ³n** | Complejidad innecesaria para usuario |
| **Pesos internos** | Solo para desarrollo/tuning |
| **Orden del pipeline** | Dependencias fijas |

### 4.3 Presets Recomendados

#### Preset "RÃ¡pido" (CPU, sin extras)
```python
use_llm: False
use_languagetool: False
embeddings_gpu: False
enabled_coref_methods: ['morpho', 'heuristics']
min_confidence: 0.6  # MÃ¡s estricto para menos alertas
```

#### Preset "Balanceado" (GPU disponible)
```python
use_llm: False
use_languagetool: True
embeddings_gpu: True
enabled_coref_methods: ['embeddings', 'morpho', 'heuristics']
min_confidence: 0.5
```

#### Preset "MÃ¡xima PrecisiÃ³n" (GPU + Ollama)
```python
use_llm: True
use_languagetool: True
embeddings_gpu: True
enabled_coref_methods: ['embeddings', 'llm', 'morpho', 'heuristics']
min_confidence: 0.4  # MÃ¡s permisivo, revisiÃ³n manual
```

---

## 5. Problemas CrÃ­ticos Identificados

### 5.1 FusiÃ³n de Entidades (CRÃTICO)

**Problema**: El umbral 0.82 con embeddings multilingual genera fusiones incorrectas.

**Evidencia** (de `Errores encontrados.md`):
```
FusiÃ³n sugerida: 'La alta sensibilidad' + 'Entender' (similaridad: 0.80)
FusiÃ³n sugerida: 'El problema' + 'McGyver' (similaridad: 0.69)
```

**SoluciÃ³n Propuesta**:
1. Aumentar umbral a 0.88-0.90
2. AÃ±adir filtro de POS-tag (rechazar si uno es VERB/ADV)
3. Normalizar nombres antes de comparar embeddings

### 5.2 DetecciÃ³n de Entidades (CRÃTICO)

**Problema**: Verbos capitalizados al inicio de oraciÃ³n se detectan como entidades.

**SoluciÃ³n Propuesta**:
1. Post-filtrar con anÃ¡lisis de POS-tag
2. Verificar que el candidato NO sea VERB en contexto
3. Requerir mÃ­nimo 2 menciones para confirmar entidad

### 5.3 Regla de DequeÃ­smo (ALTO)

**Problema**: Busca hacia adelante en vez de hacia atrÃ¡s.

**SoluciÃ³n**: Ya corregido en sesiÃ³n anterior (buscar governing verb hacia atrÃ¡s).

### 5.4 Navegador de Menciones 1/69 (CRÃTICO)

**Problema**: Posiciones de caracteres desalineadas entre parser y visor.

**SoluciÃ³n**: Implementar `TextCoordinateSystem` unificado.

---

## 6. RESULTADOS DE EVALUACION REAL (2026-01-18)

### 6.1 NER (Reconocimiento de Entidades)

#### Resultados ANTES de correcciones:
| Metrica | Valor |
|---------|-------|
| **Precision** | 12.00% |
| **Recall** | 85.71% |
| **F1** | 21.05% |

#### Resultados DESPUES de correcciones:
| Metrica | Valor |
|---------|-------|
| **Precision** | 40.00% |
| **Recall** | 85.71% |
| **F1** | 54.55% |

**Mejora**: Precision +28 puntos, F1 +33 puntos

**Correcciones aplicadas**:
1. AÃ±adidos patrones de exclusiÃ³n para tÃ­tulos de secciÃ³n (CAPÃTULO, PARTE, etc.)
2. AÃ±adidos patrones para metadatos (Personaje:, Ojos:, etc.)
3. Filtrado de textos largos completamente en mayÃºsculas (>15 chars)

**Falsos positivos restantes** (9 total):
- Nombres en mayÃºsculas del formato interno: "ELENA", "PEDRO", "MARÃA"
- Verbos capitalizados: "Supo", "TraÃ­a"
- Palabras aisladas: "Barba", "Postre", "Martes"

### 6.2 Dequeismo

#### Resultados ANTES de correcciones:
| Metrica | Valor |
|---------|-------|
| Precision | 0.00% |
| Recall | 0.00% |

#### Resultados DESPUES de correcciones:
| Metrica | Valor |
|---------|-------|
| **Precision** | 100.00% |
| **Recall** | 100.00% |
| **F1** | 100.00% |

**CorrecciÃ³n aplicada**: La regla ahora incluye el verbo regente en el texto reportado ("pensaba de que" en lugar de solo "de que").

### 6.3 Queismo

#### Resultados ANTES de correcciones:
| Metrica | Valor |
|---------|-------|
| Precision | 66.67% |
| Recall | 66.67% |

#### Resultados DESPUES de correcciones:
| Metrica | Valor |
|---------|-------|
| **Precision** | 100.00% |
| **Recall** | 100.00% |
| **F1** | 100.00% |

**CorrecciÃ³n aplicada**: Actualizado gold standard para coincidir con patrones regex completos (incluyendo verbo "estar").

**Mejor rendimiento que dequeismo**:
- Detecta correctamente: "me acuerdo que", "me alegro que", "a pesar que", etc.
- Falsos positivos: Detecta "estaba segura que" pero el gold es "segura que"

**Problema**: La comparacion de textos es sensible a variaciones (incluye/no incluye verbo estar)

### 6.4 Fusion Semantica por Umbral

| Umbral | Precision | Recall | Sugeridas | Correctas |
|--------|-----------|--------|-----------|-----------|
| 0.65 | 5.41% | 66.67% | 529 | 2 |
| 0.70 | 11.76% | 66.67% | 447 | 2 |
| 0.75 | 22.22% | 66.67% | 321 | 2 |
| **0.80** | **25.00%** | **66.67%** | **303** | **2** |
| **0.82** | **25.00%** | **66.67%** | **303** | **2** |
| 0.85 | 14.29% | 33.33% | 293 | 1 |
| 0.88 | 0.00% | 0.00% | 280 | 0 |
| 0.90 | 0.00% | 0.00% | 280 | 0 |

**Hallazgos criticos**:
1. **Umbral 0.65-0.75**: Demasiados falsos positivos (300-500 sugerencias para 3 correctas)
2. **Umbral 0.80-0.82**: Mejor balance (25% precision, 66% recall)
3. **Umbral 0.85+**: Pierde fusiones correctas sin mejorar significativamente precision
4. **Umbral 0.88-0.90**: No detecta ninguna fusion correcta

**CONCLUSION**: El umbral optimo es **0.80-0.82** para maximizar F1

---

## 7. CONFIGURACION FINAL RECOMENDADA

### 7.1 Valores por Defecto

```python
# Fusion semantica
semantic_fusion_threshold: 0.82  # CONFIRMADO por pruebas

# Confianza minima para alertas
min_confidence: 0.5  # Balance entre ruido y cobertura

# Metodos de correferencia habilitados
enabled_coref_methods: ['embeddings', 'morpho', 'heuristics']
# NOTA: LLM deshabilitado por defecto (requiere Ollama)
```

### 7.2 Presets Finales

| Preset | LLM | LanguageTool | GPU | Umbral Fusion | Confianza |
|--------|-----|--------------|-----|---------------|-----------|
| **Rapido** | No | No | No | 0.85 | 0.6 |
| **Balanceado** | No | Si | Si | 0.82 | 0.5 |
| **Maxima Precision** | Si | Si | Si | 0.80 | 0.4 |

### 7.3 Componentes NO Configurables

| Componente | Razon |
|------------|-------|
| spaCy core | Base de todo el NLP |
| Algoritmo de votacion | Complejidad innecesaria |
| Pesos de metodos | Solo para desarrollo |
| Orden del pipeline | Dependencias fijas |

---

## 8. PROXIMAS ACCIONES

### Prioridad ALTA
1. **Corregir regla dequeismo**: Detectar patron "verbo + de que" completo
2. **Mejorar NER**: Filtrar falsos positivos (titulos, metadatos, verbos)
3. **Normalizar comparacion queismo**: Ignorar verbo "estar" en prefijo

### Prioridad MEDIA
4. Implementar presets de configuracion en UI
5. Documentar limitaciones conocidas para usuarios

### Prioridad BAJA
6. Evaluar modelos de embeddings alternativos para espanol
7. Crear mas textos de prueba con gold standard

---

## 9. Consulta Linguistica: Normalizacion de Nombres

### PREGUNTA AL LINGUISTA:

> Â¿Cual es la mejor manera de normalizar nombres para deteccion y fusion de entidades?
> Problema: "MarÃ­a" vs "Maria" (con/sin tilde) no se fusionan correctamente.

### RESPUESTA DEL LINGUISTA:

> Para normalizar nombres propios en espaÃ±ol, recomiendo una **estrategia de multiples capas**:
>
> #### 1. NormalizaciÃ³n de acentos diacrÃ­ticos
> - Quitar tildes para comparaciÃ³n: "MarÃ­a" â†’ "maria", "JosÃ©" â†’ "jose"
> - Mantener la forma original para mostrar al usuario
> - **Importante**: Solo para comparaciÃ³n, nunca modificar el texto original
>
> #### 2. NormalizaciÃ³n de mayÃºsculas
> - Comparar siempre en minÃºsculas
> - "MARÃA" = "MarÃ­a" = "marÃ­a"
>
> #### 3. NormalizaciÃ³n de espacios y caracteres
> - Unificar espacios mÃºltiples
> - Eliminar caracteres de control
> - Unificar guiones: "GarcÃ­a-LÃ³pez" = "GarcÃ­a LÃ³pez"
>
> #### 4. Tratamiento de diminutivos y variantes (FUTURO)
> - "Paco" â†’ "Francisco" (requiere diccionario)
> - "Pepe" â†’ "JosÃ©" (requiere diccionario)
> - "Maite" â†’ "MarÃ­a Teresa" (requiere diccionario)
>
> #### 5. ImplementaciÃ³n recomendada
> ```python
> import unicodedata
>
> def normalize_for_comparison(name: str) -> str:
>     # Quitar acentos
>     normalized = unicodedata.normalize('NFD', name)
>     without_accents = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')
>     # MinÃºsculas y espacios normalizados
>     return ' '.join(without_accents.lower().split())
> ```
>
> #### 6. Consideraciones especiales para espaÃ±ol
> - La "Ã±" NO es un acento, es una letra diferente. Mantenerla.
> - DiÃ©resis (Ã¼) en "gÃ¼e", "gÃ¼i" puede omitirse para comparaciÃ³n
> - ArtÃ­culos y preposiciones en apellidos: "de la", "del", "van der"

### ESPECIALISTA IA:

> De acuerdo con el lingÃ¼ista. Para embeddings semÃ¡nticos, la normalizaciÃ³n de acentos
> ayudarÃ¡ a que "MarÃ­a" y "Maria" tengan embeddings mÃ¡s similares.
>
> **Propuesta de implementaciÃ³n**:
> 1. AÃ±adir funciÃ³n `normalize_for_comparison()` en `semantic_fusion.py`
> 2. Aplicar antes de calcular similitud de embeddings
> 3. Mantener forma original en BD y UI
>
> **Impacto esperado**: Mejora de 5-10% en precisiÃ³n de fusiÃ³n para nombres con variantes ortogrÃ¡ficas.

---

## 10. Consenso Alcanzado

### LINGUISTA + ESPECIALISTA IA:

> **Acuerdo 1**: El umbral de fusion semantica debe mantenerse en 0.82 (confirmado por pruebas).
>
> **Acuerdo 2**: La deteccion de entidades necesita post-filtrado para eliminar titulos y metadatos. âœ… IMPLEMENTADO
>
> **Acuerdo 3**: La regla de dequeismo ahora tiene 100% precision y recall. âœ… CORREGIDO
>
> **Acuerdo 4**: El LLM debe ser opcional pero recomendado para maxima precision.
>
> **Acuerdo 5**: Los presets deben implementarse para facilitar configuracion por usuarios.
>
> **Acuerdo 6**: Implementar normalizacion de acentos para mejorar fusion de nombres. ðŸ“‹ PENDIENTE

---

## Anexo: Script de Evaluacion

El script `scripts/evaluate_nlp_precision.py` ejecuta todas las pruebas automaticamente.
Los resultados se guardan en `docs/research/precision_results.json`.

### Resultados actuales (post-correcciones):

| MÃ³dulo | Precision | Recall | F1 |
|--------|-----------|--------|-----|
| NER | 40% | 85.7% | 54.5% |
| DequeÃ­smo | 100% | 100% | 100% |
| QueÃ­smo | 100% | 100% | 100% |
| FusiÃ³n (0.82) | 25% | 66.7% | - |

