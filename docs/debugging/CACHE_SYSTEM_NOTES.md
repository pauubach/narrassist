# Sistema de Cache - Notas de ImplementaciÃ³n

**Fecha**: 2026-02-17
**VersiÃ³n**: v0.10.15
**Objetivo**: 100x speedup en re-anÃ¡lisis (10-12 min â†’ <10 seg)

---

## ğŸ“Š Estado de ImplementaciÃ³n

### âœ… Completado

| Componente | Estado | Commit | Speedup |
|------------|--------|--------|---------|
| **Schema DB** | âœ… | `d205162` | - |
| **AnalysisCache** | âœ… | `d205162` | - |
| **NER Cache** | âœ… | `bc05901` | 3-5 min â†’ <1s |
| **Coref Cache** | â³ | Pendiente | 5-7 min â†’ <1s |
| **Attr Cache** | â³ | Pendiente | 30s â†’ <1s |

### ğŸ¯ Progreso

- **Actual**: ~40% del speedup total (solo NER cacheado)
- **Target**: 100x speedup cuando las 3 fases estÃ©n integradas

---

## ğŸ—ï¸ Arquitectura

### Tablas de Cache (SCHEMA_VERSION 29)

```sql
-- 3 tablas con patrÃ³n idÃ©ntico
CREATE TABLE {phase}_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id INTEGER NOT NULL,
    document_fingerprint TEXT NOT NULL,  -- SHA-256 cache key
    config_hash TEXT NOT NULL,           -- Config-aware cache
    {phase}_json TEXT NOT NULL,          -- Serialized results
    {counters} INTEGER DEFAULT 0,        -- Metadata
    cache_version INTEGER DEFAULT 1,
    created_at TEXT DEFAULT (datetime('now')),

    FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE,
    UNIQUE(project_id, document_fingerprint, config_hash)
);

CREATE INDEX idx_{phase}_cache_lookup ON {phase}_cache(
    project_id, document_fingerprint, config_hash
);
```

### Cache Key = `(project_id, fingerprint, config_hash)`

**Â¿Por quÃ© config_hash?**
- NER puede usar Ollama o no (`use_llm=true/false`)
- Correferencias puede usar diferentes mÃ©todos
- Configuraciones diferentes â†’ resultados diferentes â†’ cache separado

**Ejemplo**:
```python
config_hash = hashlib.sha256(
    json.dumps({
        "use_llm": True,
        "run_ner": True
    }, sort_keys=True).encode()
).hexdigest()[:16]  # "a3f2c1d4e5b6..."
```

---

## ğŸ”„ Flujo de Re-anÃ¡lisis

### Sin Cache (ANTES)
```
1. Parsing (1s)
2. Structure (2s)
3. NER (3-5 min)    â† Ollama bloqueante
4. Coref (5-7 min)  â† Ollama bloqueante
5. Attributes (30s)
6. Consistency (2 min)
TOTAL: 10-12 min
```

### Con Cache (DESPUÃ‰S)
```
1. Parsing (1s)
2. Structure (2s)
3. NER (<1s)         â† Cache hit, deserialize JSON
4. Coref (<1s)       â† Cache hit (pendiente)
5. Attributes (<1s)  â† Cache hit (pendiente)
6. Consistency (2 min)
TOTAL: ~2-3 min (con solo NER), <10s (con las 3 fases)
```

---

## ğŸ’¾ SerializaciÃ³n

### NER (Entidades + Menciones)

```json
[
  {
    "id": 3456,
    "canonical_name": "MarÃ­a SÃ¡nchez",
    "entity_type": "CHARACTER",
    "aliases": ["MarÃ­a", "SÃ¡nchez"],
    "importance": "PRINCIPAL",
    "first_appearance_char": 125,
    "mention_count": 45,
    "mentions": [
      {
        "surface_form": "MarÃ­a",
        "start_char": 125,
        "end_char": 130,
        "chapter_id": 1,
        "confidence": 0.95,
        "source": "spacy"
      },
      // ... 44 mÃ¡s
    ]
  },
  // ... mÃ¡s entidades
]
```

**TamaÃ±o**: ~500 KB por proyecto tÃ­pico (3 entidades, 100 menciones)

### Correferencias (Pendiente)

```json
{
  "chains": [
    {
      "mentions": ["MarÃ­a", "ella", "la mujer"],
      "entity_id": 3456,
      "confidence": 0.85
    }
  ],
  "unresolved": ["ese hombre"],
  "method": "voting"
}
```

### Atributos (Pendiente)

```json
[
  {
    "entity_id": 3456,
    "attr_type": "eye_color",
    "value": "azules",
    "evidence": {
      "text": "sus ojos azules brillaban",
      "start_char": 450,
      "end_char": 478,
      "confidence": 0.9
    }
  }
]
```

---

## ğŸ§ª Testing

### Cache Hit (Esperado)

```bash
# Primer anÃ¡lisis
[NER] NER complete: 3 entities (5 minutos)
[NER_CACHE] SET SUCCESS: project=5, entities=3, mentions=45

# Re-anÃ¡lisis (documento sin cambios)
[NER] Using cached results: 3 entities, 45 mentions (SKIP NER)
[NER] Cache restore complete: 3 entities (0.8s)
```

### Cache Miss (Esperado)

```bash
# Documento modificado (fingerprint cambiÃ³)
[NER_CACHE] MISS: project=5, config=a3f2c1d4 (hit rate: 0.0%)
[NER] NER complete: 3 entities (5 minutos)
[NER_CACHE] SET SUCCESS: project=5, entities=3, mentions=45
```

---

## ğŸ› Issues Conocidos

### 1. CancelaciÃ³n NO funciona durante Ollama

**Problema**: Cuando usuario cancela anÃ¡lisis, el backend estÃ¡ bloqueado esperando respuesta de Ollama (2-5 min) y no puede verificar `cancellation_flags`.

**Logs**:
```
17:54:15 - VotaciÃ³n coreference/qwen2.5: 109.0s  â† Bloqueado aquÃ­
```

**SoluciÃ³n propuesta**:
- Hacer llamadas a Ollama con timeout corto
- Verificar flag de cancelaciÃ³n cada N segundos
- Usar threads cancelables para LLM calls

**Workaround actual**: Esperar a que Ollama termine (puede tardar 5-10 min).

### 2. tokenizers version mismatch

**Warning**:
```
tokenizers>=0.22.0,<=0.23.0 is required, but found tokenizers==0.20.3
```

**Impacto**: Embeddings para correferencias NO funcionan â†’ solo LLM method

**Fix**:
```bash
pip install tokenizers==0.22.0
```

---

## ğŸ“ˆ MÃ©tricas de Performance

### Proyecto "Rich" (318 palabras, 3 capÃ­tulos)

| Fase | Sin Cache | Con Cache | Speedup |
|------|-----------|-----------|---------|
| Parsing | 1s | 1s | 1x |
| Structure | 2s | 2s | 1x |
| **NER** | **180s** | **<1s** | **180x** |
| Coref | 300s | â³ | - |
| Attributes | 30s | â³ | - |
| Consistency | 120s | 120s | 1x |
| **TOTAL** | **633s (10.5 min)** | **~450s (7.5 min)** | **1.4x** |

**Con todas las fases cacheadas**:
- **Target**: <10s (100x speedup)

---

## ğŸ”§ Rollback Plan

### Nivel 1: Deshabilitar cache (sin reiniciar)
```bash
# En ~/.bashrc o equivalente
export NA_CACHE_ENABLED=false

# Reiniciar servidor API
pkill -f "uvicorn.*main:app"
```

### Nivel 2: Limpiar cache (usuario)
```python
from narrative_assistant.persistence.analysis_cache import clear_analysis_cache
clear_analysis_cache()  # Borra todas las entradas
```

### Nivel 3: Drop tablas (catastrÃ³fico)
```sql
DROP TABLE IF EXISTS ner_cache;
DROP TABLE IF EXISTS coreference_cache;
DROP TABLE IF EXISTS attribute_cache;
```

---

## ğŸ“š Referencias

- [CACHE_DB_DEBUGGING_SESSION.md](CACHE_DB_DEBUGGING_SESSION.md) - Speech tracking cache (patrÃ³n base)
- [analysis_cache.py](../../src/narrative_assistant/persistence/analysis_cache.py) - ImplementaciÃ³n
- [database.py](../../src/narrative_assistant/persistence/database.py) - Schema SQL

---

## âœ… PrÃ³ximos Pasos

1. â³ Integrar cache en `run_fusion` (correferencias)
2. â³ Integrar cache en `run_attributes`
3. â³ Probar con proyecto "Rich" (re-anÃ¡lisis < 10s)
4. â³ Tests unitarios
5. â³ Fix cancelaciÃ³n durante Ollama calls
