# CI Pipeline - Narrative Assistant
# Ejecuta tests en cada push y PR

name: CI

on:
  push:
    branches: [master, main, develop]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'api-server/**'
      - 'frontend/**'
      - 'pyproject.toml'
      - 'frontend/package.json'
      - 'frontend/package-lock.json'
      - 'pytest.ini'
      - '.github/workflows/ci.yml'
  pull_request:
    branches: [master, main]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'api-server/**'
      - 'frontend/**'
      - 'pyproject.toml'
      - 'frontend/package.json'
      - 'frontend/package-lock.json'

jobs:
  # Tests unitarios (rápidos, sin dependencias NLP pesadas)
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
          pip install -r api-server/requirements.txt

      - name: Run unit tests
        run: |
          pytest tests/unit -v --tb=short -x -m "not slow and not heavy" --junitxml=junit-unit.xml

      - name: Upload test results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: unit-test-results
          path: junit-unit.xml

  # Linting y type checking
  lint:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install ruff mypy

      - name: Run Ruff
        run: |
          ruff check src/ tests/ api-server/ --output-format=github

      - name: Run MyPy (critical modules)
        run: |
          # Verificar módulos críticos donde errores de tipo pueden causar bugs runtime.
          # Excluir pipelines/ (legacy, 800+ errores) y cli.py (deprecated).
          mypy src/narrative_assistant/core src/narrative_assistant/persistence src/narrative_assistant/parsers src/narrative_assistant/alerts --ignore-missing-imports

  # Validaciones frontend en PR/push
  frontend-checks:
    name: Frontend Checks
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: frontend
        run: |
          npm ci

      - name: Frontend type-check
        working-directory: frontend
        run: |
          npm run type-check

      - name: Frontend tests
        working-directory: frontend
        run: |
          npm run test:run

      - name: Frontend build
        working-directory: frontend
        run: |
          npm run build

  # Tests de integración (requieren modelos NLP)
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Solo en push a master, no en PRs (son lentos)
    if: github.event_name == 'push' && github.ref == 'refs/heads/master'

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"

      - name: Download spaCy model
        run: |
          python -m spacy download es_core_news_sm

      - name: Run integration tests
        run: |
          pytest tests/integration -v --tb=short -x --junitxml=junit-integration.xml
        continue-on-error: true

      - name: Upload test results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: integration-test-results
          path: junit-integration.xml

  # Tests de performance (solo en master, manual o scheduled)
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    # Solo manual o en releases
    if: github.event_name == 'workflow_dispatch'

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
          python -m spacy download es_core_news_sm

      - name: Run performance tests
        run: |
          pytest tests/performance -v --tb=short -m slow --junitxml=junit-perf.xml
        continue-on-error: true

      - name: Upload test results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: performance-test-results
          path: junit-perf.xml

  # Resumen final
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, lint, frontend-checks]
    if: always()

    steps:
      - name: Check results
        run: |
          if [ "${{ needs.unit-tests.result }}" == "failure" ]; then
            echo "Unit tests failed"
            exit 1
          fi
          if [ "${{ needs.lint.result }}" == "failure" ]; then
            echo "Lint failed"
            exit 1
          fi
          if [ "${{ needs.frontend-checks.result }}" == "failure" ]; then
            echo "Frontend checks failed"
            exit 1
          fi
          echo "All checks passed!"
